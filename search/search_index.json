{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>HestiaStore is a lightweight, embeddable key-value storage engine optimized for billions of records, designed to run in a single directory with high performance and minimal configuration.</p> <p>Features:</p> <pre><code> \u2022 Java-based with minimum external dependencies\n \u2022 Requires Java 17+\n \u2022 In-memory or file-backed indexes\n \u2022 Optional write-ahead logging\n \u2022 Supports user-defined key/value types\n \u2022 Optionaly could be thread safe\n</code></pre>"},{"location":"#how-to-use-hestiastore","title":"How to use HestiaStore","text":"<p>Index should be created with builder, which make index instance. For example:</p> <pre><code>// Create an in-memory file system abstraction\nDirectory directory = new MemDirectory();\n\n// Prepare index configuration\nIndexConfiguration&lt;String, String&gt; conf = IndexConfiguration\n        .&lt;String, String&gt;builder()//\n        .withKeyClass(String.class)//\n        .withValueClass(String.class)//\n        .withName(\"test_index\") //\n        .build();\n\n// create new index\nIndex&lt;String, String&gt; index = Index.&lt;String, String&gt;create(directory, conf);\n\n// Do some work with the index\nindex.put(\"Hello\", \"World\");\n\nString value = index.get(\"Hello\");\nSystem.out.println(\"Value for 'Hello': \" + value);\n</code></pre>"},{"location":"#questions","title":"Questions","text":"<p>If you encounter a bug, have a feature request, or need help using HestiaStore, please create an issue.</p>"},{"location":"how-to-use-index/","title":"How to use HestiaStore","text":"<p>Note: HestiaStore is a library, not a standalone application. It is designed to be integrated into a larger system to provide efficient storage and retrieval of large volumes of key-value pairs.</p>"},{"location":"how-to-use-index/#how-to-use-hestiastore","title":"How to Use HestiaStore","text":""},{"location":"how-to-use-index/#prerequisites","title":"Prerequisites","text":"<ul> <li>Java 11 or higher (recommended)</li> <li>Maven 3.6+ or Gradle 6+</li> <li>Access to GitHub Packages (requires authentication)</li> </ul> <p>HestiaStore is available via GitHub Packages. To use it in your project, you need to add the GitHub repository and the dependency.</p>"},{"location":"how-to-use-index/#maven","title":"Maven","text":"<p>At file <code>pom.xml</code> to section <code>dependencies</code> add the following:</p> <pre><code>&lt;dependencies&gt;\n  &lt;dependency&gt;\n    &lt;groupId&gt;org.hestiastore.index&lt;/groupId&gt;\n    &lt;artifactId&gt;core&lt;/artifactId&gt;\n    &lt;version&gt;0.0.3&lt;/version&gt; &lt;!-- Replace with the actual version --&gt;\n  &lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre> <p>Note: You must authenticate to GitHub to access the package. Refer to GitHub's documentation for details.</p>"},{"location":"how-to-use-index/#gradle","title":"Gradle","text":"<p>In your <code>build.gradle</code>:</p> <pre><code>dependencies {\n  implementation \"org.hestiastore.index:core:0.0.3\" // Replace with the actual version\n}\n</code></pre>"},{"location":"how-to-use-index/#some-examples","title":"Some examples","text":""},{"location":"how-to-use-index/#creating-an-index","title":"Creating an index","text":"<pre><code>import com.hestiastore.index.Index;\nimport com.hestiastore.index.IndexFactory;\n\npublic class Example {\n  public static void main(String[] args) {\n        // Create an in-memory file system abstraction\n        final Directory directory = new MemDirectory();\n\n        // Prepare index configuration\n        final IndexConfiguration&lt;String, String&gt; conf = IndexConfiguration\n                .&lt;String, String&gt;builder()//\n                .withKeyClass(String.class)//\n                .withValueClass(String.class)//\n                .withName(\"test_index\") //\n                .build();\n\n        // create new index\n        Index&lt;String, String&gt; index = Index.&lt;String, String&gt;create(directory,\n                conf);\n\n        // Perform basic operations with the index\n        index.put(\"Hello\", \"World\");\n\n        String value = index.get(\"Hello\");\n        System.out.println(\"Value for 'Hello': \" + value);\n\n        index.close();\n  }\n}\n</code></pre> <p>This creates a simple in-memory index and stores a key-value pair.</p> <p>When you have first example you can dive into more advanced configuration. There are explained details about <code>Directory</code> object and using custom Key/Value classes</p>"},{"location":"how-to-use-index/#opening-an-existing-index","title":"Opening an existing index","text":"<p>Please note that Index uses separate methods for creating index and for opening already existing index. So open already existing index use:</p> <pre><code>IndexConfiguration&lt;String, String&gt; conf = IndexConfiguration\n        .&lt;String, String&gt;builder()//\n        .withKeyClass(String.class)//\n        .withValueClass(String.class)//\n        .withName(\"test_index\") //\n        .build();\n\nIndex&lt;String, String&gt; index = Index.&lt;String, String&gt;open(directory, conf);\n</code></pre>"},{"location":"how-to-use-index/#data-manipulation","title":"Data manipulation","text":"<p>There are two methods <code>put</code> and <code>get</code> using them is straightforward:</p> <pre><code>index.put(\"Hello\", \"World\");\n\nString value = index.get(\"Hello\");\n</code></pre> <p>Stored values are immediately available. Command ordering could be random.</p>"},{"location":"how-to-use-index/#sequential-data-reading","title":"Sequential data reading","text":"<p>Reading from index could be done like this:</p> <pre><code>index.getStream(null).forEach(entry -&gt; {\n\n  // Do what have to be done\n    System.out.println(\"Entry: \" + entry);\n\n});\n</code></pre> <p>Data are returned in ascending ordering. This ordering can't be changed. Index stores data in segments. In some cases could be usefull to sequentially read just some segments. Segment could be selected by object <code>SegmentWindow</code></p> <pre><code>SegmentWindow window = SegmentWindow.of(1000, 10);\n\nindex.getStream(window).forEach(entry -&gt; {\n    System.out.println(\"Entry: \" + entry);\n});\n</code></pre>"},{"location":"how-to-use-index/#data-maintenance","title":"Data maintenance","text":"<p>In some cases could be useful to perform maintenance with data. There are following operations with <code>Index</code>:</p> <ul> <li><code>flush()</code> It flush all data from memory to disk to ensure that all data is safely stored. It make sure that data are stored. Could be called befor index iterating and when user want to be sure, that all data are stored.</li> <li><code>checkAndRepairConsistency()</code> It verify that meta data about data in index are consistent. Some problems coudl repair. When index is beyond repair it fails.</li> <li><code>compact();</code> Goes through all segments add compact main segment data with temporal files. It can save disk space.</li> </ul>"},{"location":"how-to-use-index/#limitations","title":"Limitations","text":""},{"location":"how-to-use-index/#staled-result-from-indexgetstream-method","title":"Staled result from index.getStream() method","text":"<p>Data from <code>index.getStream()</code> method could be staled or invalid. It's corner case when next readed key value pair is changed. Index data streaming is splited internally into steps <code>hasNextElement()</code> and <code>getNextElement()</code>. Following example will show why it's no possible to use index cache:</p> <pre><code>index.hasNextElement(); // --&gt; true\n</code></pre> <p>Now next element has to be known to be sure that exists. Let's suppose that in index is just one element <code>&lt;k1,v1&gt;</code>.</p> <pre><code>index.delete(\"k1\");\nindex.nextElement(); // --&gt; fail\n</code></pre> <p>last operation will fail because there is not possible to find next element because <code>&lt;k1,v1&gt;</code> was deleted. To prevent this problem index cache is not used during index streaming. If all index content should be streamed than before streaming should be <code>compact()</code> method and during streaming data shouldn't be changed.</p> <p>To be sure that all data is read than befor reading perform <code>Index.flush()</code> and during iterating avoid using of <code>Index.put()</code> and <code>Index.delete()</code> operations.</p>"},{"location":"how-to-use-index/#threadsafe","title":"ThreadSafe","text":"<p>Note: Index is not thread-safe by default. Use <code>.withThreadSafe(true)</code> in the configuration to enable thread safety.</p>"},{"location":"how-to-use-index/#exception-handling","title":"Exception handling","text":"<p>Here are exceptions that could be throws from HestiaStore:</p> <ul> <li><code>NullPointerException</code> -  When something fails really badly. For example when disk reading fails or when user delete part of configuration file.</li> <li><code>IndexException</code> - Usually indicated internal HestiaStore problem with data consistency.</li> <li><code>IllegalArgumentException</code> - validation error, for example when key type is not specified. It's also thrown when some object is not initialized correctly.</li> <li><code>IllegalStateException</code> - When HestiaStore is in inconsistent state and is unable to recover.</li> </ul> <p>All exceptions are runtime exceptions and doesn't have to be explicitly handled.</p>"},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/arch-index/","title":"Architecture","text":"<p>Here is described basic index concepts. This page explain you how to correctly configure index.</p> <p></p>"},{"location":"architecture/arch-index/#operation-consistency","title":"Operation consistency","text":"<p>The <code>getStream()</code> method can sometimes return inconsistent results, occasionally omitting some items. This can occur in the following scenarios:</p> <ul> <li>Segment Compaction: If data is being streamed from a segment and new keys are added to that segment during the process, the segment may stop providing additional keys. In this case, the stream operation will either continue with the next segment or terminate if no more segments are available.</li> <li>Adding New Keys: If a completely new key is added to the index and is only present in the main index cache, it will not be returned.</li> </ul> <p>To prevent these issues, you should call <code>compact()</code> before invoking <code>getStream()</code> and ensure no new keys are added during streaming.</p> <p>Updating values in the index using <code>put()</code> or deleting keys using <code>delete()</code> does not cause inconsistencies. Updated values will be returned, and deleted keys will be excluded from the stream.</p> <p>Other operations, like <code>get()</code>, remain consistently reliable.</p>"},{"location":"architecture/arch-index/#states","title":"States","text":"<p>Index could be in following states:</p> <p></p> <p></p> <p>Interruption of process of writing data to index could lead to corruption of entire index.</p>"},{"location":"architecture/segment/","title":"Segment implementation","text":"<p>Segment is core part of index. It represents one string sorted table file with:</p> <ul> <li>Partial consistency - iterator stop working or return consistent data</li> <li>Support Writing changes into delta files</li> <li>Bloom filter for faster evaluating if key is in index</li> <li>Scarce index for faster searching for data in main index</li> </ul>"},{"location":"architecture/segment/#segment-putget-and-iterate-consistency","title":"Segment put/get and iterate consistency","text":"<p>operations like write and get should be always consistent. What is written is read. Iteration behave differently. better than provide old data it stop providing any data.</p> <p>Let's have a followin key value pairs in main index: <pre><code>&lt;a, 20 &gt;\n&lt;b, 30 &gt;\n&lt;c, 40 &gt;\n</code></pre></p> <p>In segment cache are following pairs: <pre><code>&lt;a, 25&gt;\n&lt;e, 28&gt;\n&lt;b, tombstone&gt;\n</code></pre></p> <p>When user will iterate throught segment data, there will be followin cases:</p>"},{"location":"architecture/segment/#case-1-read-data","title":"Case 1 - Read data","text":"<pre><code>iterator.read() --&gt; &lt;a, 25&gt;\niterator.read() --&gt; &lt;c, 40&gt;\niterator.read() --&gt; &lt;e, 28&gt;\n</code></pre>"},{"location":"architecture/segment/#case-2-change-data","title":"Case 2 - Change data","text":"<pre><code>iterator.read() --&gt; &lt;a, 25&gt;\nsegment.write(c, 10)\niterator.read() --&gt; null\n</code></pre> <p>Any segment write operation will break segment iterator. It's easier way to secure segment consistency.  </p>"},{"location":"architecture/segment/#caching-of-segment-data","title":"Caching of segment data","text":"<p>In segment following object are cached:</p> <ul> <li>SegmentDeltaCache - contains changed key value pair from segment</li> <li>BloomFilter - bloom filter data</li> <li>ScarceIndex - scarce index data</li> </ul> <p>There are few classes that provide lazy loading of segment data a flexibility to cache segment data. Segment data are managed by following classes: </p> <p></p> <p>Object <code>SegmentData</code> could contains objects <code>SegmentDeltaCache</code>, <code>BloomFilter</code> and <code>ScarceIndex</code>. All of them are lazy loaded by <code>SegmentDataSupplier</code>. For closer class description look at source code.</p> <p>The following image shows that <code>SegmentDatafactory</code> can be referenced from <code>SegmentDataProviderSimple</code>, which is the simplest implementation that merely holds segment data from the factory. The class <code>SegmentDataProviderFromMainCache</code> interacts with the main index cache where the segment data is stored. Data may be evicted from the cache without any notification.</p> <p></p>"},{"location":"architecture/segment/#writing-to-segment","title":"Writing to segment","text":"<p>Opening segment writer immediatelly close all segment readers. When writing operation add key that is in index but is not in cache this value will not returned updated. </p> <p>Putting new pair into segment is here:</p> <p></p>"},{"location":"configuration/","title":"Configuration","text":"<p>Don\u2019t be afraid to experiment\u2014if a configuration is missing or invalid, the Index will fail fast, helping you catch issues early.</p> <p>The index is configured using the <code>IndexConfiguration</code> class. All essential index properties are configurable through the builder. See the example below:</p> <pre><code>IndexConfiguration&lt;Integer, Integer&gt; conf = IndexConfiguration\n    .&lt;Integer, Integer&gt;builder()//\n    .withKeyClass(Integer.class)//\n    .withValueClass(Integer.class)//\n    .withKeyTypeDescriptor(tdi) //\n    .withValueTypeDescriptor(tdi) //\n    .withMaxNumberOfKeysInSegment(4) //\n    .withMaxNumberOfKeysInSegmentCache(10L) //\n    .withMaxNumberOfKeysInSegmentCacheDuringFlushing(12L)//\n    .withMaxNumberOfKeysInSegmentIndexPage(2) //\n    .withMaxNumberOfKeysInCache(3) //\n    .withBloomFilterIndexSizeInBytes(0) //\n    .withBloomFilterNumberOfHashFunctions(4) //\n    .withLogEnabled(false) //\n    .withName(\"test_index\") //\n    .build();\n\nIndex&lt;Integer, Integer&gt; index = Index.&lt;Integer, Integer&gt;create(directory, conf);\n</code></pre> <p>Now let's look at particular parameters.</p>"},{"location":"configuration/#index-directory","title":"Index Directory","text":"<p>Place where all data are stored. There are two already prepared types:</p>"},{"location":"configuration/#in-memory","title":"In Memory","text":"<p>All data are stored in memory. It's created like this:</p> <pre><code>Directory directory = new MemDirectory();\n</code></pre> <p>It's usefull for testing purposes.</p>"},{"location":"configuration/#file-system","title":"File system","text":"<p>Its main purpose is to store index data in the file system. Create a file-system-based directory like this:</p> <pre><code>Directory directory = new FsDirectory(new File('my directory'));\n</code></pre>"},{"location":"configuration/#properties-of-indexconfiguration-class","title":"Properties of <code>IndexConfiguration</code> class","text":"<p>All properties are required and have the following meanings:</p>"},{"location":"configuration/#index-related-configuration","title":"Index related configuration","text":""},{"location":"configuration/#key-class-withkeyclass","title":"Key class - <code>withKeyClass()</code>","text":"<p>A <code>Class</code> object that represents the type of keys used in the index. Only instances of this class may be inserted. While any Java class is technically supported, it's recommended to use simple, compact types for performance reasons. Predefined classes are:</p> <ul> <li>Integer</li> <li>Long</li> <li>String</li> <li>Byte</li> </ul> <p>If a different class is used, the key type descriptor must be set using the <code>withKeyTypeDescriptor()</code> method from the builder. If you use a custom class, you must implement the <code>com.hestiastore.index.datatype.TypeDescriptor</code> interface to describe how the type is serialized and compared.</p>"},{"location":"configuration/#value-class-withvalueclass","title":"Value class - <code>withValueClass()</code>","text":"<p>Required. Specifies the Java class used for values. The same rules that apply to the key class also apply to the value class.</p>"},{"location":"configuration/#index-name-withname","title":"Index name - <code>withName()</code>","text":"<p>Required. Assigns a logical name to the index. This can be useful in diagnostics and logging.</p>"},{"location":"configuration/#key-type-descriptor-withkeytypedescriptor","title":"Key type descriptor - <code>withKeyTypeDescriptor()</code>","text":"<p>Type descriptor for the key class. Required for non-default types.</p>"},{"location":"configuration/#value-type-descriptor-withvaluetypedescriptor","title":"Value type descriptor - <code>withValueTypeDescriptor()</code>","text":"<p>Type descriptor for the value class. Required for non-default types.</p>"},{"location":"configuration/#max-number-of-keys-in-cache-withmaxnumberofkeysincache","title":"Max number of keys in cache - <code>withMaxNumberOfKeysInCache()</code>","text":"<p>Sets the maximum number of key-value pairs allowed in the in-memory cache before flushing.</p>"},{"location":"configuration/#max-number-of-segments-in-cache-withmaxnumberofsegmentsincache","title":"Max number of segments in cache - <code>withMaxNumberOfSegmentsInCache()</code>","text":"<p>Limits the number of segments stored in memory. Useful for controlling memory usage.</p>"},{"location":"configuration/#thread-safe-withthreadsafe","title":"Thread safe - <code>withThreadSafe()</code>","text":"<p>Whether the index instance is safe for concurrent access by multiple threads. When it's set to <code>code</code> true than index will be synchronized between threads.</p>"},{"location":"configuration/#log-enabled-withlogenabled","title":"Log enabled - <code>withLogEnabled()</code>","text":"<p>Enables or disables write-ahead logging. Currently it's experimental feature.</p>"},{"location":"configuration/#segment-related-configuration","title":"Segment related configuration","text":""},{"location":"configuration/#max-number-of-keys-in-segment-withmaxnumberofkeysinsegment","title":"Max number of keys in segment - <code>withMaxNumberOfKeysInSegment()</code>","text":"<p>Sets the maximum number of keys allowed in a single segment. Exceeding this splits the segment.</p>"},{"location":"configuration/#max-number-of-keys-in-segment-cache-withmaxnumberofkeysinsegmentcache","title":"Max number of keys in segment cache - <code>withMaxNumberOfKeysInSegmentCache()</code>","text":"<p>Defines how many keys can be cached from a segment during regular operation.</p>"},{"location":"configuration/#max-number-of-keys-in-segment-cache-during-flushing-withmaxnumberofkeysinsegmentcacheduringflushing","title":"Max number of keys in segment cache during flushing - <code>withMaxNumberOfKeysInSegmentCacheDuringFlushing()</code>","text":"<p>Specifies the maximum number of keys that can be temporarily cached from a segment during flushing.</p>"},{"location":"configuration/#max-number-of-keys-in-segment-index-page-withmaxnumberofkeysinsegmentindexpage","title":"Max number of keys in segment index page - <code>withMaxNumberOfKeysInSegmentIndexPage()</code>","text":"<p>Defines the number of keys in the index page for a segment. This impacts lookup efficiency.</p>"},{"location":"configuration/#bloom-filter-configuration","title":"Bloom filter configuration","text":"<p>A Bloom filter is a probabilistic data structure that efficiently tests whether an element is part of a set. You can find a detailed explanation on Wikipedia. In this context, each segment has its own Bloom filter.</p> <p>To disable bloom filter completle set:</p> <pre><code> .withBloomFilterIndexSizeInBytes(0)\n</code></pre> <p>The settings for the Bloom filter can be adjusted using the following methods:</p>"},{"location":"configuration/#bloom-filter-size-withbloomfilterindexsizeinbytes","title":"Bloom filter size - <code>withBloomFilterIndexSizeInBytes()</code>","text":"<p>Sets the size of the Bloom filter in bytes. A value of 0 disables the use of the Bloom filter.</p>"},{"location":"configuration/#number-of-hash-functions-withbloomfilternumberofhashfunctions","title":"Number of hash functions - <code>withBloomFilterNumberOfHashFunctions()</code>","text":"<p>Sets the number of hash functions used in the Bloom filter.</p>"},{"location":"configuration/#probability-of-false-positive-withbloomfilterprobabilityoffalsepositive","title":"Probability of false positive - <code>withBloomFilterProbabilityOfFalsePositive()</code>","text":"<p>Sets the probability of false positives. When <code>get(someKey)</code> is called on a segment, the Bloom filter is checked to determine if the value is not in the segment. It can return <code>true</code>, indicating that the key could be in the segment. If the Bloom filter indicates the key is in the segment but it's not found, that's a false positive. The probability of this occurring is a value between 0 and 1.</p> <p>Usually, it's not necessary to adjust the Bloom filter settings.</p>"},{"location":"configuration/#changing-index-propertise","title":"Changing Index propertise","text":"<p>Some parameters can be redefined when the index is opened.</p> <pre><code>Index&lt;String, String&gt; index = Index.&lt;String, String&gt;open(directory, conf);\n</code></pre> <p>At allows to pass <code>IndexConfiguration</code> object and this way change configuration parameters. Fllowing table shou parameters that can be changed.  </p> Name Meaning Can be changed Applies to indexName Logical name of the index \ud83d\udfe9 index keyClass Key class \ud83d\udfe5 index valueClass Value class \ud83d\udfe5 index keyTypeDescriptor Key class type descriptor \ud83d\udfe5 index valueTypeDescriptor Value class type descriptor \ud83d\udfe5 index maxNumberOfKeysInSegmentIndexPage Maximum keys in segment index page \ud83d\udfe5 segment maxNumberOfKeysInSegmentCache Maximum number of keys in segment cache \ud83d\udfe9 segment maxNumberOfKeysInSegmentCacheDuringFlushing Maximum keys in cache during flushing \ud83d\udfe9 segment maxNumberOfKeysInCache Maximum keys in the index cache \ud83d\udfe9 index maxNumberOfKeysInSegment Maximum keys in a segment \ud83d\udfe5 segment maxNumberOfSegmentsInCache Maximum number of segments in cache \ud83d\udfe9 index bloomFilterNumberOfHashFunctions Bloom filter - number of hash functions used \ud83d\udfe5 segment bloom filter bloomFilterIndexSizeInBytes Bloom filter - index size in bytes \ud83d\udfe5 segment bloom filter bloomFilterProbabilityOfFalsePositive Bloom filter - probability of false positives \ud83d\udfe5 segment bloom filter diskIoBufferSize Size of the disk I/O buffer \ud83d\udfe9 Disk IO threadSafe If index is thread-safe \ud83d\udfe9 index logEnabled If full logging is enabled \ud83d\udfe9 index"},{"location":"configuration/#add-custom-data-type","title":"Add custom data type","text":"<p>HestiaStore have to know how to work with new data type. So first is create implementatio of <code>com.hestiastore.index.datatype.TypeDescriptor</code>. Than during index creation set let index know about your implementation by <code>withKeyTypeDescriptor</code>. And it's done.</p>"},{"location":"configuration/logging/","title":"Logging","text":"<p>HestiaStore uses slf4j for internal logging. So you should include your preferred logging library like logback, log4j, or another with a bridge to slf4j. In case you use log4j, look at the example configuration:</p>"},{"location":"configuration/logging/#example-configuration-file-for-log4j","title":"Example configuration File for log4j","text":"<p>Bellow is the example Log4j2 configuration used in HestiaStore:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Configuration status=\"INFO\"&gt;\n  &lt;Appenders&gt;\n\n    &lt;Console name=\"Console\" target=\"SYSTEM_OUT\"&gt;\n      &lt;PatternLayout\n          pattern=\"%style{%d{ISO8601}}{white} %highlight{%-5level }[%style{%t}{bright,blue}] %style{%-C{1.mv}}{bright,yellow}: %msg%n%throwable\" /&gt;\n    &lt;/Console&gt;\n\n    &lt;Console name=\"indexAppender\" target=\"SYSTEM_OUT\"&gt;\n      &lt;PatternLayout\n          pattern=\"%style{%d{ISO8601}}{white} %highlight{%-5level }[%style{%t}{bright,blue}] index='%style{%X{index.name}}{magenta}' %style{%-C{1.mv}}{bright,yellow}: %msg%n%throwable\" /&gt;\n    &lt;/Console&gt;\n\n  &lt;/Appenders&gt;\n  &lt;Loggers&gt;\n    &lt;logger name=\"com.hestiastore.index\" level=\"DEBUG\" additivity=\"false\"&gt;\n      &lt;appender-ref ref=\"indexAppender\" /&gt;\n    &lt;/logger&gt;\n    &lt;Root level=\"DEBUG\"&gt;\n      &lt;AppenderRef ref=\"Console\"/&gt;\n    &lt;/Root&gt;\n  &lt;/Loggers&gt;\n&lt;/Configuration&gt;\n</code></pre> <p>this example will produce logs look like this:</p> <p></p>"},{"location":"configuration/logging/#log-appenders","title":"Log Appenders","text":"<ul> <li>Console (default): Used by all components not explicitly assigned a logger. Outputs time, level, thread, and class name.</li> <li>indexAppender: Specifically configured for <code>com.hestiastore.index</code>, outputs additional context (<code>index.name</code>) for disambiguating messages from different index instances.</li> </ul>"},{"location":"configuration/logging/#customizing-logging-levels","title":"Customizing Logging Levels","text":"<p>You can control verbosity by modifying the <code>&lt;logger&gt;</code> or <code>&lt;Root&gt;</code> levels:</p> <ul> <li><code>ERROR</code>, <code>WARN</code>, <code>INFO</code>, <code>DEBUG</code>, or <code>TRACE</code></li> <li>For example, to suppress general debug logs:</li> </ul> <pre><code>&lt;Root level=\"INFO\"&gt;\n</code></pre>"},{"location":"configuration/logging/#disabling-index-logs","title":"Disabling Index Logs","text":"<p>If you want to disable index-specific logging entirely, remove or comment out the <code>com.hestiastore.index</code> logger section. Alternatively log level for package could be set to \"ERROR\".</p>"},{"location":"configuration/logging/#recommendations","title":"Recommendations","text":"<ul> <li>Use <code>DEBUG</code> during development or troubleshooting.</li> <li>Switch to <code>INFO</code> or <code>WARN</code> in production to reduce log noise.</li> <li>Ensure you clear MDC values (<code>ThreadContext.clearAll()</code>) in thread pools to prevent memory leaks or incorrect context reuse.</li> </ul>"},{"location":"configuration/logging/#logging-implementation","title":"Logging Implementation","text":"<p>The <code>indexAppender</code> uses a mapped diagnostic context (MDC) value <code>index.name</code>, which should be set programmatically:</p> <pre><code>ThreadContext.put(\"index.name\", \"userIndex\");\n</code></pre> <p>This allows the log output to include which index instance the message is referring to, aiding in debugging concurrent access or behavior across multiple indexes.</p>"},{"location":"development/","title":"Development","text":"<p>Here are some development related topiscs.</p>"},{"location":"development/documentation/","title":"Documentation","text":"<p>Documentation is available in the following locations:</p> <ul> <li><code>mvn site</code> - Includes detailed project reports from PMC, checkstyle, JUnit test line coverage, and Javadocs. It's not published.</li> <li>GitHub project - Simple technical development oriented site</li> <li>HestiaStore.org site - Detailed, user-focused information</li> </ul> <p>Following text is about HestiaStore.org site documentation.</p>"},{"location":"development/documentation/#how-to-make-changes-to-hestiastoreorg","title":"How to make changes to HestiaStore.org","text":"<p>HestiaStore.org site documentation is served from the main project branch <code>gh-pages</code>. Publishing a new site version involves generating HTML from Markdown and pushing it to <code>gh-pages</code>.</p> <p>Prerequisites:</p> <ul> <li>Installed git</li> <li>Site generating tool mkdocs-material - as described at https://squidfunk.github.io/mkdocs-material/. It is user-friendly and easy to work with. In case of MacOS install it with:</li> </ul> <p><pre><code>brew install mkdocs-material\n</code></pre> * Some Markdown editor of your choice * GitHub personal access token with permission to read and write project pages.</p>"},{"location":"development/documentation/#page-editing-and-viewing-documentation-locally","title":"Page editing and viewing documentation locally","text":"<p>From project checkout branch <code>docs</code>, there are all source files for main site. Markdown files for documentation are located in the directory <code>docs</code>. To preview documentation changes locally, run:</p> <pre><code>mkdocs serve\n</code></pre> <p>Now at http://127.0.0.1:8080/HestiaStore/ should display the documentation.</p> <p>The <code>mkdocs.yml</code> file in the root directory controls site structure, navigation, and theme. For more information see mkdocs-material documentation.</p>"},{"location":"development/documentation/#how-to-publish-changes-at-hestiastoreorg","title":"How to publish changes at hestiastore.org","text":"<ul> <li>From github.com/jajir/HestiaStore checkout branch <code>docs</code>. </li> <li>Make changes</li> <li>Commit changes to <code>docs</code></li> <li>Then, run the following command locally:</li> </ul> <p><pre><code>mkdocs gh-deploy\n</code></pre>   In a few minutes (could be 15 minutes) new documentation will be published.</p>"},{"location":"development/guides/","title":"Development","text":"<p>Here are some development related topiscs.</p>"},{"location":"development/guides/#how-to-run-jmh-benchmarks","title":"How to run JMH benchmarks","text":"<p>Follow this steps: * Compile whole project and create pacakge containing all benchmarks data * Go to <code>jmh-benchmarks</code> * Execute it, with temp directory in <code>target</code> directory</p> <pre><code>mvn clean install\ncd jmh-benchmarks\njava -Ddir=./target/ -jar target/jmh-benchmarks.jar\n</code></pre> <p>Specific JMH benchmark class could be run:</p> <pre><code>java -Ddir=./target/ -jar target/jmh-benchmarks.jar SegmentSearchBenchmark\n</code></pre> <p>result could look like:</p> <pre><code>Benchmark                                             Mode  Cnt    Score      Error  Units\nSequentialFileReadingBenchmark.test_with_buffer_01KB  avgt    4   70.747 \u00b1   42.480  ms/op\nSequentialFileReadingBenchmark.test_with_buffer_02KB  avgt    4   60.009 \u00b1   52.899  ms/op\nSequentialFileReadingBenchmark.test_with_buffer_04KB  avgt    4   51.254 \u00b1   30.112  ms/op\nSequentialFileReadingBenchmark.test_with_buffer_08KB  avgt    4   48.600 \u00b1   28.892  ms/op\nSequentialFileReadingBenchmark.test_with_buffer_16KB  avgt    4   48.471 \u00b1   25.665  ms/op\nSequentialFileReadingBenchmark.test_with_buffer_32KB  avgt    4   45.256 \u00b1   24.986  ms/op\nSequentialFileReadingBenchmark.test_with_buffer_64KB  avgt    4   45.204 \u00b1   24.867  ms/op\nSequentialFileWritingBenchmark.test_with_buffer_01KB  avgt    4  238.075 \u00b1   75.311  ms/op\nSequentialFileWritingBenchmark.test_with_buffer_02KB  avgt    4  271.272 \u00b1   64.747  ms/op\nSequentialFileWritingBenchmark.test_with_buffer_04KB  avgt    4  276.001 \u00b1   45.815  ms/op\nSequentialFileWritingBenchmark.test_with_buffer_08KB  avgt    4  352.189 \u00b1 1140.814  ms/op\nSequentialFileWritingBenchmark.test_with_buffer_16KB  avgt    4  258.806 \u00b1   44.693  ms/op\nSequentialFileWritingBenchmark.test_with_buffer_32KB  avgt    4  276.246 \u00b1  135.019  ms/op\nSequentialFileWritingBenchmark.test_with_buffer_64KB  avgt    4  275.944 \u00b1  128.835  ms/op\n</code></pre> <p>When some JMH benchmark class is changed command <code>mvn package</code> have to be run.</p>"},{"location":"development/guides/#possible-problems","title":"Possible problems","text":"<p>Generally JMH is quite fragile. Small changes broke JMH benchmark execution. Usually helps rebuild project and start again as described above.</p>"},{"location":"development/guides/#load-test","title":"Load test","text":"<p>Runnign JVM should be inspected with some profiller. For profilling is usefull to hae long running task to watch it. Go to project <code>load-test</code>. Following command show all optional parameters:</p> <pre><code>java -jar target/load-test.jar com.coroptis.index.loadtest.Main --help\n</code></pre> <p>Theer are two main supported operations. First is data generating. It's could be usefull to place in java profilling agent. It could look like:</p> <pre><code>java \\\n    -agentpath:/Applications/YourKit-Java-Profiler-2023.9.app/Contents/Resources/bin/mac/libyjpagent.dylib=exceptions=disable,delay=10000,listen=all \\\n    -jar target/load-test.jar com.coroptis.index.loadtest.Main \\\n    --write \\\n    --directory /Volumes/LaCie/test/  \\\n    --count 5_000_000_000 \\\n    --max-number-of-keys-in-cache 5_000_000 \\\n    --max-number-of-keys-in-segment 10_000_000 \\\n    --max-number-of-keys-in-segment-cache 500_000 \\\n    --max-number-of-keys-in-segment-cache-during-flushing 2_000_000 \\\n    --max-number-of-keys-in-segment-index-page 1_000 \\\n    --bloom-filter-index-size-in-bytes 10_000_000 \\\n    --bloom-filter-number-of-hash-functions 2\n</code></pre> <p>It will generate 210 GB of testing data. Furst search test can be performed like this:</p> <pre><code>java \\\n    -agentpath:/Applications/YourKit-Java-Profiler-2023.9.app/Contents/Resources/bin/mac/libyjpagent.dylib=exceptions=disable,delay=10000,listen=all \\\n    -jar target/load-test.jar com.coroptis.index.loadtest.Main \\\n    --search \\\n    --directory /Volumes/LaCie/test/  \\\n    --count 5_000_000_000 \\\n    --max-key 5_000_000_000 \\\n    --max-number-of-keys-in-cache 5_000_000 \\\n    --max-number-of-keys-in-segment 10_000_000 \\\n    --max-number-of-keys-in-segment-cache 500_000 \\\n    --max-number-of-keys-in-segment-cache-during-flushing 2_000_000 \\\n    --max-number-of-keys-in-segment-index-page 1_000 \\\n    --bloom-filter-index-size-in-bytes 10_000_000 \\\n    --bloom-filter-number-of-hash-functions 2\n</code></pre>"},{"location":"development/guides/#development_1","title":"Development","text":"<p>Mockito requires reflective access to non-public parts in a Java module. It could be manually open by passing following parameter as jvm parameter:</p> <pre><code>--add-opens=java.base/java.lang=ALL-UNNAMED\n</code></pre>"},{"location":"development/guides/#how-to-get-segment-disk-size","title":"How to get segment disk size","text":"<p>On apple try:</p> <pre><code>diskutil  info /Volumes/LaCie\n</code></pre>"},{"location":"development/release/","title":"Releasing new version","text":"<p>Simple guide how to make new release.</p>"},{"location":"development/release/#versioning-of-the-project","title":"Versioning of the project","text":"<p>Project use traditional versioning pattern. Version number consist of three numbers separated by dots. For example:</p> <pre><code>0.3.6\n</code></pre> <p>Meaning of number is:</p> <ul> <li><code>0</code> - Major project version, project API could be incompatible between two major versions</li> <li><code>3</code> - Minor project version contains changes in features, performance optimizations and small improvement. Minor versions should be compatible.</li> <li><code>6</code> - Bug fixing project release</li> </ul> <p>There are also snapshot versions with version number <code>0.3.6-SNAPSHOT</code>. Snapshot versions should not by sotred into maven repository.</p>"},{"location":"development/release/#branching-strategy","title":"Branching strategy","text":"<p>We use a simplified GitHub Flow:</p> <ul> <li><code>main</code>: the primary development and release branch. Small changes may be committed directly to <code>main</code>, while larger or experimental features must be developed in a separate branch and merged via pull request.</li> <li>Feature branches: created from <code>main</code> for larger or isolated changes. Use descriptive names like <code>feature/compression</code>, <code>fix/index-scan</code>, etc.</li> </ul> <p>The previous <code>devel</code> branch is no longer used and has been removed.</p>"},{"location":"development/release/#how-to-release-new-version","title":"How to release new version","text":""},{"location":"development/release/#prerequisites","title":"Prerequisites","text":"<p>Adjust settings.xml in <code>~/.m2/settings.xml</code> like this described at github official documentation how to work with github maven repository. Get correct token and it's done.</p>"},{"location":"development/release/#how-to-make-release","title":"How to make release","text":"<p>Release will appear in maven central.</p>"},{"location":"development/release/#release-prerequisities","title":"Release prerequisities:","text":"<ol> <li>File <code>~/m2/settings.xml</code> should contains:</li> </ol> <p><pre><code>&lt;settings&gt;\n    ...\n    &lt;profile&gt;\n      &lt;id&gt;release&lt;/id&gt;\n      &lt;properties&gt;\n        &lt;gpg.executable&gt;gpg&lt;/gpg.executable&gt;\n        &lt;gpg.passphrase&gt;--pgp-password--&lt;/gpg.passphrase&gt;\n      &lt;/properties&gt;      \n    &lt;/profile&gt;\n    ...\n&lt;/settings&gt;\n</code></pre> 2. At central.sonatype.com heve to be account with verified namespace <code>org.hestiastore</code>. From section <code>Acount</code> key and password have to be generated. both should be placed at </p> <pre><code>&lt;settings&gt;\n    ...\n    &lt;servers&gt;\n        &lt;server&gt;\n            &lt;id&gt;central&lt;/id&gt;\n            &lt;username&gt;------&lt;/username&gt;\n            &lt;password&gt;---------------token---------------&lt;/password&gt;\n        &lt;/server&gt;\n    &lt;/servers&gt;\n    ...\n&lt;/settings&gt;\n</code></pre>"},{"location":"development/release/#perform-release","title":"Perform release","text":"<p>Perform the following steps to create a new release:</p> <ol> <li>Checkout the <code>main</code> branch:</li> </ol> <pre><code>git checkout main\n</code></pre> <ol> <li>Set the release version:</li> </ol> <pre><code>mvn versions:set -DnewVersion=0.0.12\ngit commit -am \"release: version 0.0.12\"\n</code></pre> <ol> <li>Tag and push the release:</li> </ol> <pre><code>git tag v0.0.12\ngit push --follow-tags\n</code></pre> <ol> <li>Deploy the release (can be automated via GitHub Actions or done manually):</li> </ol> <pre><code>mvn deploy -P release\n</code></pre> <ol> <li>Bump to next snapshot version:</li> </ol> <pre><code>mvn versions:set -DnewVersion=0.0.13-SNAPSHOT\ngit commit -am \"post-release: bumped to 0.0.13-SNAPSHOT\"\ngit push\n</code></pre> <p>That's it \u2014 the release is live and development can continue.</p>"},{"location":"development/release/#helpfull-commands","title":"Helpfull commands","text":""},{"location":"development/release/#how-to-use-custom-settingsxml-file","title":"How to use custom settings.xml file","text":"<pre><code>mvn --settings ./src/main/settings.xml clean deploy\n</code></pre>"},{"location":"development/release/#how-to-use-set-maven-project-version","title":"How to use set maven project version","text":"<pre><code>mvn versions:set -DnewVersion=1.0.1-SNAPSHOT\n</code></pre>"},{"location":"development/release/#check-dependencies","title":"Check dependencies","text":"<p>try to update dependencies. Check them with:</p> <pre><code>mvn versions:display-dependency-updates\n</code></pre>"}]}