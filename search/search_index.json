{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>HestiaStore is a lightweight, embeddable key\u2011value storage engine optimized for billions of records, designed to run in a single directory with high performance and minimal configuration.</p> <p>Features:</p> <pre><code> \u2022 Pure Java (no native dependencies), easy to embed\n \u2022 200k+ ops/s; predictable I/O with configurable buffering\n \u2022 In\u2011memory or file\u2011backed storage, zero\u2011config setup\n \u2022 Pluggable filters: Snappy compression, CRC32 integrity, magic-number validation\n \u2022 Bloom filter for fast negative lookups (tunable false-positive rate)\n \u2022 Segmented SST structure with sparse index for efficient range scans\n \u2022 Custom key/value types via type descriptors\n \u2022 Single\u2011writer, multi\u2011reader (optional synchronized mode)\n \u2022 Test-friendly MemDirectory for fast, isolated tests\n \u2022 Roadmap: write-ahead logging and advanced compaction\n</code></pre>"},{"location":"#performance-comparison","title":"\ud83d\ude80 Performance Comparison","text":""},{"location":"#benchmark-throughput-opss-higher-is-better","title":"Benchmark throughput (ops/s, higher is better)","text":"<p>The following benchmark compares similar products by writing simple key-value pairs into a map. It includes a 3-minute warm-up to prime caches, followed by a 4-minute measurement period. Tests were performed on a 2024 Mac mini with 16 GB RAM.</p> <p></p> Engine Score [ops/s] Occupied space CPU Usage ChronicleMap 5 954 20.54 GB 7% H2 13 458 8 KB 21% HestiaStoreBasic 208 723 9.71 GB 6% HestiaStoreCompress 197 335 4.97 GB 6% LevelDB 45 263 1.4 GB 17% MapDB 2 946 496 MB 14% RocksDB 305 712 7.74 GB 6% <p>Detailed methodology and full benchmark artifacts are available at benchmark results.</p>"},{"location":"#feature-comparison","title":"\ud83d\udcca Feature Comparison","text":"<p>Architecture &amp; Concurrency</p> Engine Storage/Index Concurrency Background Work HestiaStore Segmented on-disk structure Single-writer, multi-reader (optional synchronized) Periodic segment flush/merge RocksDB LSM tree (leveled/uni) Highly concurrent Compaction + flush threads LevelDB LSM tree Single-writer, multi-reader Compaction MapDB B-tree/H-tree Thread-safe (synchronized) Periodic commits ChronicleMap Off-heap mmap hash map Lock-free/low-lock None (no compaction) H2 B-tree Concurrent (MVCC) Checkpoint/auto-vacuum <p>Durability &amp; Fit</p> Engine Durability Compression Runtime Deps Typical Fit HestiaStore File-backed; commit on close Snappy Pure Java (JAR-only) Embedded KV with simple ops, large datasets RocksDB WAL + checkpoints (optional transactions) Snappy/Zstd/LZ4 Native library High write throughput, low-latency reads LevelDB File-backed; no transactions Snappy JAR-only port/native bindings Lightweight LSM, smaller footprints MapDB File-backed; optional TX None/limited Pure Java (JAR-only) Simple embedded maps/sets ChronicleMap Memory-mapped persistence; no ACID TX None Pure Java (JAR-only) Ultra-low latency shared maps H2 WAL + MVCC transactions Optional Pure Java (JAR-only) SQL + transactional workloads <p>Notes</p> <ul> <li>\u201cConcurrency\u201d describes the general access model; specifics depend on configuration and workload.</li> <li>HestiaStore focuses on predictable file I/O with configurable buffering; WAL/transactions are on the roadmap.</li> </ul>"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>We welcome contributions! Please read our Contributing Guidelines before submitting a pull request.</p>"},{"location":"#documentation","title":"\ud83d\udcda Documentation","text":"<ul> <li>Index architecture</li> <li>Getting started with a quick start and examples</li> <li>Configuration \u2014 properties overview and guidance</li> <li>Logging \u2014 how to set up logging</li> <li>Releases \u2014 versioning and release process</li> </ul>"},{"location":"#installation-and-basic-usage","title":"\ud83d\udce6 Installation and Basic Usage","text":"<p>To include HestiaStore in your Maven project, add the following dependency to your <code>pom.xml</code>:</p> <pre><code>&lt;dependencies&gt;\n  &lt;dependency&gt;\n    &lt;groupId&gt;org.hestiastore.index&lt;/groupId&gt;\n    &lt;artifactId&gt;core&lt;/artifactId&gt;\n    &lt;version&gt;&lt;!--latest verson--&gt;&lt;/version&gt;\n  &lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre> <p>Replace the version number with the latest available from Maven Central org.hestiastore.index:core.</p> <p>Note: HestiaStore requires Java 17 or newer.</p> <p>You can create a new index using the builder pattern as shown below:</p> <pre><code>// Create an in-memory file system abstraction\nDirectory directory = new MemDirectory();\n\n// Prepare index configuration\nIndexConfiguration&lt;String, String&gt; conf = IndexConfiguration\n        .&lt;String, String&gt;builder()//\n        .withKeyClass(String.class)//\n        .withValueClass(String.class)//\n        .withName(\"test_index\") //\n        .build();\n\n// Create a new index\nIndex&lt;String, String&gt; index = Index.&lt;String, String&gt;create(directory, conf);\n\n// Perform basic operations\nindex.put(\"Hello\", \"World\");\n\nString value = index.get(\"Hello\");\nSystem.out.println(\"Value for 'Hello': \" + value);\n\nindex.close();\n</code></pre> <p>For more integration details, see the Getting Started section.</p>"},{"location":"#roadmap","title":"\ud83d\uddfa\ufe0f Roadmap","text":"<p>Planned improvements include:</p> <ul> <li>Enhance Javadoc documentation</li> <li>Implement data consistency verification using checksums</li> <li>Complete the implementation of Write\u2011Ahead Logging (WAL)</li> </ul> <p>For detailed tasks and progress, see the GitHub Issues page.</p>"},{"location":"#need-help-or-have-questions","title":"\u2753 Need Help or Have Questions?","text":"<p>If you encounter a bug, have a feature request, or need help using HestiaStore, please create an issue.</p>"},{"location":"CHANGELOG/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog.</p>"},{"location":"CHANGELOG/#005","title":"0.0.5","text":""},{"location":"CHANGELOG/#added","title":"\u2728 Added","text":"<ul> <li>Data blocks were introduced and the on-disk storage format was significantly improved.</li> <li>All disk writes now use a temporary file followed by an atomic rename; all streams are correctly closed.</li> <li>Data storage is configurable via the application configuration.</li> <li>Data in chunks and data blocks are validated using a magic number and CRC32.</li> <li>Added support for Snappy compression.</li> </ul>"},{"location":"CHANGELOG/#004","title":"0.0.4","text":""},{"location":"CHANGELOG/#added_1","title":"\u2728 Added","text":"<ul> <li>Add recovery support to rebuild indexes after failures. (#22)</li> <li>Introduce pages for segment-based indexing. (#31)</li> <li>Create <code>Directory</code> implementation using <code>java.nio</code>. (#50)</li> <li>Add a performance comparison framework for benchmark testing. (#60)</li> <li>Add integration tests for deletion and graceful degradation. (#76, #63)</li> <li>Add a test class for long-running index operations. (#49)</li> </ul>"},{"location":"CHANGELOG/#changed","title":"\ud83d\udd27 Changed","text":"<ul> <li>Improve design of the <code>sorteddatafile</code> package for better modularity. (#59)</li> <li>Enhance index configuration validation and parameter consistency. (#81)</li> <li>Introduce limits on the number of delta files to prevent unbounded growth. (#75)</li> </ul>"},{"location":"CODE_OF_CONDUCT/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"\ud83e\udd1d Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"\ud83c\udf1f Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others\u2019 private information, such as a physical or email address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#our-responsibilities","title":"\ud83d\udccb Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement","title":"\ud83d\udee1\ufe0f Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team via project issue. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.</p> <p>Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.</p>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"\ud83d\udcce Attribution","text":"<p>This Code of Conduct is adapted from the [Contributor Covenant][homepage], version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by the Citizen Code of Conduct.</p> <p>For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq.</p> <p>I\u2019ll personally make every effort to answer your questions and explain anything that\u2019s unclear. We are committed to discussing any feedback or questions you may have and will explain everything in detail to ensure transparency and understanding.</p>"},{"location":"CONTRIBUTING/","title":"Contributing to HestiaStore","text":"<p>Thank you for your interest in contributing to HestiaStore! We're excited to welcome your ideas, improvements, and bug fixes. Please follow the guidelines below to ensure a smooth and productive collaboration.</p>"},{"location":"CONTRIBUTING/#before-you-start","title":"\ud83e\udded Before You Start","text":"<p>Please make sure there is an existing issue or create a new one that describes your intended change or feature. This helps us track and discuss proposals before any code is written.</p>"},{"location":"CONTRIBUTING/#code-style","title":"\ud83e\uddd1\u200d\ud83d\udcbb Code Style","text":"<p>We follow a consistent Java coding style defined by the Eclipse formatter settings in <code>./eclipse-formatter.xml</code>. Please configure your IDE to use this formatter to keep the codebase consistent.</p>"},{"location":"CONTRIBUTING/#code-quality-checks","title":"\ud83e\uddea Code Quality Checks","text":"<p>Before submitting your code, please verify the following:</p> <ul> <li>\u2705 Run Site Checks   Execute <code>mvn clean site</code> to generate the project site and perform static analysis. This will highlight issues reported by:</li> <li>PMD</li> <li>Checkstyle</li> <li> <p>SpotBugs (formerly FindBugs)   Please ensure your changes do not introduce new warnings or violations.</p> </li> <li> <p>\u2705 Test Coverage   All new code should be covered by unit tests. We use JUnit. Run tests and verify that your code is being exercised by checking the line coverage in the site reports.</p> </li> <li> <p>\u2705 Javadoc Comments   Public methods, classes, and significant internal logic should be documented using Javadoc. Clear documentation helps others understand and maintain the project.</p> </li> </ul>"},{"location":"CONTRIBUTING/#commit-and-submit","title":"\ud83d\udee0 Commit and Submit","text":"<ol> <li>Make your changes in a separate branch.</li> <li>Push your branch to your fork or the main repo (if you have access).</li> <li>Open a Pull Request with a clear title and description.</li> <li>Link to the related issue or ticket.</li> </ol>"},{"location":"CONTRIBUTING/#review-process","title":"\u23f3 Review Process","text":"<p>Once submitted, your PR will be reviewed by a maintainer. We may request changes or ask clarifying questions. Please be patient \u2014 reviews are important to keep the project healthy.</p>"},{"location":"CONTRIBUTING/#thanks","title":"\ud83d\ude4c Thanks","text":"<p>We appreciate your contribution, whether it's code, documentation, or ideas. Your support makes HestiaStore better!</p> <p>\ud83d\udcac For questions, feel free to open a GitHub Issue.</p>"},{"location":"SECURITY/","title":"HestiaStore Security","text":"<p>Security and quality are important considerations in the HestiaStore project. While HestiaStore is a library (not a network-exposed service), several tools are in place to monitor and improve code and dependency safety.</p>"},{"location":"SECURITY/#dependency-scanning","title":"\ud83e\uddea Dependency Scanning","text":"<p>HestiaStore uses the OWASP Dependency-Check Maven plugin to automatically scan project dependencies for known vulnerabilities. The scan is performed during the Maven <code>verify</code> phase. This helps detect issues in third-party libraries such as outdated or vulnerable versions of common libraries.</p> <p>The OWASP dependency report is also included in the Maven Site documentation.</p>"},{"location":"SECURITY/#data-storage-security","title":"\ud83d\udcbe Data Storage Security","text":"<p>Currently, HestiaStore does not support a persistent, remote or encrypted storage backend. All data is stored in the local file system or memory, depending on the <code>Directory</code> implementation (e.g. <code>FsDirectory</code> or <code>MemDirectory</code>). Support for more advanced persistent stores with security features like encryption may be added in the future.</p>"},{"location":"SECURITY/#static-code-analysis","title":"\ud83d\udd75\ufe0f Static Code Analysis","text":"<p>HestiaStore uses the following tools to enforce code quality and detect potential bugs:</p> <ul> <li>PMD: Checks for common coding errors, best practices violations, and potential bugs.</li> <li>SpotBugs (formerly FindBugs): Performs bytecode-level bug detection for possible concurrency issues, null pointer dereferences, etc.</li> </ul> <p>Both reports are available through the Maven Site (<code>mvn site</code>).</p>"},{"location":"SECURITY/#testing-and-coverage","title":"\u2705 Testing and Coverage","text":"<p>The project includes a comprehensive suite of unit tests. Test coverage is measured using JaCoCo, and the coverage report is also published as part of the Maven Site.</p> <pre><code>mvn clean verify site\n</code></pre> <p>This will generate the full set of reports under <code>target/site/</code>.</p>"},{"location":"SECURITY/#threat-model","title":"\ud83d\udd10 Threat Model","text":"<p>HestiaStore is designed to run as a component within a trusted local application. It does not expose network interfaces or provide internal access control mechanisms. As such, it assumes that:</p> <ul> <li>The host operating environment is trusted.</li> <li>Filesystem access is managed by the application or OS.</li> <li>Inputs to the library are trusted or validated upstream.</li> </ul>"},{"location":"SECURITY/#known-risks","title":"\u26a0\ufe0f Known Risks","text":"Threat Mitigated? Notes Malicious input data \u274c No input sanitization is performed Unauthorized file access \u274c No access control; relies on OS permissions File corruption \ud83d\udeab Partial protection through optional WAL Memory data leakage \u274c JVM memory is not encrypted or zeroed Index inconsistency \u26a0\ufe0f Recovery possible using <code>checkAndRepairConsistency()</code>"},{"location":"SECURITY/#trust-boundaries","title":"\ud83d\udee1\ufe0f Trust Boundaries","text":"<p>HestiaStore does not define security boundaries within its API. Instead, it assumes that:</p> <ul> <li>The file system used by <code>FsDirectory</code> is controlled by the same principal as the application.</li> <li>Memory content is considered volatile and not protected against memory inspection.</li> <li>The user is responsible for isolating the library appropriately in containerized or multi-tenant environments.</li> </ul>"},{"location":"SECURITY/#data-integrity","title":"\ud83d\udd0d Data Integrity","text":"<p>HestiaStore provides limited protections:</p> <ul> <li>Optional Write-Ahead Logging (WAL) ensures durability between flushes.</li> <li>Manual compaction and <code>checkAndRepairConsistency()</code> assist in recovery from logical inconsistencies.</li> <li>No built-in checksums or MACs are currently used.</li> </ul>"},{"location":"SECURITY/#encryption","title":"\ud83d\udd12 Encryption","text":"<p>HestiaStore does not implement:</p> <ul> <li>Encryption at rest</li> <li>Encryption in memory</li> <li>Encrypted WAL or segment files</li> </ul> <p>Users requiring data confidentiality should enable full-disk encryption or isolate the storage backend appropriately.</p>"},{"location":"SECURITY/#denial-of-service-considerations","title":"\ud83c\udfd7\ufe0f Denial of Service Considerations","text":"<p>While HestiaStore is efficient, certain usage patterns may degrade system performance:</p> <ul> <li>Inserting excessive data without flushing may exhaust memory.</li> <li>Large segment files may incur slow read or compaction times.</li> <li><code>withThreadSafe(true)</code> may incur additional locking overhead under heavy concurrency.</li> </ul>"},{"location":"SECURITY/#security-responsibilities-of-integrators","title":"\ud83d\udc77 Security Responsibilities of Integrators","text":"<p>Users embedding HestiaStore must take responsibility for:</p> <ul> <li>Validating inputs</li> <li>Managing access to the directory path</li> <li>Applying memory and disk usage quotas externally</li> <li>Protecting against unauthorized runtime access</li> </ul>"},{"location":"SECURITY/#future-work","title":"\ud83d\udd27 Future Work","text":"<p>Planned or considered improvements include:</p> <ul> <li>Optional encryption of segment data</li> <li>Checksumming of stored values</li> <li>Sandboxed key/value type descriptors</li> </ul>"},{"location":"SECURITY/#summary","title":"\ud83d\udccb Summary","text":"<ul> <li>\u2705 Vulnerability scanning via OWASP Dependency Check</li> <li>\u2705 Static analysis via PMD and SpotBugs</li> <li>\u2705 Unit tests with coverage reporting via JaCoCo</li> <li>\u23f3 Persistent encrypted storage is not yet supported</li> <li>\u2705 Basic threat model documented</li> <li>\u26a0\ufe0f Assumes trusted host environment (no access control or encryption)</li> <li>\ud83d\udea7 Future improvements under consideration (checksums, encryption)</li> </ul> <p>If you encounter any problems, discover vulnerabilities, or have questions, please report them by opening an issue in the project's GitHub repository.</p>"},{"location":"alternatives/","title":"Alternatives","text":"<p>HestiaStore is one of many available solutions for key-value storage. When selecting the right tool, it's important to consider which one best fits your needs. Here are some key evaluation criteria:</p> <ul> <li>\ud83d\udd01 Transactional Support</li> <li>\ud83e\uddea ACID Compliance</li> <li>\u2601\ufe0f Cloud Availability</li> <li>\u26a1 Performance</li> <li>\ud83d\udee0\ufe0f Error Handling</li> <li>\ud83d\udcda API Completeness ...</li> </ul> <p>Below are a few notable alternatives (not an exhaustive list):</p>"},{"location":"alternatives/#mapdb","title":"\ud83d\uddfa\ufe0f MapDB","text":"<p>Homepage / GitHub</p> <p>MapDB focuses on replacing <code>java.util.Map</code> with a disk-backed map structure. While powerful, its recent versions have limited disk persistence support and performance may be slower for some use cases.</p>"},{"location":"alternatives/#h2-mvstore","title":"\ud83d\uddc3\ufe0f H2 MVStore","text":"<p>Homepage</p> <p>MVStore is the underlying storage engine for the H2 database. It features a friendly API, support for transactions, and generally good performance. It is well-suited for embedded systems and relational data scenarios.</p>"},{"location":"alternatives/#chronicle-map","title":"\ud83d\udcd8 Chronicle Map","text":"<p>Homepage</p> <p>Chronicle Map offers low-latency, off-heap key-value storage with support for huge datasets. It is especially suitable for high-performance and low-GC scenarios. Disk persistence is supported, though the primary target is memory-mapped data sharing.</p>"},{"location":"alternatives/#rocksdb","title":"\ud83e\udea8 RocksDB","text":"<p>Homepage / GitHub</p> <p>RocksDB is a mature, high-performance embedded key-value store developed by Facebook. While it is written in C++, a Java binding is available. It supports compression, compaction, snapshots, and many tuning options.</p>"},{"location":"alternatives/#babudb","title":"\ud83d\udc18 BabuDB","text":"<p>Homepage</p> <p>BabuDB is a log-structured, non-relational key-value store optimized for write performance and reliability. It's less widely used today but offers interesting architectural choices like write-ahead logging and on-disk persistence.</p>"},{"location":"benchmark-results/","title":"HestiaStore Benchmark Results","text":""},{"location":"benchmark-results/#test-conditions","title":"Test Conditions","text":"<ul> <li>Every benchmark in the plain-load suite runs inside the same controlled JVM environment with identical JVM flags and hardware resources. Runs start by wiping the working directory supplied through the <code>dir</code> system property, so each trial writes into a fresh, empty location.</li> <li>Execution stays single-threaded from warm-up through measurement. The test focuses purely on how quickly one writer can push key/value entries into the storage engine without any coordination overhead from additional threads.</li> <li>Warm-up phases fill the database as aggressively as possible for several 20-second stretches. This stage is meant to trigger JIT compilation, populate caches, and let LevelDB settle into steady-state behaviour before any numbers are recorded.</li> <li>Measurement phases repeat the same single-threaded write loop. Throughput is observed over multiple 20-second intervals to capture stable, sustained insert performance rather than a burst.</li> <li>Each write operation uses a deterministic pseudo-random long (seed <code>324432L</code>) to generate a unique hash string via <code>HashDataProvider</code>. The payload is the constant text <code>\"opice skace po stromech\"</code>, so variability comes exclusively from the changing keys.</li> <li>After measurements complete, the map is closed and the directory remains available for inspection. The log records how many keys were created, providing a quick sanity check that the run processed the expected volume.</li> <li>Test was performed at Mac mini 2024, 16 GB, macOS 15.6.1 (24G90).</li> </ul>"},{"location":"benchmark-results/#benchmark-results","title":"Benchmark Results","text":"Engine Score [ops/s] ScoreError Confidence Interval [ops/s] Occupied space CPU Usage ChronicleMap 5 954 1 765 4 189 .. 7 719 20.54 GB 7% H2 13 458 5 144 8 314 .. 18 601 8 KB 21% HestiaStoreBasic 208 723 123 398 85 325 .. 332 122 9.71 GB 6% HestiaStoreCompress 197 335 110 268 87 068 .. 307 603 4.97 GB 6% LevelDB 45 263 10 913 34 350 .. 56 176 1.4 GB 17% MapDB 2 946 326 2 620 .. 3 272 496 MB 14% RocksDB 305 712 78 929 226 783 .. 384 641 7.74 GB 6% <p>meaning of columns:</p> <ul> <li>Engine: name of the benchmarked engine (as derived from the JSON filename)</li> <li>Score [ops/s]: number of operations per second (higher is better)</li> <li>ScoreError: error margin of the score (lower is better). It's computed as <code>z * (stdev / sqrt(n)) where</code></li> <li><code>z</code> is the z-score for the desired confidence level (1.96 for 95%)</li> <li><code>stdev</code> is the standard deviation of the measurements</li> <li><code>n</code> is the number of measurements</li> <li>Confidence Interval: 95% confidence interval of the score (lower and upper bound). This means that the true mean is likely between this interval of ops/sec. Negative values are possible if the error margin is larger than the score itself.</li> <li>Occupied space : amount of disk space occupied by the engine's data structures (lower is better). It is measured after flushing last data to disk.</li> <li>CPU Usage: average CPU usage during the benchmark (lower is better). Please note, that it includes all system processes, not only the benchmarked engine.</li> </ul>"},{"location":"benchmark-results/#raw-json-files","title":"Raw JSON Files","text":""},{"location":"benchmark-results/#results-chroniclemap-myjson","title":"results-ChronicleMap-my.json","text":"<pre><code>{\n  \"totalDirectorySize\" : 22049472512,\n  \"fileCount\" : 1,\n  \"usedMemoryBytes\" : 27947104,\n  \"cpuBefore\" : 603274000,\n  \"cpuAfter\" : 1097938000,\n  \"startTime\" : 261108533575583,\n  \"endTime\" : 261814614016416,\n  \"cpuUsage\" : 0.07005774008077877\n}\n</code></pre>"},{"location":"benchmark-results/#results-chroniclemapjson","title":"results-ChronicleMap.json","text":"<pre><code>[\n    {\n        \"jmhVersion\" : \"1.37\",\n        \"benchmark\" : \"org.hestiastore.index.benchmark.plainload.TestChronicleMap.write\",\n        \"mode\" : \"thrpt\",\n        \"threads\" : 1,\n        \"forks\" : 1,\n        \"jvm\" : \"/opt/homebrew/Cellar/openjdk@21/21.0.7/libexec/openjdk.jdk/Contents/Home/bin/java\",\n        \"jvmArgs\" : [\n            \"-Xmx10000m\",\n            \"--add-opens=java.base/java.lang=ALL-UNNAMED\",\n            \"--add-opens=java.base/java.lang.reflect=ALL-UNNAMED\",\n            \"--add-opens=java.base/java.io=ALL-UNNAMED\",\n            \"--add-opens=java.base/java.nio=ALL-UNNAMED\",\n            \"--add-opens=java.base/sun.nio.ch=ALL-UNNAMED\",\n            \"--add-opens=jdk.compiler/com.sun.tools.javac=ALL-UNNAMED\",\n            \"--add-opens=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED\",\n            \"--add-opens=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED\",\n            \"--add-opens=jdk.compiler/com.sun.tools.javac.comp=ALL-UNNAMED\",\n            \"--add-opens=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED\",\n            \"--add-opens=jdk.compiler/com.sun.tools.javac.main=ALL-UNNAMED\",\n            \"--add-opens=jdk.compiler/com.sun.tools.javac.model=ALL-UNNAMED\",\n            \"--add-opens=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED\",\n            \"--add-opens=jdk.compiler/com.sun.tools.javac.processing=ALL-UNNAMED\",\n            \"--add-opens=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED\",\n            \"-Ddir=/Volumes/ponrava/test-index\",\n            \"-Dengine=ChronicleMap\"\n        ],\n        \"jdkVersion\" : \"21.0.7\",\n        \"vmName\" : \"OpenJDK 64-Bit Server VM\",\n        \"vmVersion\" : \"21.0.7\",\n        \"warmupIterations\" : 10,\n        \"warmupTime\" : \"20 s\",\n        \"warmupBatchSize\" : 1,\n        \"measurementIterations\" : 25,\n        \"measurementTime\" : \"20 s\",\n        \"measurementBatchSize\" : 1,\n        \"primaryMetric\" : {\n            \"score\" : 5954.200373600311,\n            \"scoreError\" : 1764.90521298729,\n            \"scoreConfidence\" : [\n                4189.295160613021,\n                7719.105586587601\n            ],\n            \"scorePercentiles\" : {\n                \"0.0\" : 3329.640674916557,\n                \"50.0\" : 5243.630014833653,\n                \"90.0\" : 10595.405308112338,\n                \"95.0\" : 12253.872048619854,\n                \"99.0\" : 12744.707905617659,\n                \"99.9\" : 12744.707905617659,\n                \"99.99\" : 12744.707905617659,\n                \"99.999\" : 12744.707905617659,\n                \"99.9999\" : 12744.707905617659,\n                \"100.0\" : 12744.707905617659\n            },\n            \"scoreUnit\" : \"ops/s\",\n            \"rawData\" : [\n                [\n                    11108.58838229165,\n                    12744.707905617659,\n                    10253.283258659461,\n                    7641.776148398347,\n                    7065.625130993228,\n                    6245.862123216896,\n                    5726.337056869982,\n                    5546.963290190697,\n                    5312.460633150494,\n                    5243.630014833653,\n                    5127.273627636177,\n                    4443.333421250085,\n                    4570.51338982323,\n                    4905.02077335985,\n                    5196.530108141268,\n                    3329.640674916557,\n                    3829.198465291546,\n                    7600.50765102385,\n                    6131.287347339458,\n                    5543.996756565399,\n                    4995.077322180827,\n                    4772.012372724426,\n                    3916.673020709464,\n                    3514.748215845972,\n                    4089.96224897762\n                ]\n            ]\n        },\n        \"secondaryMetrics\" : {\n        }\n    }\n]\n</code></pre>"},{"location":"benchmark-results/#results-h2-myjson","title":"results-H2-my.json","text":"<pre><code>{\n  \"totalDirectorySize\" : 8192,\n  \"fileCount\" : 1,\n  \"usedMemoryBytes\" : 27133320,\n  \"cpuBefore\" : 1035200000,\n  \"cpuAfter\" : 2479448000,\n  \"startTime\" : 258786636432958,\n  \"endTime\" : 259488720650875,\n  \"cpuUsage\" : 0.2057086547657931\n}\n</code></pre>"},{"location":"benchmark-results/#results-h2json","title":"results-H2.json","text":"<pre><code>[\n    {\n        \"jmhVersion\" : \"1.37\",\n        \"benchmark\" : \"org.hestiastore.index.benchmark.plainload.TestH2.write\",\n        \"mode\" : \"thrpt\",\n        \"threads\" : 1,\n        \"forks\" : 1,\n        \"jvm\" : \"/opt/homebrew/Cellar/openjdk@21/21.0.7/libexec/openjdk.jdk/Contents/Home/bin/java\",\n        \"jvmArgs\" : [\n            \"-Xmx10000m\",\n            \"-Ddir=/Volumes/ponrava/test-index\",\n            \"-Dengine=H2\"\n        ],\n        \"jdkVersion\" : \"21.0.7\",\n        \"vmName\" : \"OpenJDK 64-Bit Server VM\",\n        \"vmVersion\" : \"21.0.7\",\n        \"warmupIterations\" : 10,\n        \"warmupTime\" : \"20 s\",\n        \"warmupBatchSize\" : 1,\n        \"measurementIterations\" : 25,\n        \"measurementTime\" : \"20 s\",\n        \"measurementBatchSize\" : 1,\n        \"primaryMetric\" : {\n            \"score\" : 13457.521378452284,\n            \"scoreError\" : 5143.803121401257,\n            \"scoreConfidence\" : [\n                8313.718257051027,\n                18601.32449985354\n            ],\n            \"scorePercentiles\" : {\n                \"0.0\" : 4492.791786534924,\n                \"50.0\" : 13209.02178518997,\n                \"90.0\" : 21853.77922605105,\n                \"95.0\" : 29631.650534341064,\n                \"99.0\" : 32749.29402436372,\n                \"99.9\" : 32749.29402436372,\n                \"99.99\" : 32749.29402436372,\n                \"99.999\" : 32749.29402436372,\n                \"99.9999\" : 32749.29402436372,\n                \"100.0\" : 32749.29402436372\n            },\n            \"scoreUnit\" : \"ops/s\",\n            \"rawData\" : [\n                [\n                    12623.654285480005,\n                    11839.343622462286,\n                    14436.728477425342,\n                    13633.043439408131,\n                    16157.467112454447,\n                    6412.401044547184,\n                    6265.687494095522,\n                    18612.922946912684,\n                    16219.969068239285,\n                    12831.893972457165,\n                    18859.80952879762,\n                    4813.230127324451,\n                    13209.02178518997,\n                    22357.14905762156,\n                    18073.648245485118,\n                    8538.249998991463,\n                    32749.29402436372,\n                    18767.680908037615,\n                    21518.199338337377,\n                    8642.521511716302,\n                    17435.121051959966,\n                    7154.46408403396,\n                    4670.397715531453,\n                    4492.791786534924,\n                    6123.3438338994565\n                ]\n            ]\n        },\n        \"secondaryMetrics\" : {\n        }\n    }\n]\n</code></pre>"},{"location":"benchmark-results/#results-hestiastorebasic-myjson","title":"results-HestiaStoreBasic-my.json","text":"<pre><code>{\n  \"totalDirectorySize\" : 10421104485,\n  \"fileCount\" : 202,\n  \"usedMemoryBytes\" : 29532080,\n  \"cpuBefore\" : 630093000,\n  \"cpuAfter\" : 1321420000,\n  \"startTime\" : 251981038188791,\n  \"endTime\" : 253079760397708,\n  \"cpuUsage\" : 0.06292099990237153\n}\n</code></pre>"},{"location":"benchmark-results/#results-hestiastorebasicjson","title":"results-HestiaStoreBasic.json","text":"<pre><code>[\n    {\n        \"jmhVersion\" : \"1.37\",\n        \"benchmark\" : \"org.hestiastore.index.benchmark.plainload.TestHestiaStoreBasic.write\",\n        \"mode\" : \"thrpt\",\n        \"threads\" : 1,\n        \"forks\" : 1,\n        \"jvm\" : \"/opt/homebrew/Cellar/openjdk@21/21.0.7/libexec/openjdk.jdk/Contents/Home/bin/java\",\n        \"jvmArgs\" : [\n            \"-Ddir=/Volumes/ponrava/test-index\",\n            \"-Dengine=HestiaStoreBasic\"\n        ],\n        \"jdkVersion\" : \"21.0.7\",\n        \"vmName\" : \"OpenJDK 64-Bit Server VM\",\n        \"vmVersion\" : \"21.0.7\",\n        \"warmupIterations\" : 10,\n        \"warmupTime\" : \"20 s\",\n        \"warmupBatchSize\" : 1,\n        \"measurementIterations\" : 25,\n        \"measurementTime\" : \"20 s\",\n        \"measurementBatchSize\" : 1,\n        \"primaryMetric\" : {\n            \"score\" : 208723.46372734453,\n            \"scoreError\" : 123398.4009790847,\n            \"scoreConfidence\" : [\n                85325.06274825982,\n                332121.86470642925\n            ],\n            \"scorePercentiles\" : {\n                \"0.0\" : 554.7618862826042,\n                \"50.0\" : 162041.0809319436,\n                \"90.0\" : 470075.70756668044,\n                \"95.0\" : 492127.1980588706,\n                \"99.0\" : 499252.60276788153,\n                \"99.9\" : 499252.60276788153,\n                \"99.99\" : 499252.60276788153,\n                \"99.999\" : 499252.60276788153,\n                \"99.9999\" : 499252.60276788153,\n                \"100.0\" : 499252.60276788153\n            },\n            \"scoreUnit\" : \"ops/s\",\n            \"rawData\" : [\n                [\n                    192122.76396490858,\n                    176314.5105152991,\n                    172106.25195735498,\n                    162041.0809319436,\n                    132489.04192779973,\n                    107779.73836212876,\n                    499252.60276788153,\n                    554.7618862826042,\n                    475501.2537378453,\n                    17154.979375749186,\n                    466458.67678590387,\n                    21687.044020994686,\n                    405378.4078260152,\n                    56166.83893309033,\n                    403344.39251664525,\n                    51301.04051122623,\n                    352834.9371019776,\n                    74215.05428872978,\n                    301901.0548791414,\n                    90049.73992580615,\n                    142494.71288749005,\n                    52679.915185932994,\n                    393918.62679864746,\n                    88953.57519155115,\n                    381385.5909032691\n                ]\n            ]\n        },\n        \"secondaryMetrics\" : {\n        }\n    }\n]\n</code></pre>"},{"location":"benchmark-results/#results-hestiastorecompress-myjson","title":"results-HestiaStoreCompress-my.json","text":"<pre><code>{\n  \"totalDirectorySize\" : 5333604997,\n  \"fileCount\" : 138,\n  \"usedMemoryBytes\" : 29625800,\n  \"cpuBefore\" : 588216000,\n  \"cpuAfter\" : 1276584000,\n  \"startTime\" : 253080135943875,\n  \"endTime\" : 254157304657416,\n  \"cpuUsage\" : 0.06390530947906137\n}\n</code></pre>"},{"location":"benchmark-results/#results-hestiastorecompressjson","title":"results-HestiaStoreCompress.json","text":"<pre><code>[\n    {\n        \"jmhVersion\" : \"1.37\",\n        \"benchmark\" : \"org.hestiastore.index.benchmark.plainload.TestHestiaStoreCompress.write\",\n        \"mode\" : \"thrpt\",\n        \"threads\" : 1,\n        \"forks\" : 1,\n        \"jvm\" : \"/opt/homebrew/Cellar/openjdk@21/21.0.7/libexec/openjdk.jdk/Contents/Home/bin/java\",\n        \"jvmArgs\" : [\n            \"-Ddir=/Volumes/ponrava/test-index\",\n            \"-Dengine=HestiaStoreCompress\"\n        ],\n        \"jdkVersion\" : \"21.0.7\",\n        \"vmName\" : \"OpenJDK 64-Bit Server VM\",\n        \"vmVersion\" : \"21.0.7\",\n        \"warmupIterations\" : 10,\n        \"warmupTime\" : \"20 s\",\n        \"warmupBatchSize\" : 1,\n        \"measurementIterations\" : 25,\n        \"measurementTime\" : \"20 s\",\n        \"measurementBatchSize\" : 1,\n        \"primaryMetric\" : {\n            \"score\" : 197335.45368451648,\n            \"scoreError\" : 110267.72261413459,\n            \"scoreConfidence\" : [\n                87067.7310703819,\n                307603.1762986511\n            ],\n            \"scorePercentiles\" : {\n                \"0.0\" : 19837.659319775263,\n                \"50.0\" : 159121.5187040372,\n                \"90.0\" : 446727.6608323127,\n                \"95.0\" : 471450.60560908867,\n                \"99.0\" : 471589.3418364573,\n                \"99.9\" : 471589.3418364573,\n                \"99.99\" : 471589.3418364573,\n                \"99.999\" : 471589.3418364573,\n                \"99.9999\" : 471589.3418364573,\n                \"100.0\" : 471589.3418364573\n            },\n            \"scoreUnit\" : \"ops/s\",\n            \"rawData\" : [\n                [\n                    189366.44800340827,\n                    182001.5193574798,\n                    170531.69717638704,\n                    162364.86104533979,\n                    159121.5187040372,\n                    125406.93654261202,\n                    106902.16819859736,\n                    471589.3418364573,\n                    20815.987134208288,\n                    471126.8877452286,\n                    19837.659319775263,\n                    430461.50955703534,\n                    41763.59810876514,\n                    373047.7099334711,\n                    70686.69226237234,\n                    352984.1656029356,\n                    76161.28448556861,\n                    331142.4783053942,\n                    83170.7709646383,\n                    300736.0137753263,\n                    91106.90765487481,\n                    153934.20182376896,\n                    59495.64115310968,\n                    398898.761738379,\n                    90731.58168374155\n                ]\n            ]\n        },\n        \"secondaryMetrics\" : {\n        }\n    }\n]\n</code></pre>"},{"location":"benchmark-results/#results-leveldb-myjson","title":"results-LevelDB-my.json","text":"<pre><code>{\n    \"totalDirectorySize\": 1508330468,\n    \"fileCount\": 754,\n    \"usedMemoryBytes\": 27954256,\n    \"cpuBefore\": 1001444000,\n    \"cpuAfter\": 2178345000,\n    \"startTime\": 260193098308000,\n    \"endTime\": 260895356813250,\n    \"cpuUsage\": 0.1675880023099229\n}\n</code></pre>"},{"location":"benchmark-results/#results-leveldbjson","title":"results-LevelDB.json","text":"<pre><code>[\n    {\n        \"jmhVersion\" : \"1.37\",\n        \"benchmark\" : \"org.hestiastore.index.benchmark.plainload.TestLevelDB.write\",\n        \"mode\" : \"thrpt\",\n        \"threads\" : 1,\n        \"forks\" : 1,\n        \"jvm\" : \"/opt/homebrew/Cellar/openjdk@21/21.0.7/libexec/openjdk.jdk/Contents/Home/bin/java\",\n        \"jvmArgs\" : [\n            \"-Xmx10000m\",\n            \"-Ddir=/Volumes/ponrava/test-index\",\n            \"-Dengine=LevelDB\"\n        ],\n        \"jdkVersion\" : \"21.0.7\",\n        \"vmName\" : \"OpenJDK 64-Bit Server VM\",\n        \"vmVersion\" : \"21.0.7\",\n        \"warmupIterations\" : 10,\n        \"warmupTime\" : \"20 s\",\n        \"warmupBatchSize\" : 1,\n        \"measurementIterations\" : 25,\n        \"measurementTime\" : \"20 s\",\n        \"measurementBatchSize\" : 1,\n        \"primaryMetric\" : {\n            \"score\" : 45262.57575204393,\n            \"scoreError\" : 10913.06838787145,\n            \"scoreConfidence\" : [\n                34349.50736417248,\n                56175.64413991538\n            ],\n            \"scorePercentiles\" : {\n                \"0.0\" : 29965.68796327744,\n                \"50.0\" : 44015.87124729542,\n                \"90.0\" : 59895.29706634639,\n                \"95.0\" : 73862.46532443774,\n                \"99.0\" : 79758.10180257274,\n                \"99.9\" : 79758.10180257274,\n                \"99.99\" : 79758.10180257274,\n                \"99.999\" : 79758.10180257274,\n                \"99.9999\" : 79758.10180257274,\n                \"100.0\" : 79758.10180257274\n            },\n            \"scoreUnit\" : \"ops/s\",\n            \"rawData\" : [\n                [\n                    79758.10180257274,\n                    39978.85200469439,\n                    59754.841638050995,\n                    30051.495747236888,\n                    59710.167696545956,\n                    30759.864807986865,\n                    59261.071048612,\n                    30156.92824167015,\n                    45828.62436018362,\n                    44015.87124729542,\n                    30051.946454605757,\n                    42438.257643466684,\n                    47017.87854596809,\n                    30308.896587398805,\n                    59599.16125957037,\n                    29965.68796327744,\n                    30159.1527061617,\n                    59564.58477647708,\n                    30361.845682382078,\n                    30347.55964289471,\n                    59253.07772711731,\n                    32183.0951788089,\n                    57862.32461600187,\n                    60105.98020878948,\n                    53069.126213328724\n                ]\n            ]\n        },\n        \"secondaryMetrics\" : {\n        }\n    }\n]\n</code></pre>"},{"location":"benchmark-results/#results-mapdb-myjson","title":"results-MapDB-my.json","text":"<pre><code>{\n  \"totalDirectorySize\" : 520093696,\n  \"fileCount\" : 1,\n  \"usedMemoryBytes\" : 27726856,\n  \"cpuBefore\" : 1110727000,\n  \"cpuAfter\" : 2088963000,\n  \"startTime\" : 259489732026041,\n  \"endTime\" : 260192350201750,\n  \"cpuUsage\" : 0.13922725511802747\n}\n</code></pre>"},{"location":"benchmark-results/#results-mapdbjson","title":"results-MapDB.json","text":"<pre><code>[\n    {\n        \"jmhVersion\" : \"1.37\",\n        \"benchmark\" : \"org.hestiastore.index.benchmark.plainload.TestMapDB.write\",\n        \"mode\" : \"thrpt\",\n        \"threads\" : 1,\n        \"forks\" : 1,\n        \"jvm\" : \"/opt/homebrew/Cellar/openjdk@21/21.0.7/libexec/openjdk.jdk/Contents/Home/bin/java\",\n        \"jvmArgs\" : [\n            \"-Xmx10000m\",\n            \"-Ddir=/Volumes/ponrava/test-index\",\n            \"-Dengine=MapDB\"\n        ],\n        \"jdkVersion\" : \"21.0.7\",\n        \"vmName\" : \"OpenJDK 64-Bit Server VM\",\n        \"vmVersion\" : \"21.0.7\",\n        \"warmupIterations\" : 10,\n        \"warmupTime\" : \"20 s\",\n        \"warmupBatchSize\" : 1,\n        \"measurementIterations\" : 25,\n        \"measurementTime\" : \"20 s\",\n        \"measurementBatchSize\" : 1,\n        \"primaryMetric\" : {\n            \"score\" : 2945.9818242698652,\n            \"scoreError\" : 325.59501594188,\n            \"scoreConfidence\" : [\n                2620.3868083279854,\n                3271.576840211745\n            ],\n            \"scorePercentiles\" : {\n                \"0.0\" : 2272.884921159144,\n                \"50.0\" : 2903.932835903283,\n                \"90.0\" : 3477.3894675973625,\n                \"95.0\" : 3980.5774803791674,\n                \"99.0\" : 4191.114455891415,\n                \"99.9\" : 4191.114455891415,\n                \"99.99\" : 4191.114455891415,\n                \"99.999\" : 4191.114455891415,\n                \"99.9999\" : 4191.114455891415,\n                \"100.0\" : 4191.114455891415\n            },\n            \"scoreUnit\" : \"ops/s\",\n            \"rawData\" : [\n                [\n                    3355.129200069919,\n                    4191.114455891415,\n                    3489.3245375172587,\n                    2438.7143275091894,\n                    2579.0322123944043,\n                    3197.038563619707,\n                    3107.3043335466377,\n                    3384.5420569152025,\n                    3026.214223864194,\n                    2955.4727465665437,\n                    2938.449490331077,\n                    2444.3275358242336,\n                    2447.5359296109964,\n                    2572.5750258119742,\n                    2629.0978967032243,\n                    2641.6700332863193,\n                    2903.932835903283,\n                    2821.317530851881,\n                    2272.884921159144,\n                    2668.589365207391,\n                    3178.0194113129796,\n                    3265.484517502896,\n                    3469.4327543174313,\n                    2897.2634039647874,\n                    2775.078297064553\n                ]\n            ]\n        },\n        \"secondaryMetrics\" : {\n        }\n    }\n]\n</code></pre>"},{"location":"benchmark-results/#results-rocksdb-myjson","title":"results-RocksDB-my.json","text":"<pre><code>{\n  \"totalDirectorySize\" : 8306458361,\n  \"fileCount\" : 143,\n  \"usedMemoryBytes\" : 29881472,\n  \"cpuBefore\" : 524178000,\n  \"cpuAfter\" : 978766000,\n  \"startTime\" : 256399236974125,\n  \"endTime\" : 257100509331250,\n  \"cpuUsage\" : 0.0648233165590143\n}\n</code></pre>"},{"location":"benchmark-results/#results-rocksdbjson","title":"results-RocksDB.json","text":"<pre><code>[\n    {\n        \"jmhVersion\" : \"1.37\",\n        \"benchmark\" : \"org.hestiastore.index.benchmark.plainload.TestRocksDB.write\",\n        \"mode\" : \"thrpt\",\n        \"threads\" : 1,\n        \"forks\" : 1,\n        \"jvm\" : \"/opt/homebrew/Cellar/openjdk@21/21.0.7/libexec/openjdk.jdk/Contents/Home/bin/java\",\n        \"jvmArgs\" : [\n            \"-Ddir=/Volumes/ponrava/test-index\",\n            \"-Dengine=RocksDB\"\n        ],\n        \"jdkVersion\" : \"21.0.7\",\n        \"vmName\" : \"OpenJDK 64-Bit Server VM\",\n        \"vmVersion\" : \"21.0.7\",\n        \"warmupIterations\" : 10,\n        \"warmupTime\" : \"20 s\",\n        \"warmupBatchSize\" : 1,\n        \"measurementIterations\" : 25,\n        \"measurementTime\" : \"20 s\",\n        \"measurementBatchSize\" : 1,\n        \"primaryMetric\" : {\n            \"score\" : 305711.8304543295,\n            \"scoreError\" : 78928.99893168075,\n            \"scoreConfidence\" : [\n                226782.83152264875,\n                384640.82938601024\n            ],\n            \"scorePercentiles\" : {\n                \"0.0\" : 64828.117457250206,\n                \"50.0\" : 303051.53710396215,\n                \"90.0\" : 440196.02218382317,\n                \"95.0\" : 451632.3622033773,\n                \"99.0\" : 452870.0724388766,\n                \"99.9\" : 452870.0724388766,\n                \"99.99\" : 452870.0724388766,\n                \"99.999\" : 452870.0724388766,\n                \"99.9999\" : 452870.0724388766,\n                \"100.0\" : 452870.0724388766\n            },\n            \"scoreUnit\" : \"ops/s\",\n            \"rawData\" : [\n                [\n                    452870.0724388766,\n                    403842.93155871733,\n                    294725.1949589473,\n                    344879.7186297531,\n                    252451.31054124268,\n                    270367.7563971078,\n                    265577.0790884009,\n                    211979.36739862378,\n                    70666.26824904919,\n                    414677.1507219246,\n                    64828.117457250206,\n                    405398.2212372984,\n                    386439.0605128443,\n                    419727.7994319734,\n                    434497.12253711926,\n                    448744.3716538789,\n                    235897.63938900485,\n                    297712.0697930812,\n                    303794.303173526,\n                    360040.8711513881,\n                    257499.74121652535,\n                    303051.53710396215,\n                    185201.4305266164,\n                    303600.34376763576,\n                    254326.28242349048\n                ]\n            ]\n        },\n        \"secondaryMetrics\" : {\n        }\n    }\n]\n</code></pre>"},{"location":"profiler-stacktrace/","title":"JVM profiler results (YourKit)","text":"<p>This page summarizes a profiling session focused on read and write performance. The goal was to identify where CPU time is spent and highlight concrete improvements.</p> <p>The workload: a separate generator produced roughly 100,000,000 key\u2013value entries and then executed read-heavy operations against HestiaStore 0.0.5 while YourKit captured CPU samples.</p> <p>Test environment: run on a Mac mini on 24.10.2025.</p> <p></p>"},{"location":"profiler-stacktrace/#how-to-read-the-numbers","title":"\ud83e\udded How to read the numbers","text":"<p>Percentages shown below approximate the share of total CPU time across the whole run spent in each operation/stack. For example, \u201c40% byte array manipulations\u201d means about 40% of all CPU cycles were consumed in copying/transforming byte arrays end-to-end.</p>"},{"location":"profiler-stacktrace/#key-findings-high-level","title":"\ud83d\udcc8 Key findings (high level)","text":"<ul> <li>~40% in byte array manipulation (ultimately <code>System.arraycopy</code>) across several layers while moving data between buffers and chunks.</li> <li>~21% in sequential reads through stacked streams and iterators, indicating many small reads and buffer boundaries.</li> <li>~18% during stream/channel closing (clean-up cascades), suggesting repeated finalization work per access.</li> <li>~3% in file open syscalls while creating new channels for short-lived reads.</li> </ul> <p>These four areas dominate the observed CPU budget for the scenario above.</p>"},{"location":"profiler-stacktrace/#detailed-stacks-and-context","title":"\ud83e\uddf5 Detailed stacks and context","text":""},{"location":"profiler-stacktrace/#40-byte-array-manipulation","title":"~40%: byte array manipulation","text":"<p>The hot paths converge on <code>System.arraycopy</code>, coming from multiple places in the chunk/data-block pipeline. This usually indicates extra copying between intermediate buffers.</p>"},{"location":"profiler-stacktrace/#3-file-open-overhead","title":"~3%: file open overhead","text":"<p>Opening files repeatedly costs ~3% CPU. Consider reusing channels across related reads to reduce syscalls and JNI transitions.</p> <pre><code>sun.nio.fs.UnixNativeDispatcher.open0(Native Method)\nsun.nio.fs.UnixNativeDispatcher.open(UnixNativeDispatcher.java:72)\nsun.nio.fs.UnixChannelFactory.open(UnixChannelFactory.java:258)\nsun.nio.fs.UnixChannelFactory.newFileChannel(UnixChannelFactory.java:133)\nsun.nio.fs.UnixChannelFactory.newFileChannel(UnixChannelFactory.java:146)\nsun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:259)\njava.nio.file.Files.newByteChannel(Files.java:380)\njava.nio.file.Files.newByteChannel(Files.java:432)\njava.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:420)\njava.nio.file.Files.newInputStream(Files.java:160)\norg.hestiastore.index.directory.FsFileReaderStream.&lt;init&gt;(FsFileReaderStream.java:22)\norg.hestiastore.index.directory.FsDirectory.getFileReader(FsDirectory.java:29)\norg.hestiastore.index.datablockfile.DataBlockFile.getFileReader(DataBlockFile.java:69)\norg.hestiastore.index.datablockfile.DataBlockFile.openReader(DataBlockFile.java:61)\norg.hestiastore.index.chunkstore.ChunkStoreFile.openReader(ChunkStoreFile.java:52)\norg.hestiastore.index.chunkentryfile.ChunkEntryFile.openIteratorAtPosition(ChunkEntryFile.java:42)\norg.hestiastore.index.segment.SegmentIndexSearcher.search(SegmentIndexSearcher.java:43)\norg.hestiastore.index.segment.SegmentSearcher.get(SegmentSearcher.java:62)\norg.hestiastore.index.segment.SegmentImpl.get(SegmentImpl.java:166)\norg.hestiastore.index.sst.SstIndexImpl.get(SstIndexImpl.java:163)\norg.hestiastore.index.sst.IndexContextLoggingAdapter.get(IndexContextLoggingAdapter.java:46)\ncom.coroptis.counting.CommandCount.lambda$countBoard$0(CommandCount.java:102)\ncom.coroptis.counting.CommandCount$$Lambda.0x000000080023f0b0.accept()\njava.util.ArrayList.forEach(ArrayList.java:1596)\ncom.coroptis.counting.CommandCount.countBoard(CommandCount.java:99)\ncom.coroptis.counting.CommandCount.lambda$computeNewStates$0(CommandCount.java:82)\ncom.coroptis.counting.CommandCount$$Lambda.0x000000080023e3c0.accept()\njava.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)\njava.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)\norg.hestiastore.index.sst.EntryIteratorToSpliterator.tryAdvance(EntryIteratorToSpliterator.java:31)\njava.util.Spliterator.forEachRemaining(Spliterator.java:332)\njava.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)\njava.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)\njava.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)\njava.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)\njava.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\njava.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)\ncom.coroptis.counting.CommandCount.computeNewStates(CommandCount.java:81)\ncom.coroptis.counting.CommandCount.countRound(CommandCount.java:48)\ncom.coroptis.counting.Main.main(Main.java:132)\n</code></pre>"},{"location":"profiler-stacktrace/#21-sequential-reads-through-layered-streams","title":"~21%: sequential reads through layered streams","text":"<p>Reading through <code>BufferedInputStream</code> and custom readers accumulates overhead from many small reads and object boundaries.</p> <pre><code>sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java)\nsun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:103)\njava.io.BufferedInputStream.read1(BufferedInputStream.java:345)\njava.io.BufferedInputStream.implRead(BufferedInputStream.java:420)\njava.io.BufferedInputStream.read(BufferedInputStream.java:399)\njava.io.FilterInputStream.read(FilterInputStream.java:95)\norg.hestiastore.index.directory.FsFileReaderStream.read(FsFileReaderStream.java:51)\norg.hestiastore.index.datablockfile.DataBlockReaderImpl.read(DataBlockReaderImpl.java:35)\norg.hestiastore.index.datablockfile.DataBlockReaderImpl.read(DataBlockReaderImpl.java:12)\norg.hestiastore.index.datablockfile.DataBlockByteReaderImpl.moveToNextDataBlock(DataBlockByteReaderImpl.java:84)\norg.hestiastore.index.datablockfile.DataBlockByteReaderImpl.optionalyMoveToNextDataBlock(DataBlockByteReaderImpl.java:79)\norg.hestiastore.index.datablockfile.DataBlockByteReaderImpl.readExactly(DataBlockByteReaderImpl.java:71)\norg.hestiastore.index.chunkstore.ChunkData.read(ChunkData.java:85)\norg.hestiastore.index.chunkstore.ChunkStoreReaderImpl.read(ChunkStoreReaderImpl.java:42)\norg.hestiastore.index.chunkstore.ChunkStoreReaderImpl.read(ChunkStoreReaderImpl.java:13)\norg.hestiastore.index.chunkentryfile.ChunkEntryFileIterator.moveToNextChunk(ChunkEntryFileIterator.java:81)\norg.hestiastore.index.chunkentryfile.ChunkEntryFileIterator.&lt;init&gt;(ChunkEntryFileIterator.java:42)\norg.hestiastore.index.chunkentryfile.ChunkEntryFile.openIteratorAtPosition(ChunkEntryFile.java:42)\norg.hestiastore.index.segment.SegmentIndexSearcher.search(SegmentIndexSearcher.java:43)\norg.hestiastore.index.segment.SegmentSearcher.get(SegmentSearcher.java:62)\norg.hestiastore.index.segment.SegmentImpl.get(SegmentImpl.java:166)\norg.hestiastore.index.sst.SstIndexImpl.get(SstIndexImpl.java:163)\norg.hestiastore.index.sst.IndexContextLoggingAdapter.get(IndexContextLoggingAdapter.java:46)\ncom.coroptis.counting.CommandCount.lambda$countBoard$0(CommandCount.java:102)\ncom.coroptis.counting.CommandCount$$Lambda.0x000000080023f0b0.accept()\njava.util.ArrayList.forEach(ArrayList.java:1596)\ncom.coroptis.counting.CommandCount.countBoard(CommandCount.java:99)\ncom.coroptis.counting.CommandCount.lambda$computeNewStates$0(CommandCount.java:82)\ncom.coroptis.counting.CommandCount$$Lambda.0x000000080023e3c0.accept()\njava.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)\njava.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)\norg.hestiastore.index.sst.EntryIteratorToSpliterator.tryAdvance(EntryIteratorToSpliterator.java:31)\njava.util.Spliterator.forEachRemaining(Spliterator.java:332)\njava.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)\njava.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)\njava.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)\njava.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)\njava.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\njava.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)\ncom.coroptis.counting.CommandCount.computeNewStates(CommandCount.java:81)\ncom.coroptis.counting.CommandCount.countRound(CommandCount.java:48)\ncom.coroptis.counting.Main.main(Main.java:132)\n</code></pre>"},{"location":"profiler-stacktrace/#18-closecleanup-cascades","title":"~18%: close/cleanup cascades","text":"<p>Closing nested readers triggers multiple cleaner/finalization steps. Reusing readers or collapsing the close hierarchy could help.</p> <pre><code>java.io.FileDescriptor.close0(Native Method)\njava.io.FileDescriptor.close(FileDescriptor.java:304)\njava.io.FileDescriptor$1.close(FileDescriptor.java:89)\nsun.nio.ch.FileChannelImpl$Closer.run(FileChannelImpl.java:116)\njdk.internal.ref.CleanerImpl$PhantomCleanableRef.performCleanup(CleanerImpl.java:178)\njdk.internal.ref.PhantomCleanable.clean(PhantomCleanable.java:133)\nsun.nio.ch.FileChannelImpl.implCloseChannel(FileChannelImpl.java:210)\njava.nio.channels.spi.AbstractInterruptibleChannel.close(AbstractInterruptibleChannel.java:113)\nsun.nio.ch.ChannelInputStream.close(ChannelInputStream.java:312)\njava.io.BufferedInputStream.close(BufferedInputStream.java:618)\norg.hestiastore.index.directory.FsFileReaderStream.doClose(FsFileReaderStream.java:33)\norg.hestiastore.index.AbstractCloseableResource.close(AbstractCloseableResource.java:23)\norg.hestiastore.index.datablockfile.DataBlockReaderImpl.doClose(DataBlockReaderImpl.java:29)\norg.hestiastore.index.AbstractCloseableResource.close(AbstractCloseableResource.java:23)\norg.hestiastore.index.datablockfile.DataBlockByteReaderImpl.doClose(DataBlockByteReaderImpl.java:48)\norg.hestiastore.index.AbstractCloseableResource.close(AbstractCloseableResource.java:23)\norg.hestiastore.index.chunkstore.ChunkStoreReaderImpl.doClose(ChunkStoreReaderImpl.java:36)\norg.hestiastore.index.AbstractCloseableResource.close(AbstractCloseableResource.java:23)\norg.hestiastore.index.chunkentryfile.ChunkEntryFileIterator.doClose(ChunkEntryFileIterator.java:96)\norg.hestiastore.index.AbstractCloseableResource.close(AbstractCloseableResource.java:23)\norg.hestiastore.index.segment.SegmentIndexSearcher.search(SegmentIndexSearcher.java:59)\norg.hestiastore.index.segment.SegmentSearcher.get(SegmentSearcher.java:62)\norg.hestiastore.index.segment.SegmentImpl.get(SegmentImpl.java:166)\norg.hestiastore.index.sst.SstIndexImpl.get(SstIndexImpl.java:163)\norg.hestiastore.index.sst.IndexContextLoggingAdapter.get(IndexContextLoggingAdapter.java:46)\ncom.coroptis.counting.CommandCount.lambda$countBoard$0(CommandCount.java:102)\ncom.coroptis.counting.CommandCount$$Lambda.0x000000080023f0b0.accept()\njava.util.ArrayList.forEach(ArrayList.java:1596)\ncom.coroptis.counting.CommandCount.countBoard(CommandCount.java:99)\ncom.coroptis.counting.CommandCount.lambda$computeNewStates$0(CommandCount.java:82)\ncom.coroptis.counting.CommandCount$$Lambda.0x000000080023e3c0.accept()\njava.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)\njava.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)\norg.hestiastore.index.sst.EntryIteratorToSpliterator.tryAdvance(EntryIteratorToSpliterator.java:31)\njava.util.Spliterator.forEachRemaining(Spliterator.java:332)\njava.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)\njava.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)\njava.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)\njava.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)\njava.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\njava.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)\ncom.coroptis.counting.CommandCount.computeNewStates(CommandCount.java:81)\ncom.coroptis.counting.CommandCount.countRound(CommandCount.java:48)\ncom.coroptis.counting.Main.main(Main.java:132)\n</code></pre>"},{"location":"profiler-stacktrace/#what-to-improve-next-actionable","title":"\ud83d\udee0\ufe0f What to improve next (actionable)","text":"<ul> <li>Reduce copies in the read path<ul> <li>Pool and reuse byte buffers across <code>ChunkStoreReader</code>/<code>ChunkEntryFileIterator</code>.</li> <li>Where feasible, write directly into the final consumer\u2019s buffer instead of staging arrays.</li> </ul> </li> <li>Fewer, larger IO operations<ul> <li>Increase internal buffer sizes; align chunk/page boundaries to reduce partial reads.</li> <li>Consider a shared channel with a single buffering layer to avoid stacking multiple <code>BufferedInputStream</code>s.</li> </ul> </li> <li>Tame cleanup overhead<ul> <li>Scope readers over a batch of gets to amortize <code>close()</code> and cleaner activity.</li> <li>Ensure try-with-resources closes only once at the highest level; avoid redundant closes in nested layers.</li> </ul> </li> <li>Cut file-open churn<ul> <li>Cache open channels per data file with reference counting; close when idle for a period.</li> <li>If feasible, pre-open frequently accessed files at segment initialization.</li> </ul> </li> </ul> <p>These changes should collectively reclaim the majority of the observed CPU time in this profile.</p>"},{"location":"quality/","title":"Quality &amp; Testing","text":"<p>An overview of how HestiaStore ensures consistent quality:</p> <ul> <li>Automated CI builds and test execution on every change.</li> <li>Code coverage reporting and trend tracking.</li> <li>Static analysis and quality gates (e.g., SonarCloud).</li> <li>Dependency vulnerability scanning (OWASP Dependency Check).</li> </ul> <p>Links and details to be expanded.</p>"},{"location":"reliability/","title":"Reliability Overview","text":"<p>This page summarizes how HestiaStore approaches reliability and stability.</p> <ul> <li>Benchmarks: see benchmark-results.md for throughput and resource use.</li> <li>Security: see SECURITY.md for reporting and handling practices.</li> <li>Quality signals: CI, coverage, static analysis, and dependency checks (see badges on the Home page).</li> </ul> <p>More detail to be added.</p>"},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/arch-index/","title":"Architecture","text":"<p>Here is described basic index concepts. This page explain you how to correctly configure index.</p> <p></p>"},{"location":"architecture/arch-index/#operation-consistency","title":"Operation consistency","text":"<p>The <code>getStream()</code> method can sometimes return inconsistent results, occasionally omitting some items. This can occur in the following scenarios:</p> <ul> <li>Segment Compaction: If data is being streamed from a segment and new keys are added to that segment during the process, the segment may stop providing additional keys. In this case, the stream operation will either continue with the next segment or terminate if no more segments are available.</li> <li>Adding New Keys: If a completely new key is added to the index and is only present in the main index cache, it will not be returned.</li> </ul> <p>To prevent these issues, you should call <code>compact()</code> before invoking <code>getStream()</code> and ensure no new keys are added during streaming.</p> <p>Updating values in the index using <code>put()</code> or deleting keys using <code>delete()</code> does not cause inconsistencies. Updated values will be returned, and deleted keys will be excluded from the stream.</p> <p>Other operations, like <code>get()</code>, remain consistently reliable.</p>"},{"location":"architecture/arch-index/#states","title":"States","text":"<p>Index could be in following states:</p> <p></p> <p></p> <p>Interruption of process of writing data to index could lead to corruption of entire index.</p>"},{"location":"architecture/caching/","title":"Caching Strategy","text":"<p>HestiaStore uses a few focused caches to deliver read\u2011after\u2011write visibility and predictable read latency while keeping memory bounded. This page outlines each layer, how it is populated/evicted, and which configuration knobs control sizing.</p>"},{"location":"architecture/caching/#goals","title":"Goals","text":"<ul> <li>Read\u2011after\u2011write consistency without synchronous disk I/O</li> <li>Bound the working set in memory via LRU at the segment layer</li> <li>Keep read I/O predictable: avoid random seeks with Bloom filter + sparse index</li> <li>Make flush/compact operations deterministic and safe</li> </ul>"},{"location":"architecture/caching/#layers-overview","title":"Layers Overview","text":"<ul> <li>Index write buffer: in\u2011memory, unique latest value per key</li> <li>Class: <code>cache/UniqueCache</code></li> <li>Owner: <code>sst/SstIndexImpl</code> (top\u2011level)</li> <li> <p>Purpose: absorb writes and provide immediate visibility before flush</p> </li> <li> <p>Segment delta cache: per\u2011segment overlay of recent writes</p> </li> <li>Classes: <code>segment/SegmentDeltaCache</code>, <code>segment/SegmentDeltaCacheWriter</code>, <code>segment/SegmentDeltaCacheController</code></li> <li> <p>Purpose: hold sorted updates for a segment between compactions; also backs reads</p> </li> <li> <p>Segment data LRU: cache of heavyweight per\u2011segment objects</p> </li> <li>Classes: <code>sst/SegmentDataCache</code> (LRU), values are <code>segment/SegmentData</code> (lazy container)</li> <li> <p>Contents: delta cache, Bloom filter, sparse index (scarce index)</p> </li> <li> <p>Bloom filter: per\u2011segment probabilistic set for negative checks</p> </li> <li> <p>Classes: <code>bloomfilter/*</code>; created by <code>segment/SegmentDataSupplier</code></p> </li> <li> <p>Sparse index (\"scarce index\"): per\u2011segment in\u2011memory snapshot of pointers</p> </li> <li> <p>Classes: <code>scarceindex/ScarceIndex</code>, <code>ScarceIndexSnapshot</code></p> </li> <li> <p>Key\u2192segment map: max\u2011key to SegmentId mapping</p> </li> <li>Class: <code>sst/KeySegmentCache</code> (TreeMap, persisted to <code>index.map</code>)</li> </ul>"},{"location":"architecture/caching/#writetime-caches","title":"Write\u2011Time Caches","text":""},{"location":"architecture/caching/#index-write-buffer-uniquecache","title":"Index write buffer (UniqueCache)","text":"<ul> <li>On <code>Index.put/delete</code>, the write is stored in an index\u2011level <code>UniqueCache</code>.</li> <li>Replaces any prior value for the same key; deletes are represented as a tombstone value.</li> <li>Triggered flush (<code>cache.size() &gt; maxNumberOfKeysInCache</code>) routes sorted writes to target segments and clears the buffer.</li> </ul> <p>Code: <code>sst/SstIndexImpl#put</code>, <code>sst/SstIndexImpl#delete</code>, <code>sst/SstIndexImpl#flushCache</code>, <code>cache/UniqueCache</code>.</p>"},{"location":"architecture/caching/#segment-delta-cache","title":"Segment delta cache","text":"<ul> <li>Flush writes become per\u2011segment delta files via <code>SegmentDeltaCacheWriter</code> (transactional temp file + rename).</li> <li>If the segment\u2019s data is currently loaded in memory, the in\u2011memory delta cache is updated immediately to keep reads fresh.</li> <li>Compaction (<code>SegmentCompacter</code>) rewrites the segment, then <code>SegmentDeltaCacheController.clear()</code> evicts in\u2011memory delta cache and deletes delta files.</li> </ul> <p>Code: <code>segment/SegmentDeltaCacheWriter</code>, <code>segment/SegmentDeltaCacheController</code>, <code>segment/SegmentCompacter</code>, <code>segment/SegmentFullWriterTx#doCommit</code>.</p>"},{"location":"architecture/caching/#readtime-caches","title":"Read\u2011Time Caches","text":"<ul> <li>Top\u2011level overlay: <code>Index.get(k)</code> checks the index write buffer first. Iterators are also overlaid with <code>EntryIteratorRefreshedFromCache</code> so scans see most recent writes.</li> <li>Per\u2011segment overlay: <code>SegmentDeltaCache</code> is consulted before the Bloom filter + sparse index path. If it returns a tombstone, the key is absent.</li> <li>Heavy objects (Bloom filter, scarce index, delta cache) are obtained via a provider backed by LRU:</li> <li><code>sst/SegmentDataCache</code> holds <code>segment/SegmentData</code> instances with an LRU limit; eviction calls <code>close()</code> on the container.</li> <li>Providers: <code>segment/SegmentDataProvider</code> implementations<ul> <li><code>sst/SegmentDataProviderFromMainCache</code> \u2014 returns/creates from the LRU</li> <li><code>segment/SegmentDataProviderSimple</code> \u2014 simple local holder (used in wiring/tests)</li> </ul> </li> </ul> <p>Code: <code>sst/SstIndexImpl#get</code>, <code>segment/SegmentImpl#get</code>, <code>segment/SegmentSearcher</code>, <code>sst/EntryIteratorRefreshedFromCache</code>, <code>sst/SegmentDataCache</code>.</p>"},{"location":"architecture/caching/#eviction-and-lifecycle","title":"Eviction and Lifecycle","text":"<ul> <li>UniqueCache (index write buffer): no incremental eviction; cleared on flush.</li> <li>SegmentDataCache (LRU of SegmentData): evicts least\u2011recently\u2011used segment; eviction closes Bloom filter and clears delta cache via <code>close()</code> hook.</li> <li>SegmentDeltaCache: cleared and files removed after compaction via <code>SegmentDeltaCacheController.clear()</code>; rebuilt on demand from delta files.</li> <li>KeySegmentCache: persisted via <code>optionalyFlush()</code> when updated; survives process restarts by reading <code>index.map</code>.</li> </ul>"},{"location":"architecture/caching/#configuration-knobs","title":"Configuration Knobs","text":"<p>Index\u2011level: - <code>IndexConfiguration.getMaxNumberOfKeysInCache()</code> \u2014 size of the index write buffer (triggers flush) - <code>IndexConfiguration.getMaxNumberOfSegmentsInCache()</code> \u2014 LRU size for <code>SegmentDataCache</code></p> <p>Per\u2011segment (via <code>SegmentConf</code>, derived from index configuration): - <code>maxNumberOfKeysInSegmentCache</code> \u2014 target size for a single delta cache - <code>maxNumberOfKeysInSegmentCacheDuringFlushing</code> \u2014 safety bound while building a delta cache - <code>maxNumberOfKeysInSegmentChunk</code> \u2014 sparse index sampling cadence (affects read scan window)</p> <p>Bloom filter sizing: - <code>bloomFilterIndexSizeInBytes</code> and <code>bloomFilterNumberOfHashFunctions</code> - <code>bloomFilterProbabilityOfFalsePositive</code></p> <p>I/O buffering: - <code>diskIoBufferSize</code> \u2014 affects memory used by readers/writers across files</p> <p>See: <code>sst/IndexConfiguration</code>, <code>segment/SegmentConf</code>.</p>"},{"location":"architecture/caching/#warmup-strategies","title":"Warm\u2011Up Strategies","text":"<ul> <li>Point warm\u2011up: issue representative <code>get(key)</code> calls; this loads the target segments\u2019 Bloom filter and sparse index into the LRU.</li> <li>Segment warm\u2011up: iterate a small range to prime chunk readers and caches.</li> <li>Global warm\u2011up: a bounded <code>index.getStream(SegmentWindow.limit(N))</code> over initial segments to seed the LRU without scanning the full dataset.</li> </ul>"},{"location":"architecture/caching/#observability","title":"Observability","text":"<ul> <li>Bloom filter effectiveness and false\u2011positive rate: <code>bloomfilter/BloomFilterStats</code>, accessible via <code>BloomFilter.getStatistics()</code>.</li> <li>Index operation counters (coarse): <code>sst/Stats</code> increments on get/put/delete.</li> </ul>"},{"location":"architecture/caching/#tuning-guidance","title":"Tuning Guidance","text":"<ul> <li>Throughput\u2011oriented writes: increase <code>maxNumberOfKeysInCache</code> to batch more before flushing; monitor memory and flush latency.</li> <li>Read\u2011heavy workloads touching few segments: increase <code>maxNumberOfSegmentsInCache</code> so the working set of segments (Bloom + scarce + delta) stays resident.</li> <li>Space\u2011sensitive deployments: reduce Bloom filter size (may increase false positives and extra reads) or disable compression filters to trade CPU for I/O.</li> <li>Latency\u2011sensitive point lookups: ensure Bloom filter is sized adequately; keep segments\u2019 working set in the LRU; consider slightly smaller <code>maxNumberOfKeysInSegmentChunk</code> to narrow the local scan window.</li> </ul>"},{"location":"architecture/caching/#code-pointers","title":"Code Pointers","text":"<ul> <li>Index write buffer: <code>src/main/java/org/hestiastore/index/sst/SstIndexImpl.java</code></li> <li>Segment caches and providers: <code>src/main/java/org/hestiastore/index/sst/*SegmentData*</code>, <code>src/main/java/org/hestiastore/index/segment/SegmentData*</code></li> <li>LRU cache: <code>src/main/java/org/hestiastore/index/cache/CacheLru.java</code></li> <li>Key\u2192segment map: <code>src/main/java/org/hestiastore/index/sst/KeySegmentCache.java</code></li> </ul>"},{"location":"architecture/caching/#related-glossary","title":"Related Glossary","text":"<ul> <li>UniqueCache</li> <li>Delta Cache</li> <li>SegmentData</li> <li>Bloom Filter</li> <li>Sparse Index</li> <li>Key-to-Segment Map</li> </ul>"},{"location":"architecture/concurrency/","title":"Access Model","text":"<p>HestiaStore offers two usage modes: a fast, non\u2011synchronized default intended for single\u2011threaded (or externally synchronized) use, and an opt\u2011in thread\u2011safe variant that serializes operations with a coarse lock. Iteration is protected with an optimistic lock so scans don\u2019t observe torn updates.</p>"},{"location":"architecture/concurrency/#variants","title":"Variants","text":"<ul> <li>Default (non\u2011synchronized): <code>sst/SstIndexImpl</code></li> <li>Highest throughput, minimal coordination overhead.</li> <li>Not thread\u2011safe: internal structures (maps, caches) are not synchronized.</li> <li> <p>Use from a single thread, or add your own external synchronization.</p> </li> <li> <p>Thread\u2011safe: <code>sst/IndexInternalSynchronized</code></p> </li> <li>Enabled via <code>IndexConfigurationBuilder.withThreadSafe(true)</code>.</li> <li>Wraps all public operations (<code>put</code>, <code>get</code>, <code>delete</code>, <code>flush</code>, <code>compact</code>, <code>getStream</code>, <code>checkAndRepairConsistency</code>) in a single <code>ReentrantLock</code>.</li> <li>Iterators returned by <code>getStream</code> are wrapped with <code>EntryIteratorSynchronized</code> to take/release the lock for <code>hasNext</code>/<code>next</code>/<code>close</code> calls.</li> <li>Trade\u2011off: simple and safe, but long scans will contend with writers due to coarse locking.</li> </ul> <p>Code pointers: <code>sst/IndexInternalSynchronized.java</code>, <code>sst/EntryIteratorSynchronized.java</code>.</p>"},{"location":"architecture/concurrency/#process-exclusivity","title":"Process Exclusivity","text":"<p>Opening an index acquires a directory file lock to prevent two processes from using the same directory at once:</p> <ul> <li>On open: <code>IndexStateNew</code> creates <code>.lock</code> via <code>Directory.getLock()</code> and transitions to <code>IndexStateReady</code>.</li> <li>On close: the lock file is removed in <code>IndexStateReady#onClose</code>.</li> <li>Any operation before \u201cready\u201d or after \u201cclosed\u201d throws an error (<code>IndexState*</code>).</li> </ul> <p>Code pointers: <code>sst/IndexStateNew.java</code>, <code>sst/IndexStateReady.java</code>, <code>sst/IndexStateClose.java</code>, <code>directory/FsFileLock.java</code>.</p>"},{"location":"architecture/concurrency/#reader-isolation-optimistic-lock","title":"Reader Isolation (Optimistic Lock)","text":"<p>Segment reads are protected by an optimistic lock based on a monotonically increasing version:</p> <ul> <li>Each segment has a <code>VersionController</code> implementing <code>OptimisticLockObjectVersionProvider</code>.</li> <li>Writers bump the version before delta writes and compaction.</li> <li>Per\u2011segment iterators are wrapped with <code>EntryIteratorWithLock</code> holding a snapshot of the version. If the version changes mid\u2011scan, <code>hasNext()</code> returns false and <code>next()</code> throws, avoiding torn reads.</li> </ul> <p>Code pointers: <code>segment/VersionController.java</code>, <code>EntryIteratorWithLock.java</code>, <code>segment/SegmentImpl#openIterator()</code>.</p>"},{"location":"architecture/concurrency/#writers-and-consistency","title":"Writers and Consistency","text":"<ul> <li>Delta cache writes: <code>SegmentDeltaCacheCompactingWriter</code> opens a per\u2011segment writer, collects updates, and may trigger compaction when policy advises. Writers close before compaction; compaction runs under a fresh version.</li> <li>Full compaction: <code>SegmentCompacter#forceCompact</code> rewrites the segment via <code>SegmentFullWriterTx</code> (transactional), then clears delta and updates properties.</li> <li>Atomicity across files is guaranteed by the write\u2011transaction pattern (<code>open()</code> \u2192 close \u2192 <code>commit()</code>; <code>*.tmp</code> + atomic rename). See \u201cRecovery\u201d.</li> </ul> <p>Code pointers: <code>segment/SegmentDeltaCacheCompactingWriter.java</code>, <code>segment/SegmentCompacter.java</code>, <code>segment/SegmentFullWriter*.java</code>.</p>"},{"location":"architecture/concurrency/#contention-hotspots-and-mitigation","title":"Contention Hotspots and Mitigation","text":"<ul> <li>Thread\u2011safe variant\u2019s single lock:</li> <li>Hotspot when mixing long <code>getStream()</code> scans with frequent writes. Consider scanning with bounded <code>SegmentWindow</code> or running scans off\u2011peak.</li> <li> <p>Keep individual operations short; avoid long\u2011held locks in user callbacks.</p> </li> <li> <p>Iteration under mutation:</p> </li> <li> <p>Optimistic lock will terminate iterators if a segment mutates (e.g., compaction). Re\u2011open the stream if needed.</p> </li> <li> <p>Flush/compaction:</p> </li> <li>These operations modify many files and bump versions; plan to run them during low traffic if using the synchronized variant.</li> </ul>"},{"location":"architecture/concurrency/#configuration-tips","title":"Configuration Tips","text":"<ul> <li>Enable thread\u2011safe mode when you need concurrent access without external coordination:</li> </ul> <pre><code>IndexConfiguration&lt;Integer, String&gt; conf = IndexConfiguration.&lt;Integer, String&gt;builder()\n    // ... type descriptors and other settings ...\n    .withThreadSafe(true)\n    .build();\nIndex&lt;Integer, String&gt; index = Index.create(directory, conf);\n</code></pre> <ul> <li>For high read concurrency with minimal contention, prefer the default variant and place your own read/write locks at a higher level if needed.</li> </ul>"},{"location":"architecture/concurrency/#related-glossary","title":"Related Glossary","text":"<ul> <li>Segment</li> <li>Write Transaction</li> <li>SegmentWindow</li> <li>Compaction</li> <li>Consistency Checker</li> </ul>"},{"location":"architecture/datablock/","title":"Data Block and Chunk Design in HestiaStore","text":"<p>This document describes the structure and purpose of <code>Block</code> and <code>Chunk</code> objects in the HestiaStore storage engine.</p> <p></p>"},{"location":"architecture/datablock/#block","title":"Block","text":"<p>A Block is the lowest-level physical unit of storage. It has a fixed size (typically a multiple of 4KB) and is directly written to disk.</p>"},{"location":"architecture/datablock/#key-characteristics","title":"Key Characteristics:","text":"<ul> <li>Fixed Size: Determined by <code>BlockFile#getBlockSize()</code>.</li> <li>Header: Each block includes a header with metadata (e.g. magic number, CRC32 checksum, data length).</li> <li>Payload: The remaining portion of the block contains user data (<code>getPayloadSize()</code> returns the usable size).</li> </ul>"},{"location":"architecture/datablock/#block-header-format","title":"Block Header Format:","text":"Offset Size Field Description 0 4 B <code>magic</code> Identifier for block integrity check 4 4 B <code>crc32</code> CRC checksum for payload verification 8 4 B <code>dataLength</code> Actual size of data in the block 12+ N/A <code>payload</code> User data payload <p>Blocks are stored and retrieved via the <code>BlockFile</code> abstraction.</p>"},{"location":"architecture/datablock/#chunk","title":"Chunk","text":"<p>A Chunk represents a variable-sized, logical data unit stored inside a block. It is used to store optionally compressed sets of key-value entries.</p>"},{"location":"architecture/datablock/#key-characteristics_1","title":"Key Characteristics:","text":"<ul> <li>Variable Size: Can be smaller or span multiple blocks depending on compression.</li> <li>Stored Inside Blocks: Uses the <code>BlockFile</code> to persist data.</li> <li>Compressible: Designed for efficient compression and decompression.</li> <li>Encapsulated Metadata: Chunks also have a header to ensure validity and interpretability.</li> </ul>"},{"location":"architecture/datablock/#chunk-header-format","title":"Chunk Header Format:","text":"Offset Size Field Description 0 4 B <code>magic</code> Chunk type signature 4 4 B <code>crc32</code> CRC of compressed payload 8 4 B <code>compressedLength</code> Length of compressed data 12 4 B <code>uncompressedLength</code> Length of original (uncompressed) data 16+ N/A <code>payload</code> Compressed chunk data <p>Chunks are managed through the <code>ChunkFileStore</code> and written using <code>ChunkWriter</code>.</p>"},{"location":"architecture/datablock/#relationships","title":"Relationships","text":"<ul> <li><code>BlockFile</code> provides the persistent storage mechanism.</li> <li><code>ChunkFileStore</code> maps chunk positions to blocks and provides higher-level access.</li> <li>CRC validation is used in both blocks and chunks to ensure data consistency and detect corruption.</li> </ul>"},{"location":"architecture/filters/","title":"Filters &amp; Integrity","text":"<p>HestiaStore persists segment data in chunked files. Each chunk carries a small header and a payload processed by an ordered filter pipeline. Filters provide integrity (magic number, CRC32), optional compression, and optional reversible transformations. The same concept exists on both the write path (encoding pipeline) and read path (decoding pipeline).</p> <p>This page summarizes what the filters do, how they are ordered, and how to configure them.</p>"},{"location":"architecture/filters/#chunk-header-and-flags","title":"Chunk Header and Flags","text":"<p>Every chunk has a header with these fields:</p> <ul> <li>Magic number \u2014 constant identifying HestiaStore chunk format</li> <li>Version \u2014 current format version (presently 1)</li> <li>Payload length \u2014 number of payload bytes (unpadded)</li> <li>CRC32 \u2014 checksum of payload bytes (see ordering recommendations below)</li> <li>Flags \u2014 bit field describing which filters transformed the payload</li> </ul> <p>Flag bit positions (see <code>src/main/java/org/hestiastore/index/chunkstore/ChunkFilter.java</code>):</p> <ul> <li>0 \u2014 magic number present</li> <li>1 \u2014 CRC32 present (bit reserved; validation uses the header value)</li> <li>3 \u2014 Snappy compression</li> <li>4 \u2014 XOR encryption (reversible obfuscation)</li> </ul>"},{"location":"architecture/filters/#encoding-pipeline-write-path","title":"Encoding Pipeline (Write Path)","text":"<p>Write path constructs a <code>ChunkData</code> and passes it through a <code>ChunkProcessor</code> configured with encoding filters. The writer then combines the resulting header and (possibly transformed) payload and writes padded bytes to the underlying cell store.</p> <ul> <li>Implementation: <code>chunkstore/ChunkStoreWriterImpl#write</code></li> <li>Pipeline wrapper: <code>chunkstore/ChunkProcessor</code> with encoding filters</li> <li>Typical defaults: CRC32 \u2192 MagicNumber</li> <li>With compression/encryption enabled, recommended order:</li> <li>CRC32 writing \u2192 Magic number writing \u2192 Snappy compression \u2192 XOR encrypt</li> </ul> <p>Why this order: - CRC32 computed on the plaintext payload gives a strong data\u2011integrity check after decoding (you must decompress/decrypt before CRC validation on read). - Magic\u2011number header flag is a quick consistency guard before attempting other transforms.</p>"},{"location":"architecture/filters/#decoding-pipeline-read-path","title":"Decoding Pipeline (Read Path)","text":"<p>Read path pulls a raw chunk, parses the header, then applies the decoding filters in order. The final <code>ChunkData</code> is used to rebuild a consistent <code>Chunk</code> instance with the validated header and payload.</p> <ul> <li>Implementation: <code>chunkstore/ChunkStoreReaderImpl#read</code></li> <li>Pipeline wrapper: <code>chunkstore/ChunkProcessor</code> with decoding filters</li> <li>Typical defaults: MagicNumber validation \u2192 CRC32 validation</li> <li>With compression/encryption enabled, recommended order:</li> <li>MagicNumber validation \u2192 XOR decrypt \u2192 Snappy decompress \u2192 CRC32 validation</li> </ul> <p>Notes: - Validation filters check the corresponding header flag (when provided) and throw an exception if the precondition fails (e.g., \u201cnot marked as compressed\u201d). - CRC validation recomputes CRC32 on the current payload and compares to the header value.</p>"},{"location":"architecture/filters/#available-filters","title":"Available Filters","text":"<p>Integrity - Magic number writing/validation: <code>ChunkFilterMagicNumberWriting</code>, <code>ChunkFilterMagicNumberValidation</code>   - Sets and validates the fixed magic number; toggles bit 0 in flags. - CRC32 writing/validation: <code>ChunkFilterCrc32Writing</code>, <code>ChunkFilterCrc32Validation</code>   - Computes/stores CRC over the payload; validation recomputes and compares.</p> <p>Compression - Snappy compress/decompress: <code>ChunkFilterSnappyCompress</code>, <code>ChunkFilterSnappyDecompress</code>   - Fast compression; sets/clears bit 3 in flags.</p> <p>Transformations - XOR encrypt/decrypt: <code>ChunkFilterXorEncrypt</code>, <code>ChunkFilterXorDecrypt</code>   - Lightweight reversible obfuscation; sets/clears bit 4 in flags.</p> <p>Utility - No\u2011op: <code>ChunkFilterDoNothing</code> (testing/bench harnesses)</p>"},{"location":"architecture/filters/#configuration","title":"Configuration","text":"<p>Filters are configured on the index through the fluent builder and then stored in the index configuration:</p> <ul> <li>API: <code>sst/IndexConfigurationBuilder</code></li> <li><code>addEncodingFilter(ChunkFilter)</code> / <code>addEncodingFilter(Class&lt;? extends ChunkFilter&gt;)</code></li> <li><code>addDecodingFilter(ChunkFilter)</code> / <code>addDecodingFilter(Class&lt;? extends ChunkFilter&gt;)</code></li> <li><code>withEncodingFilters(Collection&lt;ChunkFilter&gt;)</code></li> <li><code>withDecodingFilters(Collection&lt;ChunkFilter&gt;)</code></li> <li>Defaults (when you don\u2019t specify any):</li> <li>Encoding: CRC32 writing \u2192 Magic number writing</li> <li>Decoding: Magic number validation \u2192 CRC32 validation</li> </ul> <p>The filter sequences are propagated into segment I/O via <code>SegmentFiles</code>, used by: - Writer side: <code>ChunkStoreWriterTx</code> \u2192 <code>ChunkStoreWriterImpl</code> - Reader side: <code>ChunkStoreReaderImpl</code></p> <p>Constraints: - Filter lists must not be empty; <code>ChunkProcessor</code> enforces this. - Decoding order must mirror the inverse of encoding for transforms like compression/encryption. If you enable Snappy or XOR, include the matching decode filters in the correct order.</p>"},{"location":"architecture/filters/#error-handling-and-safety","title":"Error Handling and Safety","text":"<ul> <li>Validation failures (wrong magic, CRC mismatch, missing flags) throw exceptions and abort the read; no partial state is committed.</li> <li>Writes are protected by transactional temp\u2011file + atomic rename; a failed write never exposes a partially written chunk to readers.</li> </ul>"},{"location":"architecture/filters/#examples","title":"Examples","text":"<p>Enable Snappy compression with correct decode order:</p> <pre><code>IndexConfiguration&lt;Integer, String&gt; conf = IndexConfiguration.&lt;Integer, String&gt;builder()\n    // ... types and other settings ...\n    .addEncodingFilter(new ChunkFilterCrc32Writing())\n    .addEncodingFilter(new ChunkFilterMagicNumberWriting())\n    .addEncodingFilter(new ChunkFilterSnappyCompress())\n    .addDecodingFilter(new ChunkFilterMagicNumberValidation())\n    .addDecodingFilter(new ChunkFilterSnappyDecompress())\n    .addDecodingFilter(new ChunkFilterCrc32Validation())\n    .build();\n</code></pre> <p>Add XOR obfuscation on top of compression:</p> <pre><code>builder\n  .addEncodingFilter(new ChunkFilterXorEncrypt())\n  .addDecodingFilter(new ChunkFilterXorDecrypt());\n</code></pre>"},{"location":"architecture/filters/#code-pointers","title":"Code Pointers","text":"<ul> <li>Pipeline engine: <code>src/main/java/org/hestiastore/index/chunkstore/ChunkProcessor.java</code></li> <li>Filters: <code>src/main/java/org/hestiastore/index/chunkstore/ChunkFilter*.java</code></li> <li>Writer path: <code>src/main/java/org/hestiastore/index/chunkstore/ChunkStoreWriterImpl.java</code></li> <li>Reader path: <code>src/main/java/org/hestiastore/index/chunkstore/ChunkStoreReaderImpl.java</code></li> <li>Configuration defaults: <code>src/main/java/org/hestiastore/index/sst/IndexConfigurationContract.java</code></li> </ul>"},{"location":"architecture/filters/#related-glossary","title":"Related Glossary","text":"<ul> <li>Filters</li> <li>Chunk</li> <li>Main SST</li> </ul>"},{"location":"architecture/glossary/","title":"Glossary","text":"<p>Concise definitions of terms used across HestiaStore\u2019s architecture, with links and code pointers.</p>"},{"location":"architecture/glossary/#segment","title":"Segment","text":"<p>Bounded shard of the index stored on disk with its own files: main SST (<code>.index</code>), sparse index (<code>.scarce</code>), Bloom filter (<code>.bloom-filter</code>), properties, and optional delta caches. See also: On\u2011Disk Layout. Code: <code>segment/*</code>, <code>sst/SegmentRegistry.java</code>.</p>"},{"location":"architecture/glossary/#segmentid","title":"SegmentId","text":"<p>Stable integer id rendered as <code>segment-00000</code>, used to name per\u2011segment files. Code: <code>segment/SegmentId.java</code>.</p>"},{"location":"architecture/glossary/#key-to-segment-map","title":"Key-to-Segment Map","text":"<p>Global sorted map of max key \u2192 SegmentId that routes lookups and flushes. Persisted as <code>index.map</code>. Code: <code>sst/KeySegmentCache.java</code>.</p>"},{"location":"architecture/glossary/#main-sst","title":"Main SST","text":"<p>On\u2011disk, chunked Sorted String Table containing sorted key/value entries for a segment. Code: <code>chunkentryfile/*</code>, <code>chunkstore/*</code>.</p>"},{"location":"architecture/glossary/#chunk","title":"Chunk","text":"<p>Fixed\u2011cell payload plus a small header (magic, version, payload length, CRC, flags). Filters may transform payload on write and are inverted on read. Code: <code>chunkstore/Chunk*.java</code>.</p>"},{"location":"architecture/glossary/#delta-cache","title":"Delta Cache","text":"<p>Per\u2011segment overlay of recent updates, materialized as sorted <code>.cache</code> files and an in\u2011memory <code>UniqueCache</code> when loaded. Code: <code>segment/SegmentDeltaCache*.java</code>.</p>"},{"location":"architecture/glossary/#uniquecache","title":"UniqueCache","text":"<p>In\u2011memory map that keeps only the latest value per key. Used at the index\u2011level write buffer and inside the delta overlay. Code: <code>cache/UniqueCache*.java</code>.</p>"},{"location":"architecture/glossary/#flush","title":"Flush","text":"<p>Drains the index\u2011level write buffer, routes entries to per\u2011segment delta caches, and updates <code>index.map</code>. Code: <code>sst/SstIndexImpl#flush()</code>, <code>sst/CompactSupport.java</code>.</p>"},{"location":"architecture/glossary/#compaction","title":"Compaction","text":"<p>Segment rewrite that merges main SST with delta caches into fresh <code>.index</code>, <code>.scarce</code>, and <code>.bloom-filter</code> files, then clears delta caches. Code: <code>segment/SegmentCompacter.java</code>, <code>segment/SegmentFullWriter*.java</code>.</p>"},{"location":"architecture/glossary/#split","title":"Split","text":"<p>When a segment grows beyond <code>maxNumberOfKeysInSegment</code>, it is split into two; <code>index.map</code> is updated with a new max key and SegmentId. Code: <code>sst/SegmentSplitCoordinator.java</code>, <code>segment/SegmentSplitter*.java</code>.</p>"},{"location":"architecture/glossary/#sparse-index-scarce-index","title":"Sparse Index (Scarce Index)","text":"<p>Per\u2011segment, sorted sample of keys that points to chunk start positions in the main SST to bound local scans. Code: <code>scarceindex/*</code>.</p>"},{"location":"architecture/glossary/#bloom-filter","title":"Bloom Filter","text":"<p>Per\u2011segment probabilistic set that quickly proves absence and reduces on\u2011disk probes; rebuilt during compaction. Code: <code>bloomfilter/*</code>.</p>"},{"location":"architecture/glossary/#filters-chunk-filters","title":"Filters (Chunk Filters)","text":"<p>Pluggable transformations applied to chunk payloads on write and inverted on read (magic number, CRC32, Snappy, XOR). Configured per index. Code: <code>chunkstore/ChunkFilter*.java</code>; config via <code>sst/IndexConfigurationBuilder</code>.</p>"},{"location":"architecture/glossary/#tombstone","title":"Tombstone","text":"<p>Special value denoting deletion; read path treats it as absent and compaction drops obsolete values. Provided by the value type descriptor. Code: <code>datatype/TypeDescriptor#getTombstone()</code>, used in <code>sst/SstIndexImpl#delete()</code>.</p>"},{"location":"architecture/glossary/#entry","title":"Entry","text":"<p>Immutable key/value pair used across iterators and writers. Code: <code>index/Entry.java</code>.</p>"},{"location":"architecture/glossary/#entryiterator","title":"EntryIterator","text":"<p>Forward iterator over entries; variants exist for merging overlays and for safe iteration under writes (optimistic lock). Code: <code>index/EntryIterator.java</code>, <code>segment/MergeDeltaCacheWithIndexIterator.java</code>, <code>index/EntryIteratorWithLock.java</code>.</p>"},{"location":"architecture/glossary/#write-transaction","title":"Write Transaction","text":"<p>Pattern that enforces open \u2192 close \u2192 commit, guaranteeing atomic file replacement. Code: <code>index/GuardedWriteTransaction.java</code>, <code>index/WriteTransaction.java</code>.</p>"},{"location":"architecture/glossary/#directory-abstraction","title":"Directory (Abstraction)","text":"<p>File I/O backend (FS, memory, zip) providing readers/writers and atomic rename. Code: <code>directory/*</code>.</p>"},{"location":"architecture/glossary/#segmentdata-and-provider","title":"SegmentData and Provider","text":"<p>Lazy containers and providers for per\u2011segment heavyweight structures (delta cache, Bloom, sparse index). Often cached via LRU. Code: <code>segment/SegmentData*.java</code>, <code>sst/SegmentDataCache.java</code>, <code>sst/SegmentDataProviderFromMainCache.java</code>.</p>"},{"location":"architecture/glossary/#segmentwindow","title":"SegmentWindow","text":"<p>Offset/limit window for streaming across segments, analogous to SQL OFFSET/LIMIT. Code: <code>sst/SegmentWindow.java</code>.</p>"},{"location":"architecture/glossary/#stats","title":"Stats","text":"<p>Simple counters for get/put/delete to observe workload shape. Code: <code>sst/Stats.java</code>.</p>"},{"location":"architecture/glossary/#consistency-checker","title":"Consistency Checker","text":"<p>Utilities to verify sortedness and segment/map coherence after unexpected shutdowns; can repair certain metadata issues. Code: <code>sst/IndexConsistencyChecker.java</code>, <code>segment/SegmentConsistencyChecker.java</code>.</p>"},{"location":"architecture/glossary/#context-log","title":"Context Log","text":"<p>Optional append\u2011only log of operations for observability (not a recovery WAL). Code: <code>log/*</code>.</p>"},{"location":"architecture/limits/","title":"Limitations &amp; Trade\u2011offs","text":"<p>This page lists the most important constraints and design trade\u2011offs so you can plan deployments and avoid surprises. Each item links to the code or related docs for verification.</p>"},{"location":"architecture/limits/#durability-and-recovery","title":"Durability and Recovery","text":"<ul> <li>No WAL recovery: There is no write\u2011ahead log to replay after a crash. Durability boundaries are explicit <code>flush()</code> and <code>close()</code>. Writes still in the index write buffer (in\u2011memory <code>UniqueCache</code>) are not durable until flushed. See Recovery.</li> <li>Per\u2011file atomicity only: Writers use temp files + atomic rename; groups of files (e.g., SST + scarce index + bloom) commit in a safe order but not as a single atomic unit. Readers remain consistent because old files stay in place until each rename. See SegmentFullWriterTx, BloomFilterWriterTx.</li> <li>Filesystem requirement: Crash safety relies on same\u2011directory atomic <code>rename</code>. Use local filesystems; be cautious with network filesystems that may not guarantee strict atomicity.</li> <li>Stale lock files: A crash can leave <code>.lock</code> behind, preventing open until removed. See <code>directory/FsFileLock.java</code> and IndexState*. Remove the file only when certain no process still uses the directory.</li> </ul>"},{"location":"architecture/limits/#concurrency","title":"Concurrency","text":"<ul> <li>Default build is not thread\u2011safe: <code>SstIndexImpl</code> favors throughput with no internal locking. Use one writer thread (and coordinate readers), or enable the synchronized variant.</li> <li>Thread\u2011safe mode uses a coarse <code>ReentrantLock</code>: <code>IndexInternalSynchronized</code> serializes all ops; long scans contend with writes. Iterators in this mode take/release the same lock per step.</li> <li>Optimistic iteration: Segment iterators may stop early if a write bumps the version during a scan (by design). Re\u2011open the iterator to continue. See <code>EntryIteratorWithLock</code>.</li> </ul>"},{"location":"architecture/limits/#size-and-addressing-limits","title":"Size and Addressing Limits","text":"<ul> <li>Per\u2011segment SST size bounded by 32\u2011bit positions: Sparse index stores an <code>Integer</code> position and readers cast to <code>int</code> (<code>ChunkEntryFile#openIteratorAtPosition((int)position)</code>). Keep a single <code>.index</code> file below ~2 GiB. Use multiple segments to scale. Code: <code>chunkentryfile/ChunkEntryFile.java</code>, <code>scarceindex/*</code>.</li> <li>Data\u2011block and cell sizing constraints: <code>diskIoBufferSize</code> must be divisible by 1024; chunk cell size is fixed at 16 bytes. Payloads pad to whole cells (space overhead). Code: <code>Vldtn#requireIoBufferSize</code>, <code>chunkstore/CellPosition.java</code>.</li> <li>Log file rollover ceiling: Context logging keeps up to 99,999 files (<code>wal-xxxxx.log</code>). Hitting this throws. Code: <code>log/LogFileNamesManager</code>.</li> </ul>"},{"location":"architecture/limits/#configuration-immutability","title":"Configuration Immutability","text":"<p>Once an index is created, several properties cannot be changed when reopening with a config:</p> <ul> <li>Type descriptors (key/value serialization)</li> <li>Sparse index cadence (<code>maxNumberOfKeysInSegmentChunk</code>)</li> <li>Segment sizing limits (e.g., <code>maxNumberOfKeysInSegment</code>)</li> <li>Bloom filter sizing and hash functions</li> <li>Encoding/decoding filter lists (order and membership)</li> </ul> <p>Attempts to change these raise an error in <code>IndexConfigurationManager.validateThatWasntChanged</code>. To change them, create a new index and bulk\u2011copy data (read + write) or export/import. See <code>sst/IndexConfigurationManager.java</code>.</p>"},{"location":"architecture/limits/#data-model-and-semantics","title":"Data Model and Semantics","text":"<ul> <li>Strictly increasing keys: All on\u2011disk structures assume ascending order; compaction and consistency checks enforce it. Incorrect comparators or inconsistent key ordering will fail. Code: <code>segment/SegmentConsistencyChecker.java</code>.</li> <li>Tombstones: Deletes are tombstones until compaction merges and drops them. Heavy delete workloads without compaction may grow delta files and increase read work.</li> <li>No multi\u2011key transactions: Writes are per\u2011key; there is no cross\u2011key atomic batch. Use application\u2011level coordination if needed.</li> </ul>"},{"location":"architecture/limits/#security-posture","title":"Security Posture","text":"<ul> <li>XOR filter is not encryption: <code>ChunkFilterXorEncrypt</code> provides reversible obfuscation only; do not use as security. For encryption at rest, place HestiaStore on an encrypted volume or add a real crypto layer above. See <code>chunkstore/ChunkFilterXor*</code>.</li> <li>No authentication/authorization: HestiaStore is an embedded library and relies on your process/container isolation.</li> </ul>"},{"location":"architecture/limits/#workloads-that-fit-well","title":"Workloads That Fit Well","text":"<ul> <li>High\u2011throughput append/update workloads where read\u2011after\u2011write visibility matters and periodic flush/compaction is acceptable.</li> <li>Point lookups and ordered scans with predictable latency (Bloom + sparse index bound I/O).</li> </ul>"},{"location":"architecture/limits/#antipatterns","title":"Anti\u2011patterns","text":"<ul> <li>Expecting durability without flush/close.</li> <li>Relying on WAL replay (not implemented).</li> <li>Very large single segments (&gt;2 GiB <code>.index</code>); split into more segments.</li> <li>Heavy mixed concurrent reads/writes with strict low\u2011latency tail in synchronized mode (coarse locking).</li> </ul>"},{"location":"architecture/limits/#mitigations-and-best-practices","title":"Mitigations and Best Practices","text":"<ul> <li>Plan periodic <code>flush()</code> and <code>compact()</code> windows; after crashes run consistency check and optionally compact.</li> <li>Size Bloom filters for your negative\u2011lookup rate; monitor <code>BloomFilterStats</code>.</li> <li>Tune <code>maxNumberOfKeysInSegmentChunk</code> to balance read scan length vs. sparse index size.</li> <li>Use multiple segments to stay under per\u2011segment limits and to improve compaction parallelism (future).</li> </ul>"},{"location":"architecture/limits/#related-docs","title":"Related Docs","text":"<ul> <li>Recovery: <code>architecture/recovery.md</code></li> <li>Concurrency: <code>architecture/concurrency.md</code></li> <li>Filters &amp; Integrity: <code>architecture/filters.md</code></li> <li>On\u2011Disk Layout: <code>architecture/on-disk-layout.md</code></li> </ul>"},{"location":"architecture/on-disk-layout/","title":"On-Disk Layout &amp; File Names","text":"<p>This page documents the files HestiaStore writes into an index directory, their naming conventions, how they evolve over time, and the atomic commit pattern used to keep them consistent.</p>"},{"location":"architecture/on-disk-layout/#directory-layout-one-index-per-directory","title":"Directory Layout (One Index per Directory)","text":"<p>Top-level files: - <code>index.map</code> \u2014 Global key\u2192segment map (max key per segment). Sorted key\u2192SegmentId pairs. Updated atomically. - <code>wal-00000.log</code>, <code>wal-00001.log</code>, \u2026 \u2014 Optional context logs if enabled. Useful for observability; not a recovery WAL.</p> <p>Per\u2011segment files for segment <code>segment-00000</code>: - <code>segment-00000.index</code> \u2014 Main SST in chunked format (ChunkStoreFile). Holds sorted key/value entries in chunks. - <code>segment-00000.scarce</code> \u2014 Sparse index (key\u2192chunk start position) to accelerate probes into <code>.index</code>. - <code>segment-00000.bloom-filter</code> \u2014 Bloom filter backing store for negative lookups. - <code>segment-00000.properties</code> \u2014 Segment properties (counts, delta numbering). - <code>segment-00000.cache</code> \u2014 Optional seed file for the delta cache overlay (may be absent). - <code>segment-00000-delta-000.cache</code>, <code>segment-00000-delta-001.cache</code>, \u2026 \u2014 Per\u2011segment delta cache files created between compactions.</p> <p>Notes: - Segment ids are zero\u2011based and padded: <code>segment-00000</code>, <code>segment-00001</code>, \u2026 - Delta file counters are padded to 3 digits.</p>"},{"location":"architecture/on-disk-layout/#naming-and-extensions","title":"Naming and Extensions","text":"<ul> <li>Main data: <code>.index</code> (chunked SST)</li> <li>Sparse index: <code>.scarce</code> (sorted key\u2192int pointer)</li> <li>Bloom: <code>.bloom-filter</code></li> <li>Segment metadata: <code>.properties</code></li> <li>Delta/overlay: <code>.cache</code> (both seed cache and delta files)</li> <li>Key\u2192segment map: <code>index.map</code></li> <li>Context log: <code>wal-xxxxx.log</code></li> </ul> <p>Code: <code>segment/SegmentFiles.java</code>, <code>sst/KeySegmentCache.java</code>, <code>log/LogFileNamesManager.java</code>.</p>"},{"location":"architecture/on-disk-layout/#atomic-commit-pattern-tmp-rename","title":"Atomic Commit Pattern (<code>*.tmp</code> + rename)","text":"<p>All persistent writers follow the same pattern: 1) <code>openWriter()</code> returns a writer bound to a temporary file (usually <code>*.tmp</code>). 2) Close the writer to flush OS buffers. 3) <code>commit()</code> atomically renames the temp file to its final name.</p> <p>Implications: - A crash never exposes a partially written visible file. At restart, either the old file or the new file is present. - Readers treat missing files as empty where applicable (e.g., no delta files \u21d2 empty overlay).</p> <p>Code pointers: - Delta cache: <code>sorteddatafile/SortedDataFileWriterTx</code> (used by <code>SegmentDeltaCacheWriter</code>) - Main SST: <code>chunkentryfile/ChunkEntryFileWriterTx</code> \u2192 <code>chunkstore/ChunkStoreWriterTx</code> \u2192 <code>datablockfile/DataBlockWriterTx</code> - Sparse index: <code>scarceindex/ScarceIndexWriterTx</code> - Bloom filter: <code>bloomfilter/BloomFilterWriterTx</code> - Unsorted log: <code>unsorteddatafile/UnsortedDataFileWriterTx</code></p>"},{"location":"architecture/on-disk-layout/#segment-lifecycle","title":"Segment Lifecycle","text":"<p>1) New writes accumulate in the index write buffer; on flush they are routed by key into per\u2011segment delta files <code>segment-xxxxx-delta-YYY.cache</code>. 2) Reads consult delta cache first, then <code>.bloom-filter</code> and <code>.scarce</code> to bound the probe into <code>.index</code>. 3) Compaction rewrites <code>.index</code>, <code>.scarce</code>, and <code>.bloom-filter</code> transactionally; on success, delta files are deleted and the in\u2011memory delta cache is cleared. 4) When a segment grows beyond the threshold, it is split: a new <code>segment-xxxxx</code> appears and <code>index.map</code> is updated atomically.</p>"},{"location":"architecture/on-disk-layout/#chunked-sst-anatomy","title":"Chunked SST Anatomy","text":"<p>The <code>.index</code> file is a sequence of fixed\u2011cell chunks stored in a data\u2011block file. Each chunk has: - Header: magic number, version, payload length, CRC32, flags - Payload: a batch of sorted entries, optionally transformed by filters</p> <p>Filters add robustness and optional compression/obfuscation; their flags and order are recorded so the reader can invert them. See \u201cFilters &amp; Integrity\u201d.</p> <p>Code: <code>chunkstore/*</code>, <code>chunkentryfile/*</code>.</p>"},{"location":"architecture/on-disk-layout/#compatibility","title":"Compatibility","text":"<ul> <li>Header fields (magic, version) allow future readers to validate format.</li> <li>Sparse index and Bloom filter are rebuilt during compaction; no upgrade step is required beyond re\u2011writing segments if formats change in the future.</li> </ul>"},{"location":"architecture/on-disk-layout/#example-directory-minimal","title":"Example Directory (minimal)","text":"<pre><code>index.map\nsegment-00000.index\nsegment-00000.scarce\nsegment-00000.bloom-filter\nsegment-00000.properties\nsegment-00000-delta-000.cache   # present until compaction\n# wal-00000.log                 # only if context logging is enabled\n</code></pre>"},{"location":"architecture/on-disk-layout/#related-glossary","title":"Related Glossary","text":"<ul> <li>SegmentId</li> <li>Main SST</li> <li>Sparse Index</li> <li>Bloom Filter</li> <li>Key-to-Segment Map</li> <li>Delta Cache</li> <li>Write Transaction</li> </ul>"},{"location":"architecture/performance/","title":"Performance Model &amp; Sizing","text":"<p>This page summarizes how HestiaStore achieves high throughput and predictable latency, and how to size the main knobs. All claims map to code so you can verify behavior.</p>"},{"location":"architecture/performance/#mental-model-hot-paths","title":"Mental Model (Hot Paths)","text":"<ul> <li>Put/Delete:</li> <li>O(1) to update in\u2011memory write buffer (<code>UniqueCache</code>).</li> <li>Batched flush sorts unique keys (parallel sort over entries) and writes per\u2011segment delta files sequentially.</li> <li> <p>Optional compaction merges delta files into the main SST (sequential chunk write).</p> </li> <li> <p>Get (negative):</p> </li> <li> <p>O(k) Bloom probe (k = hash functions), no disk I/O when filter says \u201cabsent\u201d.</p> </li> <li> <p>Get (positive):</p> </li> <li>Locate target segment via key\u2192segment map (in\u2011memory TreeMap ceiling lookup).</li> <li>Seek into <code>.index</code> by sparse index pointer, then bounded local scan of at most <code>maxNumberOfKeysInSegmentChunk</code> entries in ascending order. Typically one chunk read.</li> </ul>"},{"location":"architecture/performance/#io-patterns-and-amplification","title":"I/O Patterns and Amplification","text":"<ul> <li>Sequential writes: delta files and SST chunks append sequentially via transactional writers (<code>*.tmp</code> + rename).</li> <li>Sequential reads: positive get reads one chunk and scans \u2264 N keys (N = <code>maxNumberOfKeysInSegmentChunk</code>).</li> <li>Negative reads: avoid disk I/O via Bloom filter unless false positive.</li> <li>Alignment and block size:</li> <li>Chunk store uses fixed 16\u2011byte cells with data blocks sized by <code>diskIoBufferSize</code> (divisible by 1024). Payloads are padded to whole cells for easy positioning.</li> <li>Code: <code>chunkstore/CellPosition.java</code>, <code>datablockfile/DataBlockSize.java</code>, <code>Vldtn#requireIoBufferSize</code>.</li> </ul>"},{"location":"architecture/performance/#key-knobs-what-they-do","title":"Key Knobs (What They Do)","text":"<ul> <li><code>maxNumberOfKeysInCache</code> (index\u2011level write buffer)</li> <li> <p>Higher \u21d2 fewer flushes, larger batches, better write throughput; uses more RAM during bursts.</p> </li> <li> <p><code>maxNumberOfKeysInSegmentChunk</code> (sparse index cadence)</p> </li> <li> <p>Lower \u21d2 smaller local scan window (read latency) with more sparse\u2011index entries; slightly more write work during compaction.</p> </li> <li> <p>Bloom filter sizing: <code>bloomFilterIndexSizeInBytes</code>, <code>bloomFilterNumberOfHashFunctions</code>, or target probability</p> </li> <li>From <code>BloomFilterBuilder</code>: m = \u2212(n ln p)/(ln2)^2, k \u2248 m/n\u00b7ln2. Larger m lowers false positives and I/O on negative lookups at the cost of RAM and disk for the filter.</li> <li> <p>Code: <code>bloomfilter/BloomFilterBuilder.java</code>.</p> </li> <li> <p><code>maxNumberOfSegmentsInCache</code> (SegmentData LRU)</p> </li> <li> <p>Number of segments whose Bloom + sparse index + delta cache can be resident. Too small \u21d2 thrash; too large \u21d2 memory waste.</p> </li> <li> <p><code>diskIoBufferSize</code></p> </li> <li> <p>Sets data\u2011block size for chunk store and buffers for file readers/writers. Choose 4\u201364 KiB depending on device. Must be divisible by 1024.</p> </li> <li> <p>Encoding/Decoding filters (CRC, magic, Snappy, XOR)</p> </li> <li> <p>Snappy reduces I/O on compressible values at CPU cost. CRC + magic are lightweight integrity guards and on by default.</p> </li> <li> <p>Context logging (<code>isContextLoggingEnabled</code>)</p> </li> <li>Writes an unsorted log entry per operation for observability. Disable if you need minimum overhead.</li> </ul>"},{"location":"architecture/performance/#memory-sizing","title":"Memory Sizing","text":"<ul> <li>Index write buffer: up to <code>maxNumberOfKeysInCache</code> entries (latest per key). Backed by a HashMap.</li> <li>Per\u2011segment delta overlay (in memory): when a segment is loaded, delta files are folded into a <code>UniqueCache</code>. Upper bound approximates number of unique keys across delta files (see segment properties).</li> <li>Bloom filter: fully memory\u2011mapped in RAM when present; <code>indexSizeInBytes</code> bytes per segment plus metadata. Code: <code>bloomfilter/BloomFilterImpl.java</code>.</li> <li>SegmentData LRU: holds delta cache + Bloom + scarce index for up to <code>maxNumberOfSegmentsInCache</code> segments; evictions call <code>close()</code> to free memory.</li> </ul>"},{"location":"architecture/performance/#cpu-sizing","title":"CPU Sizing","text":"<ul> <li>Put path: hashing and HashMap work; occasional sort on flush (parallel sort over entries) and CRC/magic/Snappy filters on compaction.</li> <li>Get path: a few compares, at most N key compares during the bounded scan, optional Snappy decompression on read.</li> <li>Enabling context logging adds a small write per operation.</li> </ul>"},{"location":"architecture/performance/#practical-tuning-recipes","title":"Practical Tuning Recipes","text":"<ul> <li>Write\u2011heavy ingestion:</li> <li>Increase <code>maxNumberOfKeysInCache</code> to batch and reduce flushes.</li> <li>Consider enabling Snappy if values are highly compressible and I/O bound.</li> <li> <p>Keep <code>maxNumberOfKeysInSegmentChunk</code> moderate (e.g., 512\u20132048) to keep sparse index size reasonable during compaction.</p> </li> <li> <p>Read\u2011latency sensitive point lookups:</p> </li> <li>Ensure Bloom filters are sized adequately (lower false positive rate with larger <code>indexSizeInBytes</code>).</li> <li>Reduce <code>maxNumberOfKeysInSegmentChunk</code> to shrink the local scan window.</li> <li> <p>Increase <code>maxNumberOfSegmentsInCache</code> so hot segments stay resident.</p> </li> <li> <p>Mixed workloads:</p> </li> <li>Start with defaults; adjust Bloom size and segment LRU to fit your hot set; validate with counters and filter stats.</li> </ul>"},{"location":"architecture/performance/#observability-and-validation","title":"Observability and Validation","text":"<ul> <li>Bloom stats: <code>BloomFilter.getStatistics()</code> reports avoided disk accesses and false\u2011positive rate. Code: <code>bloomfilter/BloomFilterStats</code>.</li> <li>Operation counters: <code>sst/Stats</code> exposes get/put/delete counts (logged on close in <code>SstIndexImpl#doClose</code>).</li> <li>Consistency: after unexpected shutdown, run <code>Index.checkAndRepairConsistency()</code>; optionally <code>compact()</code> to reclaim locality.</li> </ul>"},{"location":"architecture/performance/#code-pointers","title":"Code Pointers","text":"<ul> <li>Write buffer and flush: <code>src/main/java/org/hestiastore/index/sst/SstIndexImpl.java</code>, <code>src/main/java/org/hestiastore/index/sst/CompactSupport.java</code></li> <li>Read path bounds: <code>src/main/java/org/hestiastore/index/segment/SegmentSearcher.java</code>, <code>.../SegmentIndexSearcher.java</code></li> <li>Bloom filter: <code>src/main/java/org/hestiastore/index/bloomfilter/*</code></li> <li>Chunked I/O and filters: <code>src/main/java/org/hestiastore/index/chunkstore/*</code></li> <li>Segment sizing/splitting: <code>src/main/java/org/hestiastore/index/sst/SegmentSplitCoordinator.java</code>, <code>src/main/java/org/hestiastore/index/segment/SegmentSplitter*.java</code></li> </ul>"},{"location":"architecture/performance/#related-glossary","title":"Related Glossary","text":"<ul> <li>Main SST</li> <li>Sparse Index</li> <li>Bloom Filter</li> <li>UniqueCache</li> <li>Delta Cache</li> <li>Compaction</li> <li>Write Transaction</li> </ul>"},{"location":"architecture/read-path/","title":"Read Path","text":"<p>This page explains how reads resolve values with low latency and predictable I/O. It walks through point lookups, range iteration, and the interplay of caches, Bloom filter, and the sparse index, mapped to concrete classes in the codebase.</p>"},{"location":"architecture/read-path/#highlevel-flow-point-lookup","title":"High\u2011Level Flow (Point Lookup)","text":"<ol> <li>API call: <code>Index.get(key)</code></li> <li>Check the index\u2011level unique buffer (latest in\u2011process writes)</li> <li>Locate the target segment using the key\u2192segment map</li> <li>Inside the segment: consult delta cache \u2192 Bloom filter \u2192 sparse index \u2192 local scan</li> </ol> <p>Lookups are read\u2011after\u2011write consistent thanks to the in\u2011memory buffers.</p>"},{"location":"architecture/read-path/#entry-point-and-firstlevel-cache","title":"Entry Point and First\u2011Level Cache","text":"<ul> <li><code>sst/SstIndexImpl#get(K)</code> does:</li> <li>Check the index\u2011level <code>UniqueCache</code> (holds latest writes prior to flush)</li> <li>If miss, find <code>SegmentId</code> via <code>KeySegmentCache.findSegmentId(key)</code></li> <li>Delegate to <code>Segment.get(key)</code></li> </ul> <p>Key classes: <code>sst/SstIndexImpl.java</code>, <code>sst/KeySegmentCache.java</code>, <code>cache/UniqueCache.java</code>.</p>"},{"location":"architecture/read-path/#behavior","title":"Behavior","text":"<ul> <li>Cache hit and non\u2011tombstone \u2192 return value</li> <li>Cache hit and tombstone \u2192 treat as absent</li> <li>Otherwise fall back to the segment path below</li> </ul>"},{"location":"architecture/read-path/#persegment-read-path","title":"Per\u2011Segment Read Path","text":"<p><code>segment/SegmentImpl#get(key)</code> uses <code>SegmentSearcher</code> with lazily loaded segment data:</p> <ol> <li>Delta cache probe: in\u2011memory map of the segment\u2019s pending updates (merged from delta files). If hit and value not a tombstone \u2192 return; tombstone \u2192 absent.</li> <li>Bloom filter: <code>bloomFilter.isNotStored(key)</code> guards the on\u2011disk path. If \u201cnot stored\u201d \u2192 absent.</li> <li>Sparse index (\"scarce index\"): returns a chunk start position for keys \u2265 query.</li> <li>Local scan: within at most N keys (<code>maxNumberOfKeysInIndexPage</code>) starting at that chunk, compare keys in ascending order and stop as soon as the target is found or passed.</li> <li>If the sparse index pointed us into the file but no exact key was found, mark a false positive on the Bloom filter for metrics and return absent.</li> </ol> <p>Key classes: <code>segment/SegmentSearcher.java</code>, <code>segment/SegmentIndexSearcher.java</code>, <code>scarceindex/ScarceIndex.java</code>, <code>bloomfilter/BloomFilter.java</code>.</p>"},{"location":"architecture/read-path/#range-scans-and-full-iteration","title":"Range Scans and Full Iteration","text":"<ul> <li><code>Index.getStream()</code> and <code>Index.openSegmentIterator(...)</code> produce iterators over all data:</li> <li><code>sst/SegmentsIterator</code> chains <code>Segment.openIterator()</code> across all segments in order.</li> <li><code>segment/SegmentImpl.openIterator()</code> merges the on\u2011disk main SST with the segment\u2019s delta cache via <code>MergeDeltaCacheWithIndexIterator</code>, skipping tombstones.</li> <li>The per\u2011segment iterator is wrapped with <code>EntryIteratorWithLock</code> using an <code>OptimisticLock</code>. If a write changes the segment version mid\u2011scan, the iterator stops gracefully (no partial records).</li> <li>At the top level, <code>EntryIteratorRefreshedFromCache</code> overlays the index\u2011level unique buffer so that the iterator sees the latest writes even before they\u2019re flushed to disk.</li> </ul> <p>Key classes: <code>sst/SegmentsIterator.java</code>, <code>segment/MergeDeltaCacheWithIndexIterator.java</code>, <code>sst/EntryIteratorRefreshedFromCache.java</code>, <code>EntryIteratorWithLock.java</code>, <code>OptimisticLock.java</code>.</p>"},{"location":"architecture/read-path/#readafterwrite-semantics","title":"Read\u2011After\u2011Write Semantics","text":"<p>Two layers provide immediate visibility of recent writes:</p> <ul> <li>Index\u2011level <code>UniqueCache</code> (pre\u2011flush) is checked first by <code>Index.get</code> and overlaid on iterators.</li> <li>Segment delta cache (post\u2011flush) is kept in memory when loaded; writes to a new delta file also update the in\u2011memory delta cache when present.</li> </ul> <p>Deletes are represented as tombstones by the value type descriptor. The read path treats a tombstone as \u201cnot found\u201d.</p>"},{"location":"architecture/read-path/#complexity-and-io-characteristics","title":"Complexity and I/O Characteristics","text":"<ul> <li>Index\u2011level cache probe: O(1) hash map</li> <li>Segment delta cache probe: O(1) hash map</li> <li>Bloom filter probe: O(k) where k is number of hash functions; no I/O</li> <li>Sparse index probe: in\u2011memory list search over a small sample set (fast, cache\u2011friendly)</li> <li>Local scan: sequential read within one chunk window of up to <code>maxNumberOfKeysInIndexPage</code> entries</li> <li>Iterators: sequential over chunks; minimal seeks due to chunked layout</li> </ul> <p>These choices keep random access bounded and predictable, with sequential I/O for scans.</p>"},{"location":"architecture/read-path/#configuration-knobs-affecting-reads","title":"Configuration Knobs Affecting Reads","text":"<ul> <li><code>maxNumberOfKeysInSegmentChunk</code> \u2014 upper bound of keys per chunk; also the window size for a local scan from the sparse index pointer</li> <li>Bloom filter parameters \u2014 <code>numberOfHashFunctions</code>, <code>indexSizeInBytes</code>, <code>falsePositiveProbability</code></li> <li><code>diskIoBufferSize</code> \u2014 affects chunk and data block I/O buffering</li> <li>Encoding/decoding filters \u2014 enable CRC32, magic number and optional Snappy compression on read/write paths</li> </ul> <p>See: <code>sst/IndexConfiguration</code> and <code>segment/SegmentConf</code>.</p>"},{"location":"architecture/read-path/#integrity-on-the-read-path","title":"Integrity on the Read Path","text":"<p>Decoding applies the inverse of the write pipeline when reading chunks:</p> <ul> <li>Validate magic number</li> <li>Verify CRC32</li> <li>Decompress (if Snappy was enabled)</li> </ul> <p>Errors surface as exceptions; partial reads do not corrupt state.</p> <p>Key classes: <code>chunkstore/ChunkStoreReaderImpl</code>, <code>chunkstore/ChunkFilterMagicNumberValidation</code>, <code>chunkstore/ChunkFilterCrc32Validation</code>, <code>chunkstore/ChunkFilterSnappyDecompress</code>.</p>"},{"location":"architecture/read-path/#where-to-look-in-the-code","title":"Where to Look in the Code","text":"<ul> <li>Point lookup orchestration: <code>src/main/java/org/hestiastore/index/sst/SstIndexImpl.java</code></li> <li>Segment search path: <code>src/main/java/org/hestiastore/index/segment/SegmentSearcher.java</code></li> <li>Sparse index: <code>src/main/java/org/hestiastore/index/scarceindex/*</code></li> <li>Iteration and merging: <code>src/main/java/org/hestiastore/index/segment/MergeDeltaCacheWithIndexIterator.java</code></li> <li>Iterator safety: <code>src/main/java/org/hestiastore/index/EntryIteratorWithLock.java</code></li> </ul>"},{"location":"architecture/read-path/#related-glossary","title":"Related Glossary","text":"<ul> <li>Segment</li> <li>Delta Cache</li> <li>Bloom Filter</li> <li>Sparse Index</li> <li>UniqueCache</li> <li>EntryIterator</li> <li>SegmentWindow</li> </ul>"},{"location":"architecture/recovery/","title":"Consistency &amp; Recovery","text":"<p>This page explains HestiaStore\u2019s crash safety model and commit semantics. There is no WAL\u2011based crash recovery or multi\u2011operation transactions. Durability is driven by explicit flushes and by the fact that all data files are written via temporary files and atomically renamed on commit.</p>"},{"location":"architecture/recovery/#scope-and-guarantees","title":"Scope and Guarantees","text":"<ul> <li>No automatic recovery: the system does not replay a WAL or roll back partial groups of operations after a crash.</li> <li>Durability boundary: calling <code>flush()</code> or closing the index persists all writes that happened before the call. Writes that are only in memory (index\u2011level buffer) and not flushed are not durable.</li> <li>Atomic file replacement: data files are written to <code>*.tmp</code> and made visible via <code>rename</code> only after the writer is closed and the transaction is committed. A crash cannot produce partially written visible files.</li> </ul>"},{"location":"architecture/recovery/#where-writes-become-durable","title":"Where Writes Become Durable","text":"<ul> <li>Index\u2011level buffer \u2192 disk: <code>Index.flush()</code> drains the in\u2011memory unique buffer into segment delta cache files. On close, the index also flushes.</li> <li>Segment merge/compaction: when a segment compacts, the new main SST, sparse index, and Bloom filter are built via transactional writers; on commit they atomically replace the old ones.</li> <li>Key\u2192segment map (<code>index.map</code>): persisted via a transactional sorted data writer during flush or when updated.</li> </ul> <p>Relevant code: <code>sst/SstIndexImpl#flush()</code>, <code>sst/CompactSupport</code>, <code>sst/KeySegmentCache#optionalyFlush()</code>.</p>"},{"location":"architecture/recovery/#transactional-write-primitives","title":"Transactional Write Primitives","text":"<p>All main data files follow the same pattern: write to a temporary file, then atomically rename on <code>commit()</code>.</p> <ul> <li>Guarded transactions: <code>GuardedWriteTransaction</code> requires the resource to be closed before <code>commit()</code> and prevents double\u2011commit.</li> <li>Single\u2011call helper: <code>WriteTransaction.execute(writer -&gt; { \u2026 })</code> does open \u2192 write \u2192 close \u2192 commit.</li> </ul> <p>Key classes: - <code>unsorteddatafile/UnsortedDataFileWriterTx</code> \u2192 <code>rename(temp, final)</code> on commit - <code>sorteddatafile/SortedDataFileWriterTx</code> \u2192 <code>rename(temp, final)</code> on commit - <code>datablockfile/DataBlockWriterTx</code> \u2192 used by chunk store writers - <code>chunkstore/ChunkStoreWriterTx</code> and <code>chunkentryfile/ChunkEntryFileWriterTx</code> \u2192 layered over <code>DataBlockWriterTx</code> - <code>bloomfilter/BloomFilterWriterTx</code> \u2192 writes new filter and swaps it in on commit</p>"},{"location":"architecture/recovery/#file-types-and-commit-paths","title":"File Types and Commit Paths","text":"<ul> <li>Segment delta cache files</li> <li>Writer: <code>segment/SegmentDeltaCacheWriter</code></li> <li>Mechanism: <code>SortedDataFileWriterTx.execute(\u2026)</code></li> <li> <p>Naming: property counter assigns <code>segmentId-delta-XXX.cache</code> before write; if a crash happens before commit, the reader treats missing files as empty, so boot remains safe.</p> </li> <li> <p>Main SST (chunked) + sparse index (\"scarce index\")</p> </li> <li>Writers: <code>segment/SegmentFullWriterTx</code> and <code>segment/SegmentFullWriter</code></li> <li>Internals: <code>ChunkEntryFileWriterTx</code> for SST, <code>ScarceIndexWriterTx</code> for the sparse index</li> <li> <p>Bloom filter: <code>BloomFilterWriterTx</code> builds a new filter and commits (rename) before the SST and sparse index are committed. This ordering avoids false negatives on restart.</p> </li> <li> <p>Bloom filter</p> </li> <li> <p>Writes to a temporary file via <code>BloomFilterWriterTx.open()</code> and commits with <code>rename</code>; also updates the in\u2011memory hash snapshot on commit.</p> </li> <li> <p>Key\u2192segment map (<code>index.map</code>)</p> </li> <li>Writer: <code>SortedDataFileWriterTx.execute(\u2026)</code> inside <code>KeySegmentCache.optionalyFlush()</code></li> <li>Ensures the map is replaced atomically.</li> </ul>"},{"location":"architecture/recovery/#what-is-not-transactional","title":"What Is Not Transactional","text":"<ul> <li>Segment properties (counts and delta\u2011file numbering) are persisted via an overwrite (<code>Directory.Access.OVERWRITE</code>). They are updated after data files are committed, and are not critical to data correctness. If a crash corrupts or desynchronizes this metadata, the reader logic remains safe (e.g., missing delta file names yield empty reads) and you can re\u2011establish consistency via the checker below.</li> </ul> <p>Code: <code>properties/PropertyStoreimpl</code> and <code>SegmentPropertiesManager</code>.</p>"},{"location":"architecture/recovery/#failure-model-examples","title":"Failure Model (Examples)","text":"<ul> <li>Crash while writing a delta file before commit: only <code>*.tmp</code> exists; it is ignored on boot; prior state remains valid.</li> <li>Crash after committing a Bloom filter but before committing SST/sparse index: Bloom filter is ahead of data, which is safe (may increase positives but never produce false negatives).</li> <li>Crash after committing SST/sparse index but before properties update: data is fully committed; metadata may lag but does not affect correctness.</li> </ul>"},{"location":"architecture/recovery/#consistency-check-and-repair","title":"Consistency Check and Repair","text":"<ul> <li>Run <code>Index.checkAndRepairConsistency()</code> after an unexpected shutdown to verify that segments are well\u2011formed and sorted and that the key\u2192segment map is coherent. This walks all segments, checks ordering and basic invariants, and raises an error if it finds non\u2011recoverable issues.</li> </ul> <p>Key classes: <code>sst/IndexConsistencyChecker</code>, <code>segment/SegmentConsistencyChecker</code>.</p>"},{"location":"architecture/recovery/#developer-notes-opencommit-and-tmp","title":"Developer Notes: <code>open()</code>/<code>commit()</code> and <code>*.tmp</code>","text":"<ul> <li><code>open()</code> returns a writer bound to a temporary file (typically with a <code>.tmp</code> suffix). You must close the writer before calling <code>commit()</code>.</li> <li><code>commit()</code> performs an atomic <code>rename(temp, final)</code> so either the old file or the new file is visible on disk.</li> <li>Prefer <code>execute(writer -&gt; {\u2026})</code> to ensure the correct order: open \u2192 write \u2192 close \u2192 commit.</li> </ul> <p>Examples in code: - <code>sorteddatafile/SortedDataFileWriterTx#open()</code> \u2192 <code>commit()</code> renames temp to final - <code>unsorteddatafile/UnsortedDataFileWriterTx#open()</code> \u2192 <code>commit()</code> renames temp to final - <code>datablockfile/DataBlockWriterTx#open()</code> \u2192 <code>commit()</code> renames temp to final - <code>bloomfilter/BloomFilterWriterTx#open()</code> \u2192 <code>commit()</code> renames temp to final and swaps hash</p>"},{"location":"architecture/recovery/#practical-guidance","title":"Practical Guidance","text":"<ul> <li>Call <code>flush()</code> on periodic boundaries and always before shutdown to persist in\u2011memory writes.</li> <li>After a crash, reopen the index and run <code>checkAndRepairConsistency()</code>; optionally trigger a <code>compact()</code> to collapse delta caches.</li> <li>Remember there is no WAL: durability is guaranteed at the <code>flush()</code>/close boundaries and via atomic file replacement for all data files.</li> </ul>"},{"location":"architecture/recovery/#related-glossary","title":"Related Glossary","text":"<ul> <li>Flush</li> <li>Write Transaction</li> <li>Compaction</li> <li>Consistency Checker</li> </ul>"},{"location":"architecture/segment/","title":"Segment implementation","text":"<p>Segment is core part of index. It represents one string sorted table file with:</p> <ul> <li>Partial consistency - iterator stop working or return consistent data</li> <li>Support Writing changes into delta files</li> <li>Bloom filter for faster evaluating if key is in index</li> <li>Scarce index for faster searching for data in main index</li> </ul>"},{"location":"architecture/segment/#segment-putget-and-iterate-consistency","title":"Segment put/get and iterate consistency","text":"<p>operations like write and get should be always consistent. What is written is read. Iteration behave differently. better than provide old data it stop providing any data.</p> <p>Let's have a followin key value entries in main index:</p> <pre><code>&lt;a, 20 &gt;\n&lt;b, 30 &gt;\n&lt;c, 40 &gt;\n</code></pre> <p>In segment cache are following entries:</p> <pre><code>&lt;a, 25&gt;\n&lt;e, 28&gt;\n&lt;b, tombstone&gt;\n</code></pre> <p>When user will iterate throught segment data, there will be followin cases:</p>"},{"location":"architecture/segment/#case-1-read-data","title":"Case 1 - Read data","text":"<pre><code>iterator.read() --&gt; &lt;a, 25&gt;\niterator.read() --&gt; &lt;c, 40&gt;\niterator.read() --&gt; &lt;e, 28&gt;\n</code></pre>"},{"location":"architecture/segment/#case-2-change-data","title":"Case 2 - Change data","text":"<pre><code>iterator.read() --&gt; &lt;a, 25&gt;\nsegment.write(c, 10)\niterator.read() --&gt; null\n</code></pre> <p>Any segment write operation will break segment iterator. It's easier way to secure segment consistency.  </p>"},{"location":"architecture/segment/#caching-of-segment-data","title":"Caching of segment data","text":"<p>In segment following object are cached:</p> <ul> <li>SegmentDeltaCache - contains changed key value entry from segment</li> <li>BloomFilter - bloom filter data</li> <li>ScarceIndex - scarce index data</li> </ul> <p>There are few classes that provide lazy loading of segment data a flexibility to cache segment data. Segment data are managed by following classes: </p> <p></p> <p>Object <code>SegmentData</code> could contains objects <code>SegmentDeltaCache</code>, <code>BloomFilter</code> and <code>ScarceIndex</code>. All of them are lazy loaded by <code>SegmentDataSupplier</code>. For closer class description look at source code.</p> <p>The following image shows that <code>SegmentDatafactory</code> can be referenced from <code>SegmentDataProviderSimple</code>, which is the simplest implementation that merely holds segment data from the factory. The class <code>SegmentDataProviderFromMainCache</code> interacts with the main index cache where the segment data is stored. Data may be evicted from the cache without any notification.</p> <p></p>"},{"location":"architecture/segment/#writing-to-segment","title":"Writing to segment","text":"<p>Opening segment writer immediatelly close all segment readers. When writing operation add key that is in index but is not in cache this value will not returned updated. </p> <p>Putting new entry into segment is here:</p> <p></p>"},{"location":"architecture/write-path/","title":"Write Path","text":"<p>This page describes how a write travels through HestiaStore from the API call to on\u2011disk structures, highlighting buffering, compaction, and atomicity. It maps directly to the code so you can cross\u2011check behavior and tune configuration.</p>"},{"location":"architecture/write-path/#highlevel-flow","title":"High\u2011Level Flow","text":"<ol> <li>API call: <code>Index.put(key, value)</code> or <code>Index.delete(key)</code></li> <li>Optional context log append (debug/trace log, not a durability WAL)</li> <li>In\u2011memory unique write buffer accepts the latest value per key</li> <li>Threshold\u2011based flush routes buffered writes to target segments</li> <li>Segment delta caches persist sorted updates as transactional files</li> <li>Segment compaction merges delta caches into the main SST + sparse index + bloom filter</li> <li>Optional segment split when size thresholds are exceeded</li> </ol> <p>Writes become durable when flushed to segment files. Closing the index performs a flush.</p>"},{"location":"architecture/write-path/#entry-points","title":"Entry Points","text":"<ul> <li><code>Index.put(K,V)</code> and <code>Index.delete(K)</code> validate input, update counters, and delegate to the internal implementation.</li> <li>Two internal variants exist:</li> <li>Default: <code>IndexInternalDefault</code> (non\u2011synchronized)</li> <li>Synchronized: <code>IndexInternalSynchronized</code> (for thread\u2011safe access)</li> </ul> <p>Key classes: <code>sst/Index.java</code>, <code>sst/IndexInternalDefault.java</code>.</p>"},{"location":"architecture/write-path/#optional-context-log","title":"Optional Context Log","text":"<p>If <code>IndexConfiguration.isContextLoggingEnabled()</code> is true, each write is mirrored to an append\u2011only log file under <code>docs</code> directory using type\u2011safe serializers. This is intended for observability and debugging, not recovery. The writer rotates on flush or close to start a new file. When disabled, a no\u2011op log is used.</p> <p>Key classes: <code>log/LogImpl</code>, <code>log/LogWriter</code>, <code>log/LogUnsortedFileWriterImpl</code>, <code>log/LoggedKey</code>.</p> <p>Notes:</p> <ul> <li>The log is not used for crash recovery; a real write\u2011ahead log is on the roadmap.</li> <li>Log files are written via transactional temp files and atomic rename on rotate.</li> </ul>"},{"location":"architecture/write-path/#unique-write-buffer-indexlevel","title":"Unique Write Buffer (Index\u2011Level)","text":"<p>Every <code>put</code>/<code>delete</code> is first stored in an in\u2011memory unique cache that holds only the latest value per key. When the buffer exceeds <code>maxNumberOfKeysInCache</code>, the index flushes.</p> <ul> <li>Structure: <code>UniqueCache</code> keyed by K with comparator ordering.</li> <li>Behavior:</li> <li>New write replaces any previous value for the same key.</li> <li>Reads consult this buffer first (read\u2011after\u2011write visibility without disk I/O).</li> <li>Deletes are represented as a tombstone value from the value type descriptor.</li> <li>Trigger: <code>cache.size() &gt; conf.getMaxNumberOfKeysInCache()</code> calls <code>flushCache()</code>.</li> </ul> <p>Key classes: <code>cache/UniqueCache</code>, <code>sst/SstIndexImpl#put</code>, <code>sst/SstIndexImpl#delete</code>.</p>"},{"location":"architecture/write-path/#flush-and-routing-to-segments","title":"Flush and Routing to Segments","text":"<p>On flush, buffered entries are sorted and routed to target segments based on the key\u2011to\u2011segment map. Routing is incremental and batched per target segment for locality.</p> <p>Flow:</p> <p>1) Sort unique cache entries by key. 2) For each key, find the target segment id via <code>KeySegmentCache.insertKeyToSegment</code>. 3) Buffer entries to the current segment; when switching segments, write the batch to that segment\u2019s delta cache and continue. 4) After all entries are written, optionally split segments that exceed size thresholds. 5) Clear the unique buffer, flush the key\u2011segment map (if changed), and rotate the context log.</p> <p>Key classes: <code>sst/CompactSupport</code>, <code>sst/KeySegmentCache</code>, <code>sst/SegmentSplitCoordinator</code>.</p>"},{"location":"architecture/write-path/#segment-delta-cache-files-transactional","title":"Segment Delta Cache Files (Transactional)","text":"<p>Writes land in a segment\u2019s delta cache as sorted key/value files. Each delta file is written transactionally:</p> <ul> <li>Data is written to <code>segmentId-delta-XXX.cache.tmp</code> and atomically renamed on commit.</li> <li>Segment properties track counts and delta file numbering.</li> <li>If the segment data is currently cached in memory, the delta cache is also updated in\u2011memory to keep reads fresh.</li> </ul> <p>Key classes: <code>segment/SegmentDeltaCacheWriter</code>, <code>segment/SegmentPropertiesManager</code>, <code>sorteddatafile/SortedDataFileWriterTx</code>.</p>"},{"location":"architecture/write-path/#ondisk-merge-compaction","title":"On\u2011Disk Merge (Compaction)","text":"<p>Compaction merges the main SST with all delta cache files into a new consistent state and rebuilds auxiliary structures:</p> <ul> <li>Main SST (chunked file) written via <code>ChunkEntryFileWriter</code> and <code>ChunkStoreWriterTx</code>.</li> <li>Sparse index (\"scarce index\") updated every Nth key to accelerate seeks.</li> <li>Bloom filter rebuilt from keys to accelerate negative lookups.</li> <li>Delta cache is cleared on successful commit.</li> </ul> <p>Triggers:</p> <ul> <li>Opportunistic: after delta writes, if policy advises compaction.</li> <li>Forced: explicitly via <code>compact()</code> or before certain operations like splitting.</li> </ul> <p>Atomicity:</p> <ul> <li>All writers use temp files (<code>.tmp</code>) and <code>rename</code> to commit.</li> <li>Bloom filter writes inside a dedicated transaction (<code>BloomFilterWriterTx</code>).</li> </ul> <p>Key classes: <code>segment/SegmentCompacter</code>, <code>segment/SegmentFullWriterTx</code>, <code>segment/SegmentFullWriter</code>, <code>bloomfilter/BloomFilterWriterTx</code>, <code>scarceindex/*</code>.</p>"},{"location":"architecture/write-path/#segment-splitting","title":"Segment Splitting","text":"<p>When a segment grows beyond <code>maxNumberOfKeysInSegment</code>, the split coordinator computes a plan, optionally compacts first, and then splits into two segments. The key\u2011to\u2011segment map is updated with the new segment\u2019s max key.</p> <p>Key classes: <code>sst/SegmentSplitCoordinator</code>, <code>segment/SegmentSplitter</code>, <code>segment/SegmentSplitterPlan</code>, <code>sst/KeySegmentCache</code>.</p>"},{"location":"architecture/write-path/#delete-semantics-tombstones","title":"Delete Semantics (Tombstones)","text":"<p>Deletes write a tombstone value:</p> <ul> <li>Buffered in the unique cache and delta cache like any other update.</li> <li>During compaction, tombstones suppress older values and may be dropped if safe.</li> <li>Reads treat tombstones as absent.</li> </ul> <p>Key classes: <code>sst/SstIndexImpl#delete</code>, <code>datatype/TypeDescriptor#getTombstone</code>, <code>segment/SegmentSearcher</code>.</p>"},{"location":"architecture/write-path/#durability-and-atomicity","title":"Durability and Atomicity","text":"<ul> <li>Transactional writers use a temp file + atomic rename to ensure either the old state or the new state is visible after a crash.</li> <li>Index <code>close()</code> and explicit <code>flush()</code> drive persistence of buffered writes.</li> <li>Optional context log is not a durability mechanism; it rotates on flush.</li> </ul>"},{"location":"architecture/write-path/#configuration-knobs-affecting-writes","title":"Configuration Knobs Affecting Writes","text":"<ul> <li><code>maxNumberOfKeysInCache</code> \u2013 triggers flush of the index\u2011level buffer.</li> <li><code>maxNumberOfKeysInSegmentCache</code> / <code>\u2026DuringFlushing</code> \u2013 bounds delta cache growth.</li> <li><code>maxNumberOfKeysInSegmentChunk</code> \u2013 controls sparse index sampling cadence.</li> <li><code>maxNumberOfKeysInSegment</code> \u2013 split threshold per segment.</li> <li><code>bloomFilter*</code> \u2013 Bloom filter size/hash tuning.</li> <li><code>diskIoBufferSize</code> \u2013 I/O buffer sizing for on\u2011disk writers.</li> <li><code>encoding/decodingChunkFilters</code> \u2013 write/read pipelines (e.g., Snappy, CRC32, magic number).</li> <li><code>threadSafe</code> \u2013 choose synchronized index variant.</li> </ul> <p>See: <code>sst/IndexConfiguration</code> and <code>sst/IndexConfigurationBuilder</code>.</p>"},{"location":"architecture/write-path/#integrity-filters-on-the-write-path","title":"Integrity Filters on the Write Path","text":"<p>The chunk writer applies a filter pipeline when persisting chunk payloads:</p> <ul> <li>Magic number writing</li> <li>CRC32 computation</li> <li>Optional Snappy compression</li> </ul> <p>These produce a self\u2011describing chunk header and robust payload handling.</p> <p>Key classes: <code>chunkstore/ChunkProcessor</code>, <code>chunkstore/ChunkFilterMagicNumberWriting</code>, <code>chunkstore/ChunkFilterCrc32Writing</code>, <code>chunkstore/ChunkFilterSnappyCompress</code>.</p>"},{"location":"architecture/write-path/#sequence-put","title":"Sequence (Put)","text":"<p>1) <code>Index.put(k,v)</code> \u2192 validate inputs; forbid direct tombstone values 2) Optional: append to context log and keep writer open until rotate 3) Buffer latest <code>(k,v)</code> into unique cache (replaces any prior value for k) 4) If buffer over threshold \u2192 flushCache:    - Route sorted entries by key to segments    - For each target segment: write a new delta cache file (transactional)    - Optionally compact the segment and optionally split if too large    - Clear unique cache, flush key\u2011segment map, rotate log</p>"},{"location":"architecture/write-path/#where-to-look-in-the-code","title":"Where to Look in the Code","text":"<ul> <li>Index entry points and buffering: <code>src/main/java/org/hestiastore/index/sst/SstIndexImpl.java</code></li> <li>Segment write/merge path: <code>src/main/java/org/hestiastore/index/segment/*</code></li> <li>Chunk store and filters: <code>src/main/java/org/hestiastore/index/chunkstore/*</code></li> <li>Delta and sorted file writers: <code>src/main/java/org/hestiastore/index/sorteddatafile/*</code></li> <li>Context log (optional): <code>src/main/java/org/hestiastore/index/log/*</code></li> </ul> <p>For the read path and on\u2011disk layout, see the related pages:</p> <ul> <li>Read Path: <code>architecture/read-path.md</code></li> <li>On\u2011Disk Layout &amp; File Names: <code>architecture/on-disk-layout.md</code></li> <li>Filters &amp; Integrity: <code>architecture/filters.md</code></li> </ul>"},{"location":"architecture/write-path/#related-glossary","title":"Related Glossary","text":"<ul> <li>Segment</li> <li>UniqueCache</li> <li>Delta Cache</li> <li>Flush</li> <li>Compaction</li> <li>Split</li> <li>Write Transaction</li> <li>Filters</li> <li>Tombstone</li> <li>Context Log</li> </ul>"},{"location":"configuration/","title":"Configuration","text":"<p>Don\u2019t be afraid to experiment\u2014if a configuration is missing or invalid, the Index will fail fast, helping you catch issues early.</p> <p>The index is configured using the <code>IndexConfiguration</code> class. All essential index properties are configurable through the builder. See the example below:</p> <pre><code>IndexConfiguration&lt;Integer, Integer&gt; conf = IndexConfiguration\n    .&lt;Integer, Integer&gt;builder()//\n    .withKeyClass(Integer.class)//\n    .withValueClass(Integer.class)//\n    .withKeyTypeDescriptor(tdi) //\n    .withValueTypeDescriptor(tdi) //\n    .withMaxNumberOfKeysInSegment(4) //\n    .withMaxNumberOfKeysInSegmentCache(10L) //\n    .withMaxNumberOfKeysInSegmentCacheDuringFlushing(12L)//\n    .withMaxNumberOfKeysInSegmentIndexPage(2) //\n    .withMaxNumberOfKeysInCache(3) //\n    .withBloomFilterIndexSizeInBytes(0) //\n    .withBloomFilterNumberOfHashFunctions(4) //\n    .withContextLoggingEnabled(false) //\n    .withName(\"test_index\") //\n    .build();\n\nIndex&lt;Integer, Integer&gt; index = Index.&lt;Integer, Integer&gt;create(directory, conf);\n</code></pre> <p>Now let's look at particular parameters.</p>"},{"location":"configuration/#index-directory","title":"Index Directory","text":"<p>Place where all data are stored. There are two already prepared types:</p>"},{"location":"configuration/#in-memory","title":"In Memory","text":"<p>All data are stored in memory. It's created like this:</p> <pre><code>Directory directory = new MemDirectory();\n</code></pre> <p>It's usefull for testing purposes.</p>"},{"location":"configuration/#file-system","title":"File system","text":"<p>Its main purpose is to store index data in the file system. Create a file-system-based directory like this:</p> <pre><code>Directory directory = new FsDirectory(new File('my directory'));\n</code></pre>"},{"location":"configuration/#properties-of-indexconfiguration-class","title":"Properties of <code>IndexConfiguration</code> class","text":"<p>All properties are required and have the following meanings:</p>"},{"location":"configuration/#index-related-configuration","title":"Index related configuration","text":""},{"location":"configuration/#key-class-withkeyclass","title":"Key class - <code>withKeyClass()</code>","text":"<p>A <code>Class</code> object that represents the type of keys used in the index. Only instances of this class may be inserted. While any Java class is technically supported, it's recommended to use simple, compact types for performance reasons. Predefined classes are:</p> <ul> <li>Integer</li> <li>Long</li> <li>String</li> <li>Byte</li> </ul> <p>If a different class is used, the key type descriptor must be set using the <code>withKeyTypeDescriptor()</code> method from the builder. If you use a custom class, you must implement the <code>com.hestiastore.index.datatype.TypeDescriptor</code> interface to describe how the type is serialized and compared.</p>"},{"location":"configuration/#value-class-withvalueclass","title":"Value class - <code>withValueClass()</code>","text":"<p>Required. Specifies the Java class used for values. The same rules that apply to the key class also apply to the value class.</p>"},{"location":"configuration/#index-name-withname","title":"Index name - <code>withName()</code>","text":"<p>Required. Assigns a logical name to the index. This can be useful in diagnostics and logging.</p>"},{"location":"configuration/#key-type-descriptor-withkeytypedescriptor","title":"Key type descriptor - <code>withKeyTypeDescriptor()</code>","text":"<p>Type descriptor for the key class. Required for non-default types.</p>"},{"location":"configuration/#value-type-descriptor-withvaluetypedescriptor","title":"Value type descriptor - <code>withValueTypeDescriptor()</code>","text":"<p>Type descriptor for the value class. Required for non-default types.</p>"},{"location":"configuration/#max-number-of-keys-in-cache-withmaxnumberofkeysincache","title":"Max number of keys in cache - <code>withMaxNumberOfKeysInCache()</code>","text":"<p>Sets the maximum number of key-value entries allowed in the in-memory cache before flushing.</p>"},{"location":"configuration/#max-number-of-segments-in-cache-withmaxnumberofsegmentsincache","title":"Max number of segments in cache - <code>withMaxNumberOfSegmentsInCache()</code>","text":"<p>Limits the number of segments stored in memory. Useful for controlling memory usage.</p>"},{"location":"configuration/#thread-safe-withthreadsafe","title":"Thread safe - <code>withThreadSafe()</code>","text":"<p>Whether the index instance is safe for concurrent access by multiple threads. When it's set to <code>code</code> true than index will be synchronized between threads.</p> <p>Default value is 'false'.</p>"},{"location":"configuration/#context-logging-enabled-withcontextloggingenabled","title":"Context logging enabled - <code>withContextLoggingEnabled()</code>","text":"<p>Controls whether the index wraps operations with MDC context propagation so log statements include the index name. When it's set on 'true' following loog message will contain set 'index' property:</p> <pre><code>&lt;Console name=\"indexAppender\" target=\"SYSTEM_OUT\"&gt;\n    &lt;PatternLayout\n        pattern=\"%d{ISO8601} %-5level [%t] index='%X{index.name}' %-C{1.mv}: %msg%n%throwable\" /&gt;\n&lt;/Console&gt;\n</code></pre> <p>Default value is 'true'.</p> <p>Please note, that in highly intensive applications enabling this option could eat up to 40% of CPU time.</p>"},{"location":"configuration/#segment-related-configuration","title":"Segment related configuration","text":""},{"location":"configuration/#max-number-of-keys-in-segment-withmaxnumberofkeysinsegment","title":"Max number of keys in segment - <code>withMaxNumberOfKeysInSegment()</code>","text":"<p>Sets the maximum number of keys allowed in a single segment. Exceeding this splits the segment.</p>"},{"location":"configuration/#max-number-of-keys-in-segment-cache-withmaxnumberofkeysinsegmentcache","title":"Max number of keys in segment cache - <code>withMaxNumberOfKeysInSegmentCache()</code>","text":"<p>Defines how many keys can be cached from a segment during regular operation.</p>"},{"location":"configuration/#max-number-of-keys-in-segment-cache-during-flushing-withmaxnumberofkeysinsegmentcacheduringflushing","title":"Max number of keys in segment cache during flushing - <code>withMaxNumberOfKeysInSegmentCacheDuringFlushing()</code>","text":"<p>Specifies the maximum number of keys that can be temporarily cached from a segment during flushing.</p>"},{"location":"configuration/#max-number-of-keys-in-segment-index-page-withmaxnumberofkeysinsegmentindexpage","title":"Max number of keys in segment index page - <code>withMaxNumberOfKeysInSegmentIndexPage()</code>","text":"<p>Defines the number of keys in the index page for a segment. This impacts lookup efficiency.</p>"},{"location":"configuration/#bloom-filter-configuration","title":"Bloom filter configuration","text":"<p>A Bloom filter is a probabilistic data structure that efficiently tests whether an element is part of a set. You can find a detailed explanation on Wikipedia. In this context, each segment has its own Bloom filter.</p> <p>To disable bloom filter completle set:</p> <pre><code> .withBloomFilterIndexSizeInBytes(0)\n</code></pre> <p>The settings for the Bloom filter can be adjusted using the following methods:</p>"},{"location":"configuration/#bloom-filter-size-withbloomfilterindexsizeinbytes","title":"Bloom filter size - <code>withBloomFilterIndexSizeInBytes()</code>","text":"<p>Sets the size of the Bloom filter in bytes. A value of 0 disables the use of the Bloom filter.</p>"},{"location":"configuration/#number-of-hash-functions-withbloomfilternumberofhashfunctions","title":"Number of hash functions - <code>withBloomFilterNumberOfHashFunctions()</code>","text":"<p>Sets the number of hash functions used in the Bloom filter.</p>"},{"location":"configuration/#probability-of-false-positive-withbloomfilterprobabilityoffalsepositive","title":"Probability of false positive - <code>withBloomFilterProbabilityOfFalsePositive()</code>","text":"<p>Sets the probability of false positives. When <code>get(someKey)</code> is called on a segment, the Bloom filter is checked to determine if the value is not in the segment. It can return <code>true</code>, indicating that the key could be in the segment. If the Bloom filter indicates the key is in the segment but it's not found, that's a false positive. The probability of this occurring is a value between 0 and 1.</p> <p>Usually, it's not necessary to adjust the Bloom filter settings.</p>"},{"location":"configuration/#changing-index-propertise","title":"Changing Index propertise","text":"<p>Some parameters can be redefined when the index is opened.</p> <pre><code>Index&lt;String, String&gt; index = Index.&lt;String, String&gt;open(directory, conf);\n</code></pre> <p>At allows to pass <code>IndexConfiguration</code> object and this way change configuration parameters. Fllowing table shou parameters that can be changed.  </p> Name Meaning Can be changed Applies to indexName Logical name of the index \ud83d\udfe9 index keyClass Key class \ud83d\udfe5 index valueClass Value class \ud83d\udfe5 index keyTypeDescriptor Key class type descriptor \ud83d\udfe5 index valueTypeDescriptor Value class type descriptor \ud83d\udfe5 index maxNumberOfKeysInSegmentIndexPage Maximum keys in segment index page \ud83d\udfe5 segment maxNumberOfKeysInSegmentCache Maximum number of keys in segment cache \ud83d\udfe9 segment maxNumberOfKeysInSegmentCacheDuringFlushing Maximum keys in cache during flushing \ud83d\udfe9 segment maxNumberOfKeysInCache Maximum keys in the index cache \ud83d\udfe9 index maxNumberOfKeysInSegment Maximum keys in a segment \ud83d\udfe5 segment maxNumberOfSegmentsInCache Maximum number of segments in cache \ud83d\udfe9 index bloomFilterNumberOfHashFunctions Bloom filter - number of hash functions used \ud83d\udfe5 segment bloom filter bloomFilterIndexSizeInBytes Bloom filter - index size in bytes \ud83d\udfe5 segment bloom filter bloomFilterProbabilityOfFalsePositive Bloom filter - probability of false positives \ud83d\udfe5 segment bloom filter diskIoBufferSize Size of the disk I/O buffer \ud83d\udfe9 Disk IO threadSafe If index is thread-safe \ud83d\udfe9 index contextLoggingEnabled If MDC-based context logging is enabled \ud83d\udfe9 index"},{"location":"configuration/#add-custom-data-type","title":"Add custom data type","text":"<p>HestiaStore have to know how to work with new data type. So first is create implementatio of <code>com.hestiastore.index.datatype.TypeDescriptor</code>. Than during index creation set let index know about your implementation by <code>withKeyTypeDescriptor</code>. And it's done.</p>"},{"location":"configuration/data-types/","title":"Data types","text":"<p>HestiaStore supports a variety of data types for storing keys and values in a binary-efficient and consistent manner. Each data type is associated with a <code>TypeDescriptor</code>, which handles serialization, deserialization, comparison, and hashing logic.</p> <p>Below is a list of the supported data types and their characteristics.</p> Java Class TypeDescriptor Class Max Length (Bytes) Notes <code>java.lang.Byte</code> <code>TypeDescriptorByte</code> 1 Two's complement representation <code>java.lang.Integer</code> <code>TypeDescriptorInteger</code> 4 Big-endian encoding <code>java.lang.Long</code> <code>TypeDescriptorLong</code> 8 Big-endian encoding <code>java.lang.Float</code> <code>TypeDescriptorFloat</code> 4 IEEE 754 format <code>java.lang.Double</code> <code>TypeDescriptorDouble</code> 8 IEEE 754 format <code>java.lang.String</code> <code>TypeDescriptorShortString</code> 128 UTF-8 encoding, prefixed with 1-byte length, it's default string type descriptor <code>java.lang.String</code> <code>TypeDescriptorString</code> 2 GB UTF-8 encoding, prefixed with 4-byte length <code>org.hestiastore.index.datatype.ByteArray</code> <code>TypeDescriptorByteArray</code> n Raw bytes, length determined by actual data <code>org.hestiastore.index.datatype.NullValue</code> <code>TypeDescriptorNullValue</code> 0 Usefulll when value is not needed. Doesn't occupy any space. <code>org.hestiastore.index.datatype.CompositeValue</code> <code>TypeDescriptorCompositeValue</code> n Represents multiple values."},{"location":"configuration/data-types/#custom-data-types","title":"Custom Data Types","text":"<p>HestiaStore allows advanced users to define custom <code>TypeDescriptor</code> implementations for handling specialized serialization strategies or complex types. Main usecases:</p> <ul> <li>Allows to store new data type.</li> <li>Introduce some specific encoding. it could lead to space saving.</li> <li>Limit data to some exact size</li> </ul> <p>To create a new data type:</p> <ol> <li>Implement the <code>TypeDescriptor&lt;T&gt;</code> interface. It's just a collection of simple interfaces which allows store data type to bytes and restore it from byte array</li> <li>Optionallly register it using <code>org.hestiastore.index.sst.DataTypeDescriptorRegistry.addTypeDescriptor(Class, descriptor)</code>.</li> </ol>"},{"location":"configuration/data-types/#why-register-your-custom-type-descriptor","title":"Why Register Your Custom Type Descriptor","text":"<p>Registering your <code>TypeDescriptor</code> with <code>DataTypeDescriptorRegistry</code> is not mandatory, but it brings benefits:</p> <ul> <li>Simpler configuration defaults: When building an <code>IndexConfiguration</code> you can specify only <code>keyClass</code>/<code>valueClass</code>. The manager auto-fills <code>keyTypeDescriptor</code>/<code>valueTypeDescriptor</code> from the registry, so you don\u2019t have to wire descriptors everywhere.</li> <li>Consistency and validation: A single registry reduces mismatches between classes and descriptors. The configuration manager can validate and prevent accidental overriding of fixed properties because the descriptor identity is explicit.</li> <li>Future-proofing: Sharing an index between services or running offline maintenance works seamlessly as long as your descriptor type is on the classpath.</li> </ul> <p>Important: If you register using a <code>TypeDescriptor</code> instance, its class will be saved. That class must have a public no-args constructor (the system instantiates it reflectively). If this is not possible, you can register using the explicit class name overload <code>addTypeDescriptor(Class, String)</code>.</p>"},{"location":"configuration/data-types/#how-to-use-new-data-type","title":"How to use new Data Type","text":"<p>During Index configuration new data type descriptor can by directly used:</p> <pre><code>IndexConfiguration&lt;Integer, Integer&gt; conf = IndexConfiguration\n    .&lt;Integer, Integer&gt;builder()//\n    .withKeyClass(Integer.class)//\n    .withValueClass(MySuperDataType.class)//\n        ...\n    .withValueTypeDescriptor(new TypeDescriptorMySuperDataType()) //\n        ...\n    .build();\n\nIndex&lt;Integer, Integer&gt; index = Index.&lt;Integer, Integer&gt;create(directory, conf);\n</code></pre>"},{"location":"configuration/data-types/#notes","title":"Notes","text":"<ul> <li>All numeric types use big-endian byte order for consistent sorting and comparison.</li> <li><code>ByteArray</code> is a wrapper class designed to support <code>equals()</code>, <code>hashCode()</code>, and lexicographic comparison. It can be used for binary blobs or hash digests.</li> </ul>"},{"location":"configuration/data-types/#equality-hashing-and-sorting-contracts","title":"Equality, Hashing, and Sorting Contracts","text":"<p>When you define custom key types (or use low-level binary types), it is critical that equality, hashing, and ordering behave consistently. HestiaStore relies on these properties to deduplicate updates in memory, to merge data from multiple sources, and to safely write strictly-increasing keys to disk.</p> <p>Why this matters</p> <ul> <li>In-memory caches coalesce multiple updates to the same key before flush. If the cache cannot recognize \u201cthe same key\u201d, duplicate keys can slip through.</li> <li>During flushing and compaction, keys are iterated in sorted order and written by <code>SortedDataFileWriter</code>. That writer requires strictly increasing keys. Two adjacent keys that are equal under the comparator will cause a hard failure.</li> <li>Merging/lookup structures assume a total and stable order; a non-transitive or unstable comparator leads to undefined behavior.</li> </ul> <p>Typical failure mode when the contract is broken</p> <ul> <li>Using raw <code>byte[]</code> as a key: <code>byte[]</code> uses reference equality and identity-based <code>hashCode()</code>. If your comparator compares by content (e.g., lexicographically), then two different <code>byte[]</code> instances with the same content are NOT equal to <code>HashMap</code>, but ARE equal to the comparator. The cache keeps both, sorts them, and the writer sees two adjacent equal keys and throws an exception like:</li> <li>\"Attempt to insert the same key as previous. Key(Base64)='\u2026'\"</li> </ul> <p>Contracts to follow</p> <ul> <li>equals/hashCode consistency: If <code>a.equals(b)</code> is <code>true</code>, then <code>a.hashCode() == b.hashCode()</code> must also be <code>true</code>.</li> <li>Comparator total order: The comparator returned by your <code>TypeDescriptor#getComparator()</code> must be total (anti-symmetric, transitive, and consistent), and must define the uniqueness of keys.</li> <li>Comparator consistency with equality: If the system uses hash-based maps anywhere for keys of type <code>K</code>, ensure that <code>compare(a, b) == 0</code> implies <code>a.equals(b)</code>. This avoids having one part of the system see two objects as the same key while another part sees them as different. If you cannot satisfy this for a given JVM type (e.g., raw <code>byte[]</code>), wrap it in a type that does (e.g., <code>ByteArray</code>).</li> <li>Stable order vs. encoding: Keep the comparator consistent with the intended semantics of your keys and their encoding. For numbers encoded big-endian, natural numeric order is the correct comparator.</li> </ul> <p>Practical guidance</p> <ul> <li>Do NOT use raw <code>byte[]</code> as keys. Use <code>org.hestiastore.index.datatype.ByteArray</code> or another wrapper that implements content-based <code>equals()</code>, <code>hashCode()</code>, and a lexicographic <code>compareTo</code>.</li> <li>For fixed-length binary keys, prefer a wrapper or a fixed-length <code>String</code> (<code>TypeDescriptorFixedLengthString</code>) if your domain allows it.</li> <li>Avoid lossy comparators (e.g., comparing only a prefix) unless that prefix truly defines key identity. Otherwise, distinct keys will be treated as equal under the comparator and collapse unintentionally.</li> <li>Ensure your comparator never depends on mutable or external state; it must be stable for the lifetime of the index.</li> </ul> <p>How to self-check</p> <ul> <li>Property checks you can add to tests when introducing a new key type <code>K</code> and comparator <code>cmp</code>:</li> <li>For many random pairs <code>(a, b)</code>: if <code>cmp.compare(a, b) == 0</code>, then assert <code>a.equals(b)</code> and <code>a.hashCode() == b.hashCode()</code>.</li> <li>For many triples <code>(a, b, c)</code>: assert transitivity: if <code>cmp.compare(a, b) &lt;= 0</code> and <code>cmp.compare(b, c) &lt;= 0</code> then <code>cmp.compare(a, c) &lt;= 0</code>.</li> <li>Round-trip through caches: insert duplicates under the comparator, ensure only the latest value is kept, and iteration returns strictly increasing unique keys.</li> </ul> <p>Example: byte[] vs. ByteArray</p> <ul> <li>Bad (will fail): using <code>byte[]</code> as keys with a content comparator. Two different arrays with the same content will be considered different by a hash-based map but equal by the comparator, leading to duplicate adjacent keys during write.</li> <li>Good: using <code>ByteArray</code> as keys. <code>ByteArray</code> implements content-based <code>equals()</code>, <code>hashCode()</code>, and lexicographic <code>compareTo</code>, so all parts of the system agree on key identity and ordering.</li> </ul> <p>By following these contracts, you ensure that updates are correctly deduplicated, merges are deterministic, and on-disk files maintain the strict key ordering required for safe reads and compactions.</p>"},{"location":"configuration/logging/","title":"Logging","text":"<p>HestiaStore uses slf4j for internal logging. So you should include your preferred logging library like logback, log4j, or another with a bridge to slf4j. In case you use log4j, look at the example configuration:</p>"},{"location":"configuration/logging/#example-configuration-file-for-log4j","title":"Example configuration File for log4j","text":"<p>Bellow is the example Log4j2 configuration used in HestiaStore:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Configuration status=\"INFO\"&gt;\n  &lt;Appenders&gt;\n\n    &lt;Console name=\"Console\" target=\"SYSTEM_OUT\"&gt;\n      &lt;PatternLayout\n          pattern=\"%style{%d{ISO8601}}{white} %highlight{%-5level }[%style{%t}{bright,blue}] %style{%-C{1.mv}}{bright,yellow}: %msg%n%throwable\" /&gt;\n    &lt;/Console&gt;\n\n    &lt;Console name=\"indexAppender\" target=\"SYSTEM_OUT\"&gt;\n      &lt;PatternLayout\n          pattern=\"%style{%d{ISO8601}}{white} %highlight{%-5level }[%style{%t}{bright,blue}] index='%style{%X{index.name}}{magenta}' %style{%-C{1.mv}}{bright,yellow}: %msg%n%throwable\" /&gt;\n    &lt;/Console&gt;\n\n  &lt;/Appenders&gt;\n  &lt;Loggers&gt;\n    &lt;logger name=\"org.hestiastore.index\" level=\"DEBUG\" additivity=\"false\"&gt;\n      &lt;appender-ref ref=\"indexAppender\" /&gt;\n    &lt;/logger&gt;\n    &lt;Root level=\"DEBUG\"&gt;\n      &lt;AppenderRef ref=\"Console\"/&gt;\n    &lt;/Root&gt;\n  &lt;/Loggers&gt;\n&lt;/Configuration&gt;\n</code></pre> <p>this example will produce logs look like this:</p> <p></p>"},{"location":"configuration/logging/#log-appenders","title":"Log Appenders","text":"<ul> <li>Console (default): Used by all components not explicitly assigned a logger. Outputs time, level, thread, and class name.</li> <li>indexAppender: Specifically configured for <code>org.hestiastore.index</code>, outputs additional context (<code>index.name</code>) for disambiguating messages from different index instances.</li> </ul>"},{"location":"configuration/logging/#customizing-logging-levels","title":"Customizing Logging Levels","text":"<p>You can control verbosity by modifying the <code>&lt;logger&gt;</code> or <code>&lt;Root&gt;</code> levels:</p> <ul> <li><code>ERROR</code>, <code>WARN</code>, <code>INFO</code>, <code>DEBUG</code>, or <code>TRACE</code></li> <li>For example, to suppress general debug logs:</li> </ul> <pre><code>&lt;Root level=\"INFO\"&gt;\n</code></pre>"},{"location":"configuration/logging/#disabling-index-logs","title":"Disabling Index Logs","text":"<p>If you want to disable index-specific logging entirely, remove or comment out the <code>org.hestiastore.index</code> logger section. Alternatively log level for package could be set to \"ERROR\".</p>"},{"location":"configuration/logging/#recommendations","title":"Recommendations","text":"<ul> <li>Use <code>DEBUG</code> during development or troubleshooting.</li> <li>Switch to <code>INFO</code> or <code>WARN</code> in production to reduce log noise.</li> <li>Ensure you clear MDC values (<code>ThreadContext.clearAll()</code>) in thread pools to prevent memory leaks or incorrect context reuse.</li> </ul>"},{"location":"configuration/logging/#logging-implementation","title":"Logging Implementation","text":"<p>The <code>indexAppender</code> uses a mapped diagnostic context (MDC) value <code>index.name</code>, which should be set programmatically:</p> <pre><code>ThreadContext.put(\"index.name\", \"userIndex\");\n</code></pre> <p>This allows the log output to include which index instance the message is referring to, aiding in debugging concurrent access or behavior across multiple indexes.</p>"},{"location":"development/","title":"Development","text":"<p>Here are some development related topiscs.</p>"},{"location":"development/documentation/","title":"Documentation","text":"<p>Documentation is available in the following locations:</p> <ul> <li><code>mvn site</code> - Includes detailed project reports from PMC, checkstyle, JUnit test line coverage, and Javadocs. It's not published.</li> <li>GitHub project - Simple technical development oriented site</li> <li>HestiaStore.org site - Detailed, user-focused information</li> </ul> <p>Following text is about HestiaStore.org site documentation.</p>"},{"location":"development/documentation/#how-to-make-changes-to-hestiastoreorg","title":"How to make changes to HestiaStore.org","text":"<p>HestiaStore.org site documentation is served from the main project branch <code>gh-pages</code>. Publishing a new site version involves generating HTML from Markdown and pushing it to <code>gh-pages</code>.</p> <p>Prerequisites:</p> <ul> <li>Installed git</li> <li>Site generating tool mkdocs-material - as described at https://squidfunk.github.io/mkdocs-material/. It is user-friendly and easy to work with. In case of MacOS install it with:</li> </ul> <p><pre><code>brew install mkdocs-material\n</code></pre> * Some Markdown editor of your choice * GitHub personal access token with permission to read and write project pages.</p>"},{"location":"development/documentation/#page-editing-and-viewing-documentation-locally","title":"Page editing and viewing documentation locally","text":"<p>From project checkout branch <code>docs</code>, there are all source files for main site. Markdown files for documentation are located in the directory <code>docs</code>. To preview documentation changes locally, run:</p> <pre><code>mkdocs serve\n</code></pre> <p>Now at http://127.0.0.1:8080/HestiaStore/ should display the documentation.</p> <p>The <code>mkdocs.yml</code> file in the root directory controls site structure, navigation, and theme. For more information see mkdocs-material documentation.</p>"},{"location":"development/documentation/#how-to-publish-changes-at-hestiastoreorg","title":"How to publish changes at hestiastore.org","text":"<ul> <li>From github.com/jajir/HestiaStore checkout branch <code>docs</code>. </li> <li>Make changes</li> <li>Commit changes to <code>docs</code></li> <li>Pull again to be sure, that latest chnages from branch <code>gh-pages</code> is at local.</li> <li>Then, run the following command locally:</li> </ul> <p><pre><code>mkdocs gh-deploy\n</code></pre>   In a few minutes (could be 15 minutes) new documentation will be published.</p>"},{"location":"development/guides/","title":"Development","text":"<p>Here are some development related topiscs.</p>"},{"location":"development/guides/#how-to-run-jmh-benchmarks","title":"How to run JMH benchmarks","text":"<p>Follow this steps: * Compile whole project and create pacakge containing all benchmarks data * Go to <code>jmh-benchmarks</code> * Execute it, with temp directory in <code>target</code> directory</p> <pre><code>mvn clean install\ncd jmh-benchmarks\njava -Ddir=./target/ -jar target/jmh-benchmarks.jar\n</code></pre> <p>Specific JMH benchmark class could be run:</p> <pre><code>java -Ddir=./target/ -jar target/jmh-benchmarks.jar SegmentSearchBenchmark\n</code></pre> <p>result could look like:</p> <pre><code>Benchmark                                             Mode  Cnt    Score      Error  Units\nSequentialFileReadingBenchmark.test_with_buffer_01KB  avgt    4   70.747 \u00b1   42.480  ms/op\nSequentialFileReadingBenchmark.test_with_buffer_02KB  avgt    4   60.009 \u00b1   52.899  ms/op\nSequentialFileReadingBenchmark.test_with_buffer_04KB  avgt    4   51.254 \u00b1   30.112  ms/op\nSequentialFileReadingBenchmark.test_with_buffer_08KB  avgt    4   48.600 \u00b1   28.892  ms/op\nSequentialFileReadingBenchmark.test_with_buffer_16KB  avgt    4   48.471 \u00b1   25.665  ms/op\nSequentialFileReadingBenchmark.test_with_buffer_32KB  avgt    4   45.256 \u00b1   24.986  ms/op\nSequentialFileReadingBenchmark.test_with_buffer_64KB  avgt    4   45.204 \u00b1   24.867  ms/op\nSequentialFileWritingBenchmark.test_with_buffer_01KB  avgt    4  238.075 \u00b1   75.311  ms/op\nSequentialFileWritingBenchmark.test_with_buffer_02KB  avgt    4  271.272 \u00b1   64.747  ms/op\nSequentialFileWritingBenchmark.test_with_buffer_04KB  avgt    4  276.001 \u00b1   45.815  ms/op\nSequentialFileWritingBenchmark.test_with_buffer_08KB  avgt    4  352.189 \u00b1 1140.814  ms/op\nSequentialFileWritingBenchmark.test_with_buffer_16KB  avgt    4  258.806 \u00b1   44.693  ms/op\nSequentialFileWritingBenchmark.test_with_buffer_32KB  avgt    4  276.246 \u00b1  135.019  ms/op\nSequentialFileWritingBenchmark.test_with_buffer_64KB  avgt    4  275.944 \u00b1  128.835  ms/op\n</code></pre> <p>When some JMH benchmark class is changed command <code>mvn package</code> have to be run.</p>"},{"location":"development/guides/#possible-problems","title":"Possible problems","text":"<p>Generally JMH is quite fragile. Small changes broke JMH benchmark execution. Usually helps rebuild project and start again as described above.</p>"},{"location":"development/guides/#load-test","title":"Load test","text":"<p>Runnign JVM should be inspected with some profiller. For profilling is usefull to hae long running task to watch it. Go to project <code>load-test</code>. Following command show all optional parameters:</p> <pre><code>java -jar target/load-test.jar com.coroptis.index.loadtest.Main --help\n</code></pre> <p>Theer are two main supported operations. First is data generating. It's could be usefull to place in java profilling agent. It could look like:</p> <pre><code>java \\\n    -agentpath:/Applications/YourKit-Java-Profiler-2023.9.app/Contents/Resources/bin/mac/libyjpagent.dylib=exceptions=disable,delay=10000,listen=all \\\n    -jar target/load-test.jar com.coroptis.index.loadtest.Main \\\n    --write \\\n    --directory /Volumes/LaCie/test/  \\\n    --count 5_000_000_000 \\\n    --max-number-of-keys-in-cache 5_000_000 \\\n    --max-number-of-keys-in-segment 10_000_000 \\\n    --max-number-of-keys-in-segment-cache 500_000 \\\n    --max-number-of-keys-in-segment-cache-during-flushing 2_000_000 \\\n    --max-number-of-keys-in-segment-index-page 1_000 \\\n    --bloom-filter-index-size-in-bytes 10_000_000 \\\n    --bloom-filter-number-of-hash-functions 2\n</code></pre> <p>It will generate 210 GB of testing data. Furst search test can be performed like this:</p> <pre><code>java \\\n    -agentpath:/Applications/YourKit-Java-Profiler-2023.9.app/Contents/Resources/bin/mac/libyjpagent.dylib=exceptions=disable,delay=10000,listen=all \\\n    -jar target/load-test.jar com.coroptis.index.loadtest.Main \\\n    --search \\\n    --directory /Volumes/LaCie/test/  \\\n    --count 5_000_000_000 \\\n    --max-key 5_000_000_000 \\\n    --max-number-of-keys-in-cache 5_000_000 \\\n    --max-number-of-keys-in-segment 10_000_000 \\\n    --max-number-of-keys-in-segment-cache 500_000 \\\n    --max-number-of-keys-in-segment-cache-during-flushing 2_000_000 \\\n    --max-number-of-keys-in-segment-index-page 1_000 \\\n    --bloom-filter-index-size-in-bytes 10_000_000 \\\n    --bloom-filter-number-of-hash-functions 2\n</code></pre>"},{"location":"development/guides/#development_1","title":"Development","text":"<p>Mockito requires reflective access to non-public parts in a Java module. It could be manually open by passing following parameter as jvm parameter:</p> <pre><code>--add-opens=java.base/java.lang=ALL-UNNAMED\n</code></pre>"},{"location":"development/guides/#how-to-get-segment-disk-size","title":"How to get segment disk size","text":"<p>On apple try:</p> <pre><code>diskutil  info /Volumes/LaCie\n</code></pre>"},{"location":"development/release/","title":"\ud83d\ude80 Releasing a New Version","text":"<p>This is a step-by-step guide for making a new HestiaStore release.</p>"},{"location":"development/release/#versioning-of-the-project","title":"\u261d\ufe0f Versioning of the project","text":"<p>The project uses the traditional versioning pattern known as Semantic Versioning, detailed at https://semver.org. The version number consists of three components separated by dots:</p> <pre><code>0.3.6\n</code></pre> <p>Each number has the following meaning:</p> <ul> <li><code>0</code> - Major project version. Project API could be incompatible between two major versions.</li> <li><code>3</code> - Minor project version. Contains changes in features, performance optimizations, and small improvements. Minor versions should be compatible.</li> <li><code>6</code> - Patch version. Bug fixing project release.</li> </ul> <p>There are also snapshot versions with version number <code>0.3.6-SNAPSHOT</code>. Snapshot versions should not be stored in the Maven repository.</p>"},{"location":"development/release/#branching-strategy","title":"\ud83d\udd4a\ufe0f Branching strategy","text":"<p>We use a simplified GitHub Flow:</p> <ul> <li><code>main</code>: the primary development and release branch. Small changes may be committed directly to <code>main</code>, while larger or experimental features must be developed in a separate branch and merged via pull request.</li> <li>Feature branches are created from <code>main</code> for larger or isolated changes. Use descriptive names like <code>feature/compression</code>, <code>fix/index-scan</code>, etc.</li> </ul> <p>The deprecated <code>devel</code> branch has been removed and is no longer used.</p>"},{"location":"development/release/#release-prerequisites","title":"\ud83e\uddd1\u200d\ud83d\udcbb Release prerequisites","text":"<p>The release will be published to Maven Central. Release configuration secrets are placed at the Maven settings file <code>~/.m2/settings.xml</code>. Adjust <code>settings.xml</code> in <code>~/.m2/settings.xml</code> as described in GitHub's official documentation on how to work with the GitHub Maven repository. Generate a valid token and you are done.</p>"},{"location":"development/release/#provide-correct-package-signature","title":"Provide correct package signature","text":"<p>In your <code>~/.m2/settings.xml</code> file, add the following section:</p> <pre><code>&lt;settings&gt;\n    ...\n   &lt;profile&gt;\n     &lt;id&gt;release&lt;/id&gt;\n       &lt;properties&gt;\n       &lt;gpg.executable&gt;gpg&lt;/gpg.executable&gt;\n       &lt;gpg.passphrase&gt;--pgp-password--&lt;/gpg.passphrase&gt;\n     &lt;/properties&gt;      \n   &lt;/profile&gt;\n    ...\n&lt;/settings&gt;\n</code></pre>"},{"location":"development/release/#setup-maven-central-accout-secrets","title":"Setup maven central accout secrets","text":"<p>This provides <code>org.sonatype.central:central-publishing-maven-plugin</code> plugin secrets to enable login to the Maven Central account where release data will be placed. You must have an account with a verified namespace <code>org.hestiastore</code> at central.sonatype.com. From the <code>Account</code> section, generate a key and password. These should be added to:</p> <pre><code>&lt;settings&gt;\n    ...\n    &lt;servers&gt;\n        &lt;server&gt;\n            &lt;id&gt;central&lt;/id&gt;\n           &lt;username&gt;------&lt;/username&gt;\n           &lt;password&gt;---------------token---------------&lt;/password&gt;\n       &lt;/server&gt;\n    &lt;/servers&gt;\n    ...\n&lt;/settings&gt;\n</code></pre>"},{"location":"development/release/#perform-release","title":"Perform release","text":"<p>Perform the following steps to create a new release:</p>"},{"location":"development/release/#1-checkout-the-main-branch","title":"1. \ud83c\udff7\ufe0f Checkout the <code>main</code> branch","text":"<pre><code>git checkout main\n</code></pre>"},{"location":"development/release/#2-set-the-release-version","title":"2. \ud83d\udd22 Set the Release Version","text":"<pre><code>mvn versions:set -DnewVersion=0.0.12\ngit commit -am \"release: version 0.0.12\"\n</code></pre>"},{"location":"development/release/#3-tag-and-push-the-release","title":"3. \ud83c\udff7\ufe0f Tag and Push the Release","text":"<pre><code>git tag v0.0.12\ngit push --follow-tags\n</code></pre>"},{"location":"development/release/#4-deploy-the-release","title":"4. \ud83d\ude80 Deploy the Release","text":"<p>Deploy the release (can be later automated via GitHub Actions or done manually):</p> <pre><code>mvn deploy -P release\n</code></pre>"},{"location":"development/release/#5-bump-to-the-next-snapshot-version","title":"5. \ud83d\udcc8 Bump to the Next Snapshot Version","text":"<pre><code>mvn versions:set -DnewVersion=0.0.13-SNAPSHOT\ngit commit -am \"post-release: bumped to 0.0.13-SNAPSHOT\"\ngit push\n</code></pre>"},{"location":"development/release/#6-publish-the-release-on-github","title":"6. \ud83d\udcdd Publish the Release on GitHub","text":"<ol> <li>Go to https://github.com/jajir/HestiaStore/releases and choose <code>Draft a new release</code>.</li> <li>From the drop-down box <code>target: main</code>, select <code>recent commits</code> and select the correct one with name <code>release: version 0.0.12</code>.</li> <li>From the drop-down box <code>Choose a tag</code> enter <code>release-0.0.12</code> and click <code>Create new tag: release ...</code>. Now in the repo, the tag clearly signals the new release.</li> <li>Release title should be <code>Release 0.0.3</code> and in the <code>Write</code> field, use the text generated from the template below:</li> <li>Press <code>Publish release</code>.</li> </ol> <p>Text template:</p> <pre><code>Release to maven central:\n\n```xml\n&lt;dependencies&gt;\n  &lt;dependency&gt;\n    &lt;groupId&gt;org.hestiastore.index&lt;/groupId&gt;\n    &lt;artifactId&gt;core&lt;/artifactId&gt;\n    &lt;version&gt;0.0.3&lt;/version&gt; &lt;!-- Replace with the actual version --&gt;\n  &lt;/dependency&gt;\n&lt;/dependencies&gt;\n```\n</code></pre>"},{"location":"development/release/#7-celebrate","title":"7. \ud83c\udf89 Celebrate","text":"<p>That's it \u2014 the release is live and development can continue.</p>"},{"location":"development/release/#helpful-commands","title":"\ud83e\uddf0 Helpful Commands","text":"<p>At the beginning there may be problems. Here are a few tricks that help to gather more information.</p>"},{"location":"development/release/#how-to-use-a-custom-settingsxml-file","title":"How to Use a Custom settings.xml File","text":"<pre><code>mvn --settings ./src/main/settings.xml clean deploy\n</code></pre>"},{"location":"development/release/#how-to-set-the-maven-project-version","title":"How to Set the Maven Project Version","text":"<pre><code>mvn versions:set -DnewVersion=1.0.1-SNAPSHOT\n</code></pre>"},{"location":"development/release/#check-dependencies","title":"Check dependencies","text":"<p>Try to update dependencies. Check them with:</p> <pre><code>mvn versions:display-dependency-updates\n</code></pre>"},{"location":"how-to-use/","title":"\ud83d\ude80 Getting Started","text":"<p>Note: HestiaStore is a library, not a standalone application. It is designed to be integrated into a larger system to provide efficient storage and retrieval of large volumes of key\u2011value entries.</p> <p>HestiaStore is a Java library distributed as a JAR. To get started quickly:</p> <ul> <li>Install \u2014 add the dependency via Maven/Gradle.</li> <li>Quick Start \u2014 minimal in\u2011memory and filesystem examples.</li> <li>Troubleshooting \u2014 common issues, .lock files, and how to get help.</li> </ul>"},{"location":"how-to-use/#use-cases","title":"\ud83d\udca1 Use Cases","text":"<p>HestiaStore is especially effective when you need to:</p> <ul> <li>Store billions of key\u2011value entries on local disks</li> <li>Perform efficient point lookups with bounded memory</li> <li>Persist values to disk without external databases</li> <li>Avoid cloud storage or network\u2011attached stores</li> </ul> <p>When not to use HestiaStore:</p> <ul> <li>If all key\u2011value entries fit in RAM, prefer an in\u2011memory map (e.g., <code>HashMap</code> or <code>ConcurrentHashMap</code>) for speed and simplicity.</li> <li>For small datasets with relational queries, a traditional RDBMS may be simpler to operate.</li> </ul>"},{"location":"how-to-use/install/","title":"Installation Guide","text":""},{"location":"how-to-use/install/#prerequisites","title":"\u2699\ufe0f Prerequisites","text":"<ul> <li>Java 11 or higher (Java 17 recommended)</li> <li>Maven 3.6+ or Gradle 6+</li> </ul> <p>HestiaStore is distributed via Maven Central: https://central.sonatype.com/artifact/org.hestiastore.index/core</p>"},{"location":"how-to-use/install/#maven","title":"\ud83d\udee0\ufe0f Maven","text":"<p>Add the dependency to your pom.xml (use the latest version from Maven Central):</p> <pre><code>&lt;dependencies&gt;\n  &lt;dependency&gt;\n    &lt;groupId&gt;org.hestiastore.index&lt;/groupId&gt;\n    &lt;artifactId&gt;core&lt;/artifactId&gt;\n    &lt;version&gt;&lt;!-- latest --&gt;&lt;/version&gt;\n  &lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre>"},{"location":"how-to-use/install/#verify-installation-maven","title":"\u2705 Verify Installation (Maven)","text":"<pre><code>mvn dependency:tree\n</code></pre> <p>Confirm org.hestiastore.index:core is present in the dependency tree.</p>"},{"location":"how-to-use/install/#gradle","title":"\ud83d\udee0\ufe0f Gradle","text":"<p>Add the dependency to your Gradle build (use the latest version from Maven Central). Ensure mavenCentral() is in repositories.</p> <p>Groovy DSL (build.gradle):</p> <pre><code>repositories {\n  mavenCentral()\n}\n\ndependencies {\n  implementation \"org.hestiastore.index:core:&lt;latest&gt;\"\n}\n</code></pre>"},{"location":"how-to-use/install/#verify-installation-gradle","title":"\u2705 Verify Installation (Gradle)","text":"<pre><code>./gradlew dependencyInsight --dependency org.hestiastore.index:core\n</code></pre>"},{"location":"how-to-use/install/#kotlin","title":"\ud83d\udee0\ufe0f Kotlin","text":"<p>Kotlin DSL (build.gradle.kts):</p> <pre><code>repositories {\n  mavenCentral()\n}\n\ndependencies {\n  implementation(\"org.hestiastore.index:core:&lt;latest&gt;\")\n}\n</code></pre>"},{"location":"how-to-use/install/#build-from-sources","title":"\ud83e\uddf1 Build from Sources","text":"<p>Source code for each release can be downloaded from GitHub releases: https://github.com/jajir/HestiaStore/releases</p> <p>Build the desired version:</p> <pre><code>mvn install\n</code></pre>"},{"location":"how-to-use/quick-start/","title":"\u26a1 Quick Start","text":"<p>This page shows common usage patterns with correct imports and short explanations.</p>"},{"location":"how-to-use/quick-start/#hello-world-inmemory","title":"\ud83d\udc4b Hello World (In\u2011Memory)","text":"<p>Simple example that creates in\u2011memory storage, then opens an index in this storage, writes one key\u2011value pair, and closes the index.</p> <pre><code>import org.hestiastore.index.sst.Index;\nimport org.hestiastore.index.sst.IndexConfiguration;\nimport org.hestiastore.index.directory.Directory;\nimport org.hestiastore.index.directory.MemDirectory;\n\npublic class Example {\n  public static void main(String[] args) {\n    // Create an in\u2011memory directory implementation\n    Directory directory = new MemDirectory();\n\n    // Prepare index configuration\n    IndexConfiguration&lt;String, String&gt; conf = IndexConfiguration\n        .&lt;String, String&gt;builder()\n        .withKeyClass(String.class)\n        .withValueClass(String.class)\n        .withName(\"test_index\")\n        .build();\n\n    // Index is AutoCloseable \u2014 prefer try\u2011with\u2011resources\n    try (Index&lt;String, String&gt; index = Index.create(directory, conf)) {\n      index.put(\"Hello\", \"World\");\n      String value = index.get(\"Hello\");\n      System.out.println(\"Value for Hello: \" + value);\n    }\n  }\n}\n</code></pre> <p>Once this works, explore the advanced configuration for directory types and custom key/value classes.</p>"},{"location":"how-to-use/quick-start/#filesystem-usage","title":"\ud83d\udcbe Filesystem Usage","text":"<p>Storing data to the file system is the main function of the library. A file system directory can be used like this:</p> <pre><code>import org.hestiastore.index.directory.Directory;\nimport org.hestiastore.index.directory.FsDirectory;\nimport java.io.File;\n\n// Create a file system directory\nDirectory directory = new FsDirectory(new File(\"../some/directory/\"));\n</code></pre> <p>This immediately creates the initial index files and makes it ready to use.</p> <p>Note: When an index works with a directory, it locks it with a <code>.lock</code> file. When the index is closed, the lock is removed.</p>"},{"location":"how-to-use/quick-start/#opening-an-existing-index","title":"\ud83d\udcc2 Opening an Existing Index","text":"<p>Use a dedicated open method for existing indexes:</p> <pre><code>import org.hestiastore.index.sst.Index;\nimport org.hestiastore.index.sst.IndexConfiguration;\n\nIndexConfiguration&lt;String, String&gt; conf = IndexConfiguration\n    .&lt;String, String&gt;builder()\n    .withKeyClass(String.class)\n    .withValueClass(String.class)\n    .withName(\"test_index\")\n    .build();\n\nIndex&lt;String, String&gt; index = Index.open(directory, conf);\n</code></pre>"},{"location":"how-to-use/quick-start/#data-manipulation","title":"\u270d\ufe0f Data Manipulation","text":"<p>Put and get are straightforward:</p> <pre><code>index.put(\"Hello\", \"World\");\nString value = index.get(\"Hello\");\n</code></pre> <p>Stored values are immediately available.</p>"},{"location":"how-to-use/quick-start/#sequential-data-reading","title":"\ud83d\udcc8 Sequential Data Reading","text":"<p>Read all entries in ascending key order:</p> <pre><code>index.getStream().forEach(entry -&gt; {\n  System.out.println(\"Entry: \" + entry);\n});\n</code></pre> <p>Select a subset of entries by segment window (offset, limit):</p> <pre><code>import org.hestiastore.index.sst.SegmentWindow;\n\n// Only data from selected segments will be returned\nSegmentWindow window = SegmentWindow.of(1000, 10);\nindex.getStream(window).forEach(entry -&gt; System.out.println(entry));\n</code></pre>"},{"location":"how-to-use/quick-start/#data-maintenance","title":"\ud83e\uddf9 Data Maintenance","text":"<p>Maintenance operations available on Index:</p> <ul> <li><code>flush()</code> Flushes in\u2011memory data to disk. Useful before iterating or when you need to ensure data is durable.</li> <li><code>checkAndRepairConsistency()</code> Verifies metadata and segment consistency and attempts repairs; fails if beyond repair.</li> <li><code>compact()</code> Compacts segments and can reduce disk usage.</li> </ul> <pre><code>// After flush, all data changes are persisted. It is similar to a transaction commit.\nindex.flush();\n\n// Verify consistency or try to repair\nindex.checkAndRepairConsistency();\n\n// Data may be fragmented; this recalculates all segments\nindex.compact();\n</code></pre>"},{"location":"how-to-use/quick-start/#limitations","title":"\u26a0\ufe0f Limitations","text":""},{"location":"how-to-use/quick-start/#streaming-consistency","title":"\ud83c\udf00 Streaming Consistency","text":"<p>Streaming uses a snapshot at iteration time and does not use the index cache to avoid mid\u2011iteration mutations breaking iteration. To reduce stale results:</p> <ul> <li>Call <code>flush()</code> before streaming if recent writes must be included.</li> <li>Avoid calling <code>put()</code> or <code>delete()</code> while iterating a stream.</li> <li>For full snapshot reads, consider <code>compact()</code> beforehand to simplify segments.</li> </ul>"},{"location":"how-to-use/quick-start/#thread-safety","title":"\ud83d\udd12 Thread Safety","text":"<p>Index is not thread\u2011safe by default. Enable synchronization via configuration. See option withThreadSafe.</p>"},{"location":"how-to-use/quick-start/#exception-handling","title":"\ud83e\udde8 Exception Handling","text":"<p>Common runtime exceptions you may encounter:</p> <ul> <li><code>NullPointerException</code> \u2013 Severe I/O or unexpected nulls (e.g., corrupted files).</li> <li><code>IndexException</code> \u2013 Internal consistency issues detected by the index.</li> <li><code>IllegalArgumentException</code> \u2013 Validation errors (e.g., missing key type).</li> <li><code>IllegalStateException</code> \u2013 Inconsistent state preventing recovery.</li> </ul> <p>All exceptions are runtime exceptions and do not need explicit catching.</p>"},{"location":"how-to-use/troubleshooting/","title":"\ud83d\udee0\ufe0f Troubleshooting","text":"<p>Common issues and quick fixes.</p>"},{"location":"how-to-use/troubleshooting/#lock-file-prevents-opening","title":"\ud83d\udd12 \".lock\" File Prevents Opening","text":"<ul> <li>Cause: Another process holds the index open, or a previous run did not close cleanly.</li> <li>Fix: Ensure the process using the index has terminated and closed the index. If safe, remove the stale .lock file after verifying no process uses the directory.</li> </ul>"},{"location":"how-to-use/troubleshooting/#consistency-errors-indexexception","title":"\ud83e\udde9 Consistency Errors (IndexException)","text":"<ul> <li>Symptom: Consistency checks fail or reads behave unexpectedly after a crash.</li> <li>Fix: Run checkAndRepairConsistency(). If it still fails, restore from a backup.</li> </ul>"},{"location":"how-to-use/troubleshooting/#exception-attempt-to-insert-the-same-key-as-previous","title":"\u26a0\ufe0f Exception 'Attempt to insert the same key as previous'","text":"<p>When followin exception appears in logs. Than it's probably problem with inconsistent implementaion of custom data type. Please look at custom type configuration</p> <pre><code>xception in thread \"main\" java.lang.IllegalArgumentException: Attempt to insert the same key as previous. Key(Base64)='QUFHR0JHQkFBVERTU1BTUw==', comparator='DtFixedLengthByteArray$$Lambda/0x0000000800214238'\n    at org.hestiastore.index.sorteddatafile.SortedDataFileWriter.verifyKeyOrder(SortedDataFileWriter.java:76)\n    at org.hestiastore.index.sorteddatafile.SortedDataFileWriter.write(SortedDataFileWriter.java:104)\n    at org.hestiastore.index.GuardedEntryWriter.write(GuardedEntryWriter.java:18)\n    at org.hestiastore.index.segment.SegmentDeltaCacheWriter.lambda$doClose$0(SegmentDeltaCacheWriter.java:87)\n    at org.hestiastore.index.WriteTransaction.execute(WriteTransaction.java:41)\n    at org.hestiastore.index.segment.SegmentDeltaCacheWriter.doClose(SegmentDeltaCacheWriter.java:84)\n    at org.hestiastore.index.AbstractCloseableResource.close(AbstractCloseableResource.java:23)\n    at org.hestiastore.index.segment.SegmentDeltaCacheCompactingWriter.doClose(SegmentDeltaCacheCompactingWriter.java:47)\n    at org.hestiastore.index.AbstractCloseableResource.close(AbstractCloseableResource.java:23)\n    at org.hestiastore.index.sst.CompactSupport.flushToCurrentSegment(CompactSupport.java:84)\n    at org.hestiastore.index.sst.CompactSupport.compact(CompactSupport.java:59)\n    at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)\n    at org.hestiastore.index.sst.SstIndexImpl.flushCache(SstIndexImpl.java:126)\n    at org.hestiastore.index.sst.SstIndexImpl.put(SstIndexImpl.java:83)\n    at org.hestiastore.index.sst.Index.put(Index.java:93)\n</code></pre>"},{"location":"how-to-use/troubleshooting/#dependency-resolution-fails","title":"\ud83d\udce6 Dependency Resolution Fails","text":"<ul> <li> <p>Maven: run the command below and confirm org.hestiastore.index:core is present.</p> <p>mvn dependency:tree</p> </li> <li> <p>Gradle: run the command below for dependency insight.</p> <p>./gradlew dependencyInsight --dependency org.hestiastore.index:core</p> </li> <li> <p>Also verify you used the latest version from Maven Central.</p> </li> </ul>"},{"location":"how-to-use/troubleshooting/#java-version-mismatch","title":"\u2615 Java Version Mismatch","text":"<ul> <li>Ensure Java 11+ is used (Java 17 recommended). Check with java -version and align your IDE or CI JDK.</li> </ul>"},{"location":"how-to-use/troubleshooting/#permission-or-path-errors","title":"\ud83d\udcc1 Permission or Path Errors","text":"<ul> <li>Ensure your process has read/write permissions to the target directory.</li> <li>Use absolute paths for clarity in services or containers.</li> </ul>"},{"location":"how-to-use/troubleshooting/#stale-streaming-results","title":"\ud83d\udd04 Stale Streaming Results","text":"<ul> <li>Call flush() before streaming if you require latest writes.</li> <li>Avoid put() or delete() while iterating a stream.</li> </ul>"},{"location":"how-to-use/troubleshooting/#need-more-help","title":"\u2753 Need More Help?","text":"<ul> <li>Search existing tickets: https://github.com/jajir/HestiaStore/issues?q=is%3Aissue</li> <li>Open a new ticket: https://github.com/jajir/HestiaStore/issues/new/choose</li> </ul> <p>When opening a ticket, please include:</p> <ul> <li>Your Java version (run <code>java -version</code>)</li> <li>HestiaStore version and build tool (Maven/Gradle)</li> <li>Minimal code snippet or steps to reproduce</li> <li>Relevant logs/stack traces and OS info</li> </ul>"},{"location":"operations/","title":"Production Guide","text":"<p>Operational guidance for running HestiaStore in production.</p> <ul> <li>Deployment considerations and sizing</li> <li>File system and storage layout</li> <li>Backup and restore strategy</li> <li>Observability and logging</li> </ul>"},{"location":"operations/#after-unexpected-shutdown","title":"After Unexpected Shutdown","text":"<p>Recommended steps to verify integrity and reclaim optimal layout:</p> <ul> <li>Reopen the index and run a consistency check to validate segments and the key\u2192segment map.</li> <li>Optionally run a compaction to merge delta caches into main SST files and rebuild auxiliary structures (sparse index, Bloom filter).</li> <li>Take a fresh backup after compaction completes.</li> </ul> <p>Example (Java):</p> <pre><code>// Open existing index (types omitted for brevity)\nIndex&lt;Integer, String&gt; index = Index.open(directory);\n\n// 1) Verify internal consistency (throws IndexException on irreparable issues)\nindex.checkAndRepairConsistency();\n\n// 2) Optionally compact to fold delta caches into main SST files\nindex.compact();\n\n// 3) Create a new backup snapshot\n//   (use your backup process; see operations/backup-restore.md)\n\nindex.close();\n</code></pre> <p>Notes: - HestiaStore has no WAL; durability comes from flush/close boundaries and atomic file replacement on commit. - If you keep running without compaction, reads remain correct; compaction improves locality and space usage.</p>"},{"location":"operations/backup-restore/","title":"Backup &amp; Restore","text":"<p>Approaches for backing up and restoring HestiaStore data.</p> <ul> <li>Snapshotting strategies</li> <li>Consistency considerations</li> <li>Restore and validation steps</li> </ul> <p>Content to be expanded.</p>"},{"location":"operations/monitoring/","title":"Observability","text":"<p>Monitoring and logging guidance for HestiaStore.</p> <ul> <li>Metrics and health checks (to be defined)</li> <li>Logging configuration: see configuration/logging.md</li> <li>Common alerts and thresholds</li> </ul> <p>Content to be expanded.</p>"},{"location":"operations/tuning/","title":"Performance Tuning","text":"<p>Guidance for tuning HestiaStore performance.</p> <ul> <li>Memory and buffer settings</li> <li>Compaction/merge policies</li> <li>I/O characteristics and caching</li> </ul> <p>Content to be expanded.</p>"}]}